{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.1\n",
        "!pip install dgl==0.9.0\n",
        "!pip install torch_geometric\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vt3bE89GnlZ",
        "outputId": "a2630614-2c6b-401f-bfff-a53cb5893e24"
      },
      "id": "1Vt3bE89GnlZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.4.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0\n",
            "Collecting dgl==0.9.0\n",
            "  Downloading dgl-0.9.0-cp310-cp310-manylinux1_x86_64.whl.metadata (557 bytes)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.0) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.0) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.0) (4.66.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==0.9.0) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==0.9.0) (2024.8.30)\n",
            "Downloading dgl-0.9.0-cp310-cp310-manylinux1_x86_64.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dgl\n",
            "Successfully installed dgl-0.9.0\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d6b0edec-4f1d-4a83-a3e1-418c863dc18c",
      "metadata": {
        "id": "d6b0edec-4f1d-4a83-a3e1-418c863dc18c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508de803-6d0a-4335-ae58-8aba75381b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:104: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:128: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dZ):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:177: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:207: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, *dZ):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:287: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:304: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dZ):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:352: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:371: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, *dZ):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:431: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:467: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_out):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:498: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:535: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, *grad_out):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:566: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:575: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dy):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:595: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:603: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dy):\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:666: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n",
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/sparse.py:692: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=th.float16)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import os\n",
        "from natsort import natsorted\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import FastText\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import dgl.data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense,Bidirectional\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from dgl.nn import GraphConv\n",
        "from IPython.display import FileLink\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TBIGvZ2LcdEr",
        "outputId": "fad8dcde-4d33-400a-e019-e4f76589d09d"
      },
      "id": "TBIGvZ2LcdEr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.0\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (12.1.105)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nccl-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.19.3 torch-2.2.0 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl torch_geometric tensorflow"
      ],
      "metadata": {
        "id": "yOd8xS9zuuJz",
        "outputId": "c3f609ea-2725-4514-c72c-c1b9f9429c97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "yOd8xS9zuuJz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Collecting torchdata>=0.5.0 (from dgl)\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.6.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.3.0+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, nvidia-cusolver-cu12, torchdata, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch_geometric-2.5.3 torchdata-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f9cc503-d869-486a-bde1-b0872d692955",
      "metadata": {
        "id": "7f9cc503-d869-486a-bde1-b0872d692955"
      },
      "outputs": [],
      "source": [
        "image_features=pd.read_csv('/Image_features_CNN.csv')\n",
        "\n",
        "image_features.drop(['Unnamed: 0'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "-8yo3YcaeT4R",
        "outputId": "dc24f397-4ebf-4729-9d46-7ab80b486b10"
      },
      "id": "-8yo3YcaeT4R",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0    1.574822 -0.158900  0.467889 -0.305082 -0.203228 -0.017083  0.480681   \n",
              "1    1.264443 -0.239694  0.895545 -0.191712  0.306874 -0.446246  0.166276   \n",
              "2    1.257561 -1.102980  0.224928 -0.385812 -0.163901  0.627091 -0.150821   \n",
              "3    0.606940  0.074471  1.397253 -0.818537  0.285412 -0.062521 -0.016608   \n",
              "4    2.051283  0.244863  1.007189 -0.381611 -0.485195 -0.037227 -0.085634   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "101  0.972596 -0.399213 -0.571906  0.172622  0.656279  0.051971  0.429346   \n",
              "102  0.948468 -0.396330  0.012355  1.034862 -0.622628 -0.369064  0.019497   \n",
              "103  0.583888 -0.459673 -0.814538  0.602156 -0.352087  0.411991 -0.322276   \n",
              "104  0.799966 -0.755125 -1.321654  0.316713  0.745535 -0.000321 -0.081976   \n",
              "105  0.698931 -0.563123 -0.868669  0.415313  0.023771 -0.066833 -0.165323   \n",
              "\n",
              "            7         8         9  ...        84        85        86  \\\n",
              "0    0.167982  0.042460 -0.748177  ...  0.051921  0.232423  0.069028   \n",
              "1    0.476028  0.118328 -0.235823  ... -0.054559 -0.129065 -0.373943   \n",
              "2    0.053796  0.813382  0.219870  ... -0.013023 -0.108738 -0.267997   \n",
              "3    0.090328  0.169668 -0.424401  ... -0.095884  0.358859  0.118848   \n",
              "4    0.747421  1.310601  0.523129  ... -0.071531 -0.031057  0.265448   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "101  0.375945  0.809730 -0.286302  ... -0.034617 -0.099114  0.065589   \n",
              "102  0.022257 -0.218794 -0.141589  ...  0.235054  0.006692  0.102590   \n",
              "103  0.135510 -0.313030 -0.703053  ...  0.075110  0.079732 -0.312061   \n",
              "104  0.907992  0.324029  0.613288  ... -0.035147 -0.124424  0.227205   \n",
              "105 -0.130692  0.093736  0.708718  ...  0.164101  0.036017  0.068491   \n",
              "\n",
              "           87        88        89        90        91        92        93  \n",
              "0   -0.406838 -0.023879 -0.389306  0.495563  0.280061 -0.343126  0.119126  \n",
              "1    0.131601 -0.055215  0.492614 -0.247043  0.136156  0.030885  0.379053  \n",
              "2   -0.139976 -0.049751 -0.062366  0.222516  0.475124  0.105134 -0.136304  \n",
              "3   -0.216600  0.091018 -0.007132 -0.107883 -0.320094 -0.191975 -0.190078  \n",
              "4    0.067555 -0.107087  0.097043  0.088410  0.170019 -0.171663  0.001111  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "101 -0.175906 -0.050888 -0.036915 -0.186933 -0.126468  0.068655 -0.094472  \n",
              "102 -0.125759  0.205040  0.068494 -0.148689 -0.144618 -0.185295 -0.133205  \n",
              "103 -0.008066  0.202195  0.013542  0.121599  0.067179 -0.115572  0.149759  \n",
              "104  0.057589 -0.031966 -0.054929  0.133103  0.105809  0.025864  0.021637  \n",
              "105  0.217232 -0.203910 -0.223363  0.074961 -0.184382  0.100775 -0.274663  \n",
              "\n",
              "[106 rows x 94 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c57e45a-56cf-4aa9-9035-298a77866c95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.574822</td>\n",
              "      <td>-0.158900</td>\n",
              "      <td>0.467889</td>\n",
              "      <td>-0.305082</td>\n",
              "      <td>-0.203228</td>\n",
              "      <td>-0.017083</td>\n",
              "      <td>0.480681</td>\n",
              "      <td>0.167982</td>\n",
              "      <td>0.042460</td>\n",
              "      <td>-0.748177</td>\n",
              "      <td>...</td>\n",
              "      <td>0.051921</td>\n",
              "      <td>0.232423</td>\n",
              "      <td>0.069028</td>\n",
              "      <td>-0.406838</td>\n",
              "      <td>-0.023879</td>\n",
              "      <td>-0.389306</td>\n",
              "      <td>0.495563</td>\n",
              "      <td>0.280061</td>\n",
              "      <td>-0.343126</td>\n",
              "      <td>0.119126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.264443</td>\n",
              "      <td>-0.239694</td>\n",
              "      <td>0.895545</td>\n",
              "      <td>-0.191712</td>\n",
              "      <td>0.306874</td>\n",
              "      <td>-0.446246</td>\n",
              "      <td>0.166276</td>\n",
              "      <td>0.476028</td>\n",
              "      <td>0.118328</td>\n",
              "      <td>-0.235823</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054559</td>\n",
              "      <td>-0.129065</td>\n",
              "      <td>-0.373943</td>\n",
              "      <td>0.131601</td>\n",
              "      <td>-0.055215</td>\n",
              "      <td>0.492614</td>\n",
              "      <td>-0.247043</td>\n",
              "      <td>0.136156</td>\n",
              "      <td>0.030885</td>\n",
              "      <td>0.379053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.257561</td>\n",
              "      <td>-1.102980</td>\n",
              "      <td>0.224928</td>\n",
              "      <td>-0.385812</td>\n",
              "      <td>-0.163901</td>\n",
              "      <td>0.627091</td>\n",
              "      <td>-0.150821</td>\n",
              "      <td>0.053796</td>\n",
              "      <td>0.813382</td>\n",
              "      <td>0.219870</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013023</td>\n",
              "      <td>-0.108738</td>\n",
              "      <td>-0.267997</td>\n",
              "      <td>-0.139976</td>\n",
              "      <td>-0.049751</td>\n",
              "      <td>-0.062366</td>\n",
              "      <td>0.222516</td>\n",
              "      <td>0.475124</td>\n",
              "      <td>0.105134</td>\n",
              "      <td>-0.136304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.606940</td>\n",
              "      <td>0.074471</td>\n",
              "      <td>1.397253</td>\n",
              "      <td>-0.818537</td>\n",
              "      <td>0.285412</td>\n",
              "      <td>-0.062521</td>\n",
              "      <td>-0.016608</td>\n",
              "      <td>0.090328</td>\n",
              "      <td>0.169668</td>\n",
              "      <td>-0.424401</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.095884</td>\n",
              "      <td>0.358859</td>\n",
              "      <td>0.118848</td>\n",
              "      <td>-0.216600</td>\n",
              "      <td>0.091018</td>\n",
              "      <td>-0.007132</td>\n",
              "      <td>-0.107883</td>\n",
              "      <td>-0.320094</td>\n",
              "      <td>-0.191975</td>\n",
              "      <td>-0.190078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.051283</td>\n",
              "      <td>0.244863</td>\n",
              "      <td>1.007189</td>\n",
              "      <td>-0.381611</td>\n",
              "      <td>-0.485195</td>\n",
              "      <td>-0.037227</td>\n",
              "      <td>-0.085634</td>\n",
              "      <td>0.747421</td>\n",
              "      <td>1.310601</td>\n",
              "      <td>0.523129</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.071531</td>\n",
              "      <td>-0.031057</td>\n",
              "      <td>0.265448</td>\n",
              "      <td>0.067555</td>\n",
              "      <td>-0.107087</td>\n",
              "      <td>0.097043</td>\n",
              "      <td>0.088410</td>\n",
              "      <td>0.170019</td>\n",
              "      <td>-0.171663</td>\n",
              "      <td>0.001111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.972596</td>\n",
              "      <td>-0.399213</td>\n",
              "      <td>-0.571906</td>\n",
              "      <td>0.172622</td>\n",
              "      <td>0.656279</td>\n",
              "      <td>0.051971</td>\n",
              "      <td>0.429346</td>\n",
              "      <td>0.375945</td>\n",
              "      <td>0.809730</td>\n",
              "      <td>-0.286302</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.034617</td>\n",
              "      <td>-0.099114</td>\n",
              "      <td>0.065589</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.050888</td>\n",
              "      <td>-0.036915</td>\n",
              "      <td>-0.186933</td>\n",
              "      <td>-0.126468</td>\n",
              "      <td>0.068655</td>\n",
              "      <td>-0.094472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.948468</td>\n",
              "      <td>-0.396330</td>\n",
              "      <td>0.012355</td>\n",
              "      <td>1.034862</td>\n",
              "      <td>-0.622628</td>\n",
              "      <td>-0.369064</td>\n",
              "      <td>0.019497</td>\n",
              "      <td>0.022257</td>\n",
              "      <td>-0.218794</td>\n",
              "      <td>-0.141589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.235054</td>\n",
              "      <td>0.006692</td>\n",
              "      <td>0.102590</td>\n",
              "      <td>-0.125759</td>\n",
              "      <td>0.205040</td>\n",
              "      <td>0.068494</td>\n",
              "      <td>-0.148689</td>\n",
              "      <td>-0.144618</td>\n",
              "      <td>-0.185295</td>\n",
              "      <td>-0.133205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.583888</td>\n",
              "      <td>-0.459673</td>\n",
              "      <td>-0.814538</td>\n",
              "      <td>0.602156</td>\n",
              "      <td>-0.352087</td>\n",
              "      <td>0.411991</td>\n",
              "      <td>-0.322276</td>\n",
              "      <td>0.135510</td>\n",
              "      <td>-0.313030</td>\n",
              "      <td>-0.703053</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075110</td>\n",
              "      <td>0.079732</td>\n",
              "      <td>-0.312061</td>\n",
              "      <td>-0.008066</td>\n",
              "      <td>0.202195</td>\n",
              "      <td>0.013542</td>\n",
              "      <td>0.121599</td>\n",
              "      <td>0.067179</td>\n",
              "      <td>-0.115572</td>\n",
              "      <td>0.149759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.799966</td>\n",
              "      <td>-0.755125</td>\n",
              "      <td>-1.321654</td>\n",
              "      <td>0.316713</td>\n",
              "      <td>0.745535</td>\n",
              "      <td>-0.000321</td>\n",
              "      <td>-0.081976</td>\n",
              "      <td>0.907992</td>\n",
              "      <td>0.324029</td>\n",
              "      <td>0.613288</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035147</td>\n",
              "      <td>-0.124424</td>\n",
              "      <td>0.227205</td>\n",
              "      <td>0.057589</td>\n",
              "      <td>-0.031966</td>\n",
              "      <td>-0.054929</td>\n",
              "      <td>0.133103</td>\n",
              "      <td>0.105809</td>\n",
              "      <td>0.025864</td>\n",
              "      <td>0.021637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.698931</td>\n",
              "      <td>-0.563123</td>\n",
              "      <td>-0.868669</td>\n",
              "      <td>0.415313</td>\n",
              "      <td>0.023771</td>\n",
              "      <td>-0.066833</td>\n",
              "      <td>-0.165323</td>\n",
              "      <td>-0.130692</td>\n",
              "      <td>0.093736</td>\n",
              "      <td>0.708718</td>\n",
              "      <td>...</td>\n",
              "      <td>0.164101</td>\n",
              "      <td>0.036017</td>\n",
              "      <td>0.068491</td>\n",
              "      <td>0.217232</td>\n",
              "      <td>-0.203910</td>\n",
              "      <td>-0.223363</td>\n",
              "      <td>0.074961</td>\n",
              "      <td>-0.184382</td>\n",
              "      <td>0.100775</td>\n",
              "      <td>-0.274663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 94 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c57e45a-56cf-4aa9-9035-298a77866c95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c57e45a-56cf-4aa9-9035-298a77866c95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c57e45a-56cf-4aa9-9035-298a77866c95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b62dc629-23f2-438e-9c6f-e3c149e4d714\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b62dc629-23f2-438e-9c6f-e3c149e4d714')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b62dc629-23f2-438e-9c6f-e3c149e4d714 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b2097a74-5b36-43c4-bbd8-c6f17b1615b0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('image_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b2097a74-5b36-43c4-bbd8-c6f17b1615b0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('image_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "image_features"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a12d5c34-df37-460e-aea4-c4918baec35f",
      "metadata": {
        "id": "a12d5c34-df37-460e-aea4-c4918baec35f"
      },
      "outputs": [],
      "source": [
        "text_features=pd.read_csv('/Text_features_glove.csv')\n",
        "text_features.drop(['Unnamed: 0'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ada2a103-3061-49c3-8620-a84a0e1f7af5",
      "metadata": {
        "id": "ada2a103-3061-49c3-8620-a84a0e1f7af5",
        "outputId": "356f0796-3b46-4cc3-a8f8-d91486abffde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0   -0.071949 -0.009855 -0.111473 -0.068437 -0.000051 -0.012275 -0.000518   \n",
              "1   -0.111388 -0.030549 -0.016111 -0.077624 -0.002134  0.010090  0.014642   \n",
              "2   -0.067452 -0.040640 -0.062818 -0.045927  0.023676 -0.005763  0.071898   \n",
              "3    0.044775 -0.100349  0.066181 -0.059720  0.038668 -0.014245  0.151271   \n",
              "4   -0.052044  0.015356  0.009499 -0.078976  0.036031 -0.031392  0.102122   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "101 -0.017529 -0.016424 -0.022918 -0.076668  0.023412 -0.008844  0.006505   \n",
              "102 -0.078302  0.036230 -0.012988 -0.078203  0.011558  0.016312 -0.010550   \n",
              "103 -0.059429 -0.000625 -0.073761 -0.109127  0.007848 -0.006962 -0.002142   \n",
              "104 -0.073548 -0.054509 -0.110383 -0.043330 -0.024826  0.008206 -0.065709   \n",
              "105 -0.080220  0.050109 -0.050153 -0.052790 -0.046015 -0.023670 -0.041520   \n",
              "\n",
              "            7         8         9  ...       290       291       292  \\\n",
              "0    0.067638  0.035197 -0.576179  ... -0.010726 -0.031384 -0.046320   \n",
              "1   -0.010333  0.022948 -0.730976  ...  0.027492 -0.013642  0.008443   \n",
              "2    0.008058  0.032802 -0.493687  ... -0.059697 -0.039049 -0.008491   \n",
              "3    0.205177  0.125014 -1.001503  ...  0.031391 -0.125695 -0.164498   \n",
              "4    0.054999  0.026431 -1.083184  ... -0.019299 -0.133857  0.006825   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "101  0.030281  0.017040 -0.657062  ...  0.042264 -0.021711  0.037575   \n",
              "102  0.040548  0.025831 -0.934024  ...  0.027090 -0.011476  0.047851   \n",
              "103  0.003869  0.042504 -0.816508  ...  0.020281 -0.047392  0.033249   \n",
              "104  0.061760  0.000159 -0.620741  ...  0.043000 -0.087493 -0.027383   \n",
              "105  0.019331 -0.023866 -0.620228  ...  0.039181 -0.060901  0.046628   \n",
              "\n",
              "          293       294       295       296       297       298       299  \n",
              "0   -0.051469  0.004064  0.156472  0.056101 -0.083169 -0.056463  0.031270  \n",
              "1   -0.044893 -0.003665  0.099597  0.052895 -0.087087 -0.112880  0.081286  \n",
              "2    0.003039  0.033637  0.054579 -0.001603 -0.020318  0.019826  0.044889  \n",
              "3    0.020920 -0.044410  0.145637  0.119098 -0.013138 -0.084063  0.064456  \n",
              "4   -0.043171  0.006448  0.136750  0.152182 -0.024009 -0.157182  0.117417  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "101 -0.035546 -0.010538 -0.070496  0.056927 -0.031224 -0.068734  0.107339  \n",
              "102 -0.109709  0.009897  0.001342  0.076285 -0.104019 -0.059476  0.159947  \n",
              "103 -0.053682  0.005933  0.088885  0.065815 -0.086952 -0.075959  0.120227  \n",
              "104 -0.048538  0.036135  0.231635 -0.001487 -0.050909  0.032215 -0.014655  \n",
              "105 -0.049672 -0.035099  0.056592  0.038969 -0.036497 -0.105402  0.106062  \n",
              "\n",
              "[106 rows x 300 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22a908a4-151e-458e-a124-031f0100f13a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.071949</td>\n",
              "      <td>-0.009855</td>\n",
              "      <td>-0.111473</td>\n",
              "      <td>-0.068437</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>-0.012275</td>\n",
              "      <td>-0.000518</td>\n",
              "      <td>0.067638</td>\n",
              "      <td>0.035197</td>\n",
              "      <td>-0.576179</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010726</td>\n",
              "      <td>-0.031384</td>\n",
              "      <td>-0.046320</td>\n",
              "      <td>-0.051469</td>\n",
              "      <td>0.004064</td>\n",
              "      <td>0.156472</td>\n",
              "      <td>0.056101</td>\n",
              "      <td>-0.083169</td>\n",
              "      <td>-0.056463</td>\n",
              "      <td>0.031270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.111388</td>\n",
              "      <td>-0.030549</td>\n",
              "      <td>-0.016111</td>\n",
              "      <td>-0.077624</td>\n",
              "      <td>-0.002134</td>\n",
              "      <td>0.010090</td>\n",
              "      <td>0.014642</td>\n",
              "      <td>-0.010333</td>\n",
              "      <td>0.022948</td>\n",
              "      <td>-0.730976</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027492</td>\n",
              "      <td>-0.013642</td>\n",
              "      <td>0.008443</td>\n",
              "      <td>-0.044893</td>\n",
              "      <td>-0.003665</td>\n",
              "      <td>0.099597</td>\n",
              "      <td>0.052895</td>\n",
              "      <td>-0.087087</td>\n",
              "      <td>-0.112880</td>\n",
              "      <td>0.081286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.067452</td>\n",
              "      <td>-0.040640</td>\n",
              "      <td>-0.062818</td>\n",
              "      <td>-0.045927</td>\n",
              "      <td>0.023676</td>\n",
              "      <td>-0.005763</td>\n",
              "      <td>0.071898</td>\n",
              "      <td>0.008058</td>\n",
              "      <td>0.032802</td>\n",
              "      <td>-0.493687</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059697</td>\n",
              "      <td>-0.039049</td>\n",
              "      <td>-0.008491</td>\n",
              "      <td>0.003039</td>\n",
              "      <td>0.033637</td>\n",
              "      <td>0.054579</td>\n",
              "      <td>-0.001603</td>\n",
              "      <td>-0.020318</td>\n",
              "      <td>0.019826</td>\n",
              "      <td>0.044889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.044775</td>\n",
              "      <td>-0.100349</td>\n",
              "      <td>0.066181</td>\n",
              "      <td>-0.059720</td>\n",
              "      <td>0.038668</td>\n",
              "      <td>-0.014245</td>\n",
              "      <td>0.151271</td>\n",
              "      <td>0.205177</td>\n",
              "      <td>0.125014</td>\n",
              "      <td>-1.001503</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031391</td>\n",
              "      <td>-0.125695</td>\n",
              "      <td>-0.164498</td>\n",
              "      <td>0.020920</td>\n",
              "      <td>-0.044410</td>\n",
              "      <td>0.145637</td>\n",
              "      <td>0.119098</td>\n",
              "      <td>-0.013138</td>\n",
              "      <td>-0.084063</td>\n",
              "      <td>0.064456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.052044</td>\n",
              "      <td>0.015356</td>\n",
              "      <td>0.009499</td>\n",
              "      <td>-0.078976</td>\n",
              "      <td>0.036031</td>\n",
              "      <td>-0.031392</td>\n",
              "      <td>0.102122</td>\n",
              "      <td>0.054999</td>\n",
              "      <td>0.026431</td>\n",
              "      <td>-1.083184</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019299</td>\n",
              "      <td>-0.133857</td>\n",
              "      <td>0.006825</td>\n",
              "      <td>-0.043171</td>\n",
              "      <td>0.006448</td>\n",
              "      <td>0.136750</td>\n",
              "      <td>0.152182</td>\n",
              "      <td>-0.024009</td>\n",
              "      <td>-0.157182</td>\n",
              "      <td>0.117417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>-0.017529</td>\n",
              "      <td>-0.016424</td>\n",
              "      <td>-0.022918</td>\n",
              "      <td>-0.076668</td>\n",
              "      <td>0.023412</td>\n",
              "      <td>-0.008844</td>\n",
              "      <td>0.006505</td>\n",
              "      <td>0.030281</td>\n",
              "      <td>0.017040</td>\n",
              "      <td>-0.657062</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042264</td>\n",
              "      <td>-0.021711</td>\n",
              "      <td>0.037575</td>\n",
              "      <td>-0.035546</td>\n",
              "      <td>-0.010538</td>\n",
              "      <td>-0.070496</td>\n",
              "      <td>0.056927</td>\n",
              "      <td>-0.031224</td>\n",
              "      <td>-0.068734</td>\n",
              "      <td>0.107339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>-0.078302</td>\n",
              "      <td>0.036230</td>\n",
              "      <td>-0.012988</td>\n",
              "      <td>-0.078203</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>0.016312</td>\n",
              "      <td>-0.010550</td>\n",
              "      <td>0.040548</td>\n",
              "      <td>0.025831</td>\n",
              "      <td>-0.934024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027090</td>\n",
              "      <td>-0.011476</td>\n",
              "      <td>0.047851</td>\n",
              "      <td>-0.109709</td>\n",
              "      <td>0.009897</td>\n",
              "      <td>0.001342</td>\n",
              "      <td>0.076285</td>\n",
              "      <td>-0.104019</td>\n",
              "      <td>-0.059476</td>\n",
              "      <td>0.159947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>-0.059429</td>\n",
              "      <td>-0.000625</td>\n",
              "      <td>-0.073761</td>\n",
              "      <td>-0.109127</td>\n",
              "      <td>0.007848</td>\n",
              "      <td>-0.006962</td>\n",
              "      <td>-0.002142</td>\n",
              "      <td>0.003869</td>\n",
              "      <td>0.042504</td>\n",
              "      <td>-0.816508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020281</td>\n",
              "      <td>-0.047392</td>\n",
              "      <td>0.033249</td>\n",
              "      <td>-0.053682</td>\n",
              "      <td>0.005933</td>\n",
              "      <td>0.088885</td>\n",
              "      <td>0.065815</td>\n",
              "      <td>-0.086952</td>\n",
              "      <td>-0.075959</td>\n",
              "      <td>0.120227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>-0.073548</td>\n",
              "      <td>-0.054509</td>\n",
              "      <td>-0.110383</td>\n",
              "      <td>-0.043330</td>\n",
              "      <td>-0.024826</td>\n",
              "      <td>0.008206</td>\n",
              "      <td>-0.065709</td>\n",
              "      <td>0.061760</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>-0.620741</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>-0.087493</td>\n",
              "      <td>-0.027383</td>\n",
              "      <td>-0.048538</td>\n",
              "      <td>0.036135</td>\n",
              "      <td>0.231635</td>\n",
              "      <td>-0.001487</td>\n",
              "      <td>-0.050909</td>\n",
              "      <td>0.032215</td>\n",
              "      <td>-0.014655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>-0.080220</td>\n",
              "      <td>0.050109</td>\n",
              "      <td>-0.050153</td>\n",
              "      <td>-0.052790</td>\n",
              "      <td>-0.046015</td>\n",
              "      <td>-0.023670</td>\n",
              "      <td>-0.041520</td>\n",
              "      <td>0.019331</td>\n",
              "      <td>-0.023866</td>\n",
              "      <td>-0.620228</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039181</td>\n",
              "      <td>-0.060901</td>\n",
              "      <td>0.046628</td>\n",
              "      <td>-0.049672</td>\n",
              "      <td>-0.035099</td>\n",
              "      <td>0.056592</td>\n",
              "      <td>0.038969</td>\n",
              "      <td>-0.036497</td>\n",
              "      <td>-0.105402</td>\n",
              "      <td>0.106062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 300 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22a908a4-151e-458e-a124-031f0100f13a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22a908a4-151e-458e-a124-031f0100f13a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22a908a4-151e-458e-a124-031f0100f13a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f97fa282-3b60-4265-bb76-fe96710c5e97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f97fa282-3b60-4265-bb76-fe96710c5e97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f97fa282-3b60-4265-bb76-fe96710c5e97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fcfb37e0-a53b-4572-a518-2471a6b41b81\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('text_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fcfb37e0-a53b-4572-a518-2471a6b41b81 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('text_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "text_features"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "text_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e87dfff5-f518-4535-8d6a-503b7f790ce2",
      "metadata": {
        "id": "e87dfff5-f518-4535-8d6a-503b7f790ce2"
      },
      "outputs": [],
      "source": [
        "MM= pd.concat([text_features,image_features], axis=1)\n",
        "X_train=MM.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4fa8a498-9258-430c-a575-0558b31e0502",
      "metadata": {
        "id": "4fa8a498-9258-430c-a575-0558b31e0502",
        "outputId": "c022026b-3901-4591-a3b3-365034907a40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 394)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "04d07bfc-a3b8-47c5-9efa-a0a6c8429b2b",
      "metadata": {
        "id": "04d07bfc-a3b8-47c5-9efa-a0a6c8429b2b"
      },
      "outputs": [],
      "source": [
        "X_train_df=pd.DataFrame(X_train)\n",
        "X_train_df_copy=X_train_df.copy()\n",
        "X_train_df.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "Src_ID=[i for i in range(0,106) for _ in range(0,105-i)]\n",
        "Dst_ID=[i for i in range(0,106) for i in range(1+i,106)]\n",
        "elements_to_repeat=X_train.tolist()\n",
        "repetition_counts=[105-i for i in range(0,105)]\n",
        "\n",
        "Src_feature=[]\n",
        "for element, count in zip(elements_to_repeat, repetition_counts):\n",
        "    Src_feature.extend([element] * count)\n",
        "\n",
        "Dst_feature=[]\n",
        "for i in range(1,106):\n",
        "    for j in range(i,106):\n",
        "        Dst_feature.append(X_train.tolist()[j])\n",
        "\n",
        "Nodes_Data=pd.DataFrame()\n",
        "Nodes_Data['Id']=[i for i in range(0,106)]\n",
        "labels = pd.read_csv(\"/AnimalLabels.csv\")\n",
        "labels['majority_vote'] = labels.mode(axis=1, numeric_only=True).astype(int)\n",
        "Nodes_Data['features']=X_train.tolist()\n",
        "Nodes_Data['label']=labels['majority_vote']\n",
        "\n",
        "dup=[0 for i in range(0,106)]\n",
        "Edge=pd.DataFrame()\n",
        "Edge['Src Id']=Src_ID\n",
        "Edge['Src_feature']=Src_feature\n",
        "Edge['Dst_feature']=Dst_feature\n",
        "Edge['Dst Id']=Dst_ID\n",
        "\n",
        "\n",
        "Src_Ids=[i for i in range(0,106) for _ in range(0,106)]\n",
        "Dst_Ids = [i % 106 for i in range(106 * 106)]\n",
        "Src_features=[X_train.tolist()[i] for i in range(0,106)  for i in range(0,106)]\n",
        "elements_to_repeat=X_train.tolist()\n",
        "repetition_counts=[106 for i in range(0,106)]\n",
        "Dst_features=[]\n",
        "for element, count in zip(elements_to_repeat, repetition_counts):\n",
        "    Dst_features.extend([element] * count)\n",
        "\n",
        "Edge_Data=pd.DataFrame()\n",
        "Edge_Data['Src Ids']=Src_Ids\n",
        "Edge_Data['Src_features']=Src_features\n",
        "Edge_Data['Dst_features']=Dst_features\n",
        "Edge_Data['Dst Ids']=Dst_Ids\n",
        "\n",
        "edge_weight=[]\n",
        "for i in range(0,5565):\n",
        "    A=np.array(Edge['Src_feature'][i])\n",
        "    B=np.array(Edge['Dst_feature'][i])\n",
        "    Cosine_similarity=np.dot(A,B)/(norm(A)*norm(B))\n",
        "    edge_weight.append(Cosine_similarity)\n",
        "\n",
        "for i in range(len(edge_weight)):\n",
        "    if edge_weight[i]<0:\n",
        "        edge_weight[i]=0\n",
        "\n",
        "Edge['edge weights']=edge_weight\n",
        "\n",
        "\n",
        "edge_weights=[]\n",
        "for i in range(0,11236):\n",
        "    A=np.array(Edge_Data['Src_features'][i])\n",
        "    B=np.array(Edge_Data['Dst_features'][i])\n",
        "    Cosine_similarity=np.dot(A,B)/(norm(A)*norm(B))\n",
        "    edge_weights.append(Cosine_similarity)\n",
        "\n",
        "Edge_Data['edge weights']=edge_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_weight"
      ],
      "metadata": {
        "id": "WyXwHiZ8srMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d3e4bb5-545b-4d83-e9d9-7cbc0b792a71"
      },
      "id": "WyXwHiZ8srMa",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36933451923159044,\n",
              " 0.20188085075614823,\n",
              " 0.3391602067413753,\n",
              " 0.33037234503148327,\n",
              " 0.28229449927787037,\n",
              " 0.2875550201552659,\n",
              " 0.3511457016292417,\n",
              " 0.15215096049729687,\n",
              " 0.21189518293583792,\n",
              " 0.2854512993188685,\n",
              " 0.29565122913257996,\n",
              " 0.2558674276695262,\n",
              " 0.22130218869690407,\n",
              " 0.256761685113677,\n",
              " 0.22798070244793756,\n",
              " 0.13281087841787662,\n",
              " 0.09945622042315554,\n",
              " 0.07545900840395076,\n",
              " 0.16481297119925792,\n",
              " 0.2596408610691616,\n",
              " 0.1580320203962707,\n",
              " 0.22388388409340335,\n",
              " 0.1484426518829608,\n",
              " 0.0474646875399311,\n",
              " 0.07089522129913126,\n",
              " 0.051223797586399375,\n",
              " 0,\n",
              " 0.18388251646053883,\n",
              " 0.05588608269881084,\n",
              " 0.047746833467733674,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.17223772996179118,\n",
              " 0.022635868021772625,\n",
              " 0.046732687991621315,\n",
              " 0.0416183635583747,\n",
              " 0.1127354388838679,\n",
              " 0.08695977112626554,\n",
              " 0.1909792269673502,\n",
              " 0.11452951454739105,\n",
              " 0.10165351995877141,\n",
              " 0.13902229735716137,\n",
              " 0.050898828152738995,\n",
              " 0.2505215459049555,\n",
              " 0.2005614800450569,\n",
              " 0.21775836091732595,\n",
              " 0.09671464913845769,\n",
              " 0.276942776324164,\n",
              " 0.12359984937630517,\n",
              " 0.5061031246201846,\n",
              " 0.38810425584480795,\n",
              " 0.4217830913121329,\n",
              " 0.3861949803948578,\n",
              " 0.4295259634182974,\n",
              " 0.3969251478228268,\n",
              " 0,\n",
              " 0.2803362063448537,\n",
              " 0.10020550020153564,\n",
              " 0.13823528099461616,\n",
              " 0.08482970307405183,\n",
              " 0.19703735134095998,\n",
              " 0.28544250552399897,\n",
              " 0.1874169742646031,\n",
              " 0.26875938259401705,\n",
              " 0.15189128906725763,\n",
              " 0.14168068468859268,\n",
              " 0.17999670063740483,\n",
              " 0.182219474736803,\n",
              " 0.13163448380514303,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.18003546245678761,\n",
              " 0.0991576612274388,\n",
              " 0.27107916886836103,\n",
              " 0.11621717297912389,\n",
              " 0.16928415748272932,\n",
              " 0.06364375110284656,\n",
              " 0.1390919479572665,\n",
              " 0.1516482231098321,\n",
              " 0,\n",
              " 0.17537767677938923,\n",
              " 0.17151867368473775,\n",
              " 0.17954573438677018,\n",
              " 0.12376124484078548,\n",
              " 0.1936426236778649,\n",
              " 0.1815708163165289,\n",
              " 0.21280845695675854,\n",
              " 0.2810426746458225,\n",
              " 0.28622547263820397,\n",
              " 0.35616134241866165,\n",
              " 0.22283927387404237,\n",
              " 0.12813081134257165,\n",
              " 0.26688041181306654,\n",
              " 0.2772453524727999,\n",
              " 0.4371857314621728,\n",
              " 0.42575767623328703,\n",
              " 0.31428853463690365,\n",
              " 0.37440442379075867,\n",
              " 0.4347916635369329,\n",
              " 0.24005785921796768,\n",
              " 0.3142097709011973,\n",
              " 0.30138155378293313,\n",
              " 0.3334887285660895,\n",
              " 0.31226616323142387,\n",
              " 0.42551250796418,\n",
              " 0.41915127364895716,\n",
              " 0.404467396943856,\n",
              " 0.31290005457895814,\n",
              " 0.12559179246062901,\n",
              " 0.17010107655114112,\n",
              " 0.18977619573658863,\n",
              " 0.2344143893874898,\n",
              " 0.23872429538869144,\n",
              " 0.2025597901559338,\n",
              " 0.2017025011610135,\n",
              " 0.21478625928197734,\n",
              " 0.12936466712690542,\n",
              " 0.09750554547106875,\n",
              " 0.042394402608373905,\n",
              " 0.24864053364576913,\n",
              " 0.18165343779326565,\n",
              " 0.03329968781106375,\n",
              " 0.018147160205489805,\n",
              " 0.05128611699568195,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.20912851687116613,\n",
              " 0.05117209004441645,\n",
              " 0.07921330918177376,\n",
              " 0.036695875274070346,\n",
              " 0.11861447446311953,\n",
              " 0.2225699025523209,\n",
              " 0.2148273799091378,\n",
              " 0.22724957752688738,\n",
              " 0.1481528031775979,\n",
              " 0.10847554410335523,\n",
              " 0.15655860627195897,\n",
              " 0.20558579392899667,\n",
              " 0.18454598254341445,\n",
              " 0.21609753335204826,\n",
              " 0.07751216926668945,\n",
              " 0.26976543736314357,\n",
              " 0.16856302840756948,\n",
              " 0.3448406918543226,\n",
              " 0.3777960488195334,\n",
              " 0.3424690869767335,\n",
              " 0.41487931653204113,\n",
              " 0.39191469095140996,\n",
              " 0.4240543129810886,\n",
              " 0,\n",
              " 0.22772113433396107,\n",
              " 0.0403869758722212,\n",
              " 0.2551474195799983,\n",
              " 0.26484045594747296,\n",
              " 0.30590695057339923,\n",
              " 0.22380153133076525,\n",
              " 0.22577809980448416,\n",
              " 0.3003622106650139,\n",
              " 0.14962667321991344,\n",
              " 0.1323087415449487,\n",
              " 0.20977694452654136,\n",
              " 0.17734075388067982,\n",
              " 0.20275022067444742,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.05883197418772642,\n",
              " 0.062289742274512214,\n",
              " 0.059092504966558726,\n",
              " 0.03434667931734048,\n",
              " 0.315489621256072,\n",
              " 0.1158105252209395,\n",
              " 0.26363986439020193,\n",
              " 0.1201712580779688,\n",
              " 0.17666163904854745,\n",
              " 0.17436557903279598,\n",
              " 0.09938180460117242,\n",
              " 0.20084080801546508,\n",
              " 0,\n",
              " 0.31220968685125267,\n",
              " 0.24939629857353318,\n",
              " 0.22141783358672842,\n",
              " 0.2596885242068282,\n",
              " 0.1406505657386059,\n",
              " 0.31620280316537247,\n",
              " 0.25363434022305104,\n",
              " 0.24999566243848367,\n",
              " 0.25162160080287965,\n",
              " 0.30984468682628175,\n",
              " 0.23002919658127188,\n",
              " 0.24533116447394948,\n",
              " 0.26685597041983156,\n",
              " 0.2222587619269603,\n",
              " 0.30156109393796005,\n",
              " 0.3765769627081978,\n",
              " 0.2239624409129347,\n",
              " 0.2304303913200124,\n",
              " 0.18351890469511264,\n",
              " 0.2531813207518232,\n",
              " 0.05763350950577085,\n",
              " 0.22895638469393764,\n",
              " 0.18343228028350442,\n",
              " 0.0944365145288439,\n",
              " 0.1938827075320135,\n",
              " 0.19633775819407548,\n",
              " 0.10806159080994066,\n",
              " 0,\n",
              " 0.10768496885588595,\n",
              " 0.11900663738503944,\n",
              " 0.1603992490435124,\n",
              " 0.12459883243848764,\n",
              " 0.21293265267377104,\n",
              " 0.1592383955677921,\n",
              " 0.10326100871777788,\n",
              " 0.11753628313197541,\n",
              " 0.08923246914716228,\n",
              " 0.019045734021930036,\n",
              " 0.11676012671907793,\n",
              " 0.16345381552850832,\n",
              " 0,\n",
              " 0.0013305147463347883,\n",
              " 0.005970560269792654,\n",
              " 0.0760961439081718,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.21094919918824107,\n",
              " 0.14125495282041903,\n",
              " 0.03326938448475515,\n",
              " 0.0015285062131322213,\n",
              " 0.22762603890953834,\n",
              " 0.1531738802373138,\n",
              " 0.14755021410977107,\n",
              " 0.04674996969528097,\n",
              " 0.14030789258751422,\n",
              " 0.0473430903426496,\n",
              " 0.11959090212851367,\n",
              " 0.14481989519646926,\n",
              " 0,\n",
              " 0.2648159868221164,\n",
              " 0,\n",
              " 0.1768012917260456,\n",
              " 0.1345588320593072,\n",
              " 0.29960069202141204,\n",
              " 0.3521930872762381,\n",
              " 0.2462726822974652,\n",
              " 0.3618182796862917,\n",
              " 0.3576341554103438,\n",
              " 0.3879758721228795,\n",
              " 0,\n",
              " 0.05837284247936198,\n",
              " 0.1075092935239342,\n",
              " 0.0420453250405186,\n",
              " 0.08973611231858533,\n",
              " 0.10922448373101656,\n",
              " 0.11498076682578615,\n",
              " 0.06933866014118917,\n",
              " 0.08586538303682655,\n",
              " 0.0091292487432711,\n",
              " 0.03171151043276403,\n",
              " 0.09752348511156346,\n",
              " 0.04904656557521724,\n",
              " 0.0600750040094176,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.02289123299859889,\n",
              " 0.032059002314239325,\n",
              " 0.136971060966722,\n",
              " 0,\n",
              " 0.1527792241622333,\n",
              " 0.16344408787936873,\n",
              " 0.11092391212325527,\n",
              " 0.17157759114988153,\n",
              " 0.19676957845364285,\n",
              " 0.1351784546437818,\n",
              " 0,\n",
              " 0.20188565009499074,\n",
              " 0.17337090002208985,\n",
              " 0.12747649904676595,\n",
              " 0.1392171890255045,\n",
              " 0.2373852223521208,\n",
              " 0.1693940974818617,\n",
              " 0.21326331043331861,\n",
              " 0.0606656140042126,\n",
              " 0.1448218423116438,\n",
              " 0.2040387795710677,\n",
              " 0.13308628443305345,\n",
              " 0.1898200612247087,\n",
              " 0.108771002767798,\n",
              " 0.3996711519171054,\n",
              " 0.33470780888993207,\n",
              " 0.35733655809967374,\n",
              " 0.3994809772096679,\n",
              " 0.3049658506167775,\n",
              " 0.30429008086954645,\n",
              " 0.3852552564080064,\n",
              " 0.3262698177672079,\n",
              " 0.3644222844160887,\n",
              " 0.34522420198779025,\n",
              " 0.4843726068748377,\n",
              " 0.4287100593127323,\n",
              " 0.32652442403892645,\n",
              " 0.28927143181279763,\n",
              " 0.2025452468576917,\n",
              " 0.15498910403237356,\n",
              " 0.23287852630784062,\n",
              " 0.19262967815285484,\n",
              " 0.16806380675633656,\n",
              " 0.18672757568942283,\n",
              " 0.13540967029331838,\n",
              " 0.15107286690139896,\n",
              " 0.0895189472083957,\n",
              " 0.041212309847683586,\n",
              " 0.18866764493205074,\n",
              " 0.1330311751190256,\n",
              " 0.15327879379754847,\n",
              " 0.0760127668636289,\n",
              " 0.10445296184654194,\n",
              " 0.021156205107232928,\n",
              " 0.15933250237525298,\n",
              " 0.15223255904382885,\n",
              " 0.09316688045945644,\n",
              " 0.0918358195016007,\n",
              " 0.04886973466716961,\n",
              " 0.04016065545668691,\n",
              " 0.07054118787187647,\n",
              " 0.12704165122375286,\n",
              " 0.10816935438855525,\n",
              " 0.1044848030354632,\n",
              " 0.1792936936242595,\n",
              " 0.26047273389040393,\n",
              " 0.22451374901695495,\n",
              " 0.2720973493961414,\n",
              " 0.20744341586085166,\n",
              " 0.12041684979998424,\n",
              " 0.10744057538023095,\n",
              " 0.1392615134466742,\n",
              " 0.26596552599291423,\n",
              " 0.1885374938479659,\n",
              " 0.13456279579359595,\n",
              " 0.23930612159543885,\n",
              " 0.14938096274405505,\n",
              " 0.2590853140753387,\n",
              " 0.22371829805110094,\n",
              " 0.2586775711148567,\n",
              " 0.21812545565470526,\n",
              " 0.26772658785960135,\n",
              " 0.2140115008934133,\n",
              " 0,\n",
              " 0.32957444039319567,\n",
              " 0.13647108051594628,\n",
              " 0.29881120352917795,\n",
              " 0.22652317845874773,\n",
              " 0.2736811032119613,\n",
              " 0.12925645091842405,\n",
              " 0.23217769582948322,\n",
              " 0.2180879647405984,\n",
              " 0.168655693067228,\n",
              " 0.18734194787846772,\n",
              " 0.20588747285231324,\n",
              " 0.15221262899475288,\n",
              " 0.1862698236570314,\n",
              " 0.007141270959244626,\n",
              " 0.05987455501723872,\n",
              " 0.15630451599671122,\n",
              " 0.24457507156225547,\n",
              " 0.1848573649985902,\n",
              " 0.17990960371660386,\n",
              " 0.05615499426367996,\n",
              " 0.22386121470990744,\n",
              " 0.18845443224384711,\n",
              " 0.2110667667212954,\n",
              " 0.16013764715008066,\n",
              " 0.15007228627734398,\n",
              " 0.1981193749570404,\n",
              " 0.1181524361755492,\n",
              " 0.19685684106028092,\n",
              " 0.013261146205786266,\n",
              " 0.2004601289012157,\n",
              " 0.2741013262519318,\n",
              " 0.2306630498045766,\n",
              " 0.31059169499441586,\n",
              " 0.2706477171562839,\n",
              " 0.24434420862030154,\n",
              " 0.15821255846911406,\n",
              " 0.16800522920588273,\n",
              " 0.17252277578609312,\n",
              " 0.18888026728893328,\n",
              " 0.16105750822870238,\n",
              " 0.11687548668881272,\n",
              " 0.16978701644603145,\n",
              " 0.37506583494575824,\n",
              " 0.3153473195443715,\n",
              " 0.3908664511259766,\n",
              " 0.2650666632083369,\n",
              " 0.319108088996204,\n",
              " 0.33868268569349774,\n",
              " 0.3209728736146642,\n",
              " 0.2921965670682527,\n",
              " 0.2525060636161403,\n",
              " 0.32704582973123236,\n",
              " 0.28947696212661955,\n",
              " 0.18266414431842617,\n",
              " 0.10478219568035052,\n",
              " 0.1549008175388686,\n",
              " 0.14949146065341448,\n",
              " 0.2571425510739367,\n",
              " 0.1900093108221817,\n",
              " 0.2573449981244451,\n",
              " 0.18600686368507863,\n",
              " 0.1262035264652375,\n",
              " 0.14451796728261748,\n",
              " 0.07490625374159095,\n",
              " 0.06199649409033884,\n",
              " 0.20095606633239624,\n",
              " 0.1305343220492302,\n",
              " 0,\n",
              " 0.04262202245218019,\n",
              " 0.023830685780703225,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.16853130524870133,\n",
              " 0.09181633027140947,\n",
              " 0,\n",
              " 0.029826361969431323,\n",
              " 0.19631960233395557,\n",
              " 0.13229695613832199,\n",
              " 0.17897503571307152,\n",
              " 0.15512114941022837,\n",
              " 0.256159476111528,\n",
              " 0.12618671909422463,\n",
              " 0.17393510036891638,\n",
              " 0.3099456340090552,\n",
              " 0.2627057446505933,\n",
              " 0.2045673024744205,\n",
              " 0.017099253764300743,\n",
              " 0.25124051542328213,\n",
              " 0.14888230490190216,\n",
              " 0.33461720984960075,\n",
              " 0.3970665847975358,\n",
              " 0.3606337840368728,\n",
              " 0.3751244341870206,\n",
              " 0.40682183451849613,\n",
              " 0.39110305773947307,\n",
              " 0,\n",
              " 0.28632626846798115,\n",
              " 0.1629913127393043,\n",
              " 0.2914041850230918,\n",
              " 0.32003995208877933,\n",
              " 0.2657061306274703,\n",
              " 0.33356070860225623,\n",
              " 0.14228926535117703,\n",
              " 0.223482519393132,\n",
              " 0.19187490303067214,\n",
              " 0.2577965514440175,\n",
              " 0.25707096731283324,\n",
              " 0.23345024266956207,\n",
              " 0.1743178482049431,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.04599931792375348,\n",
              " 0.014897144585587755,\n",
              " 0.09134470436904216,\n",
              " 0.006330218535889241,\n",
              " 0.1994588484484248,\n",
              " 0.0926231607455419,\n",
              " 0.22106993535540165,\n",
              " 0.1641047021365051,\n",
              " 0.15795805042753028,\n",
              " 0.15066822677773503,\n",
              " 0.13476982560326226,\n",
              " 0.2103496047833255,\n",
              " 0,\n",
              " 0.1713318911346084,\n",
              " 0.17802854062519485,\n",
              " 0.15635632617927947,\n",
              " 0.20285817782428253,\n",
              " 0.21278697778789782,\n",
              " 0.28996666044216296,\n",
              " 0.34121582563198666,\n",
              " 0.2468284618691813,\n",
              " 0.27345067900381376,\n",
              " 0.3186380932947694,\n",
              " 0.260359817659871,\n",
              " 0.15328859675522266,\n",
              " 0.20280805928528778,\n",
              " 0.32720302270222196,\n",
              " 0.37488038826150355,\n",
              " 0.22564998404969905,\n",
              " 0.22055933516583504,\n",
              " 0.16671756308480623,\n",
              " 0.19345716759585052,\n",
              " 0.14372777120746003,\n",
              " 0.24001748236295764,\n",
              " 0.2595978485800601,\n",
              " 0.26494297630569724,\n",
              " 0.1576907642658029,\n",
              " 0.05747348207932388,\n",
              " 0.10972732865509204,\n",
              " 0.1406252657940032,\n",
              " 0.2714239977186839,\n",
              " 0.19978226680633523,\n",
              " 0.2784195872510473,\n",
              " 0.17432208628464388,\n",
              " 0.10743097167501324,\n",
              " 0.1819151852498766,\n",
              " 0.12170063765919684,\n",
              " 0.029031170956126798,\n",
              " 0.10858698824536507,\n",
              " 0.11405826514591151,\n",
              " 0.02117952922747168,\n",
              " 0,\n",
              " 0,\n",
              " 0.03267129928128023,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.1788213044039913,\n",
              " 0.13703437455096124,\n",
              " 0,\n",
              " 0,\n",
              " 0.19322646894569923,\n",
              " 0.12570736903011526,\n",
              " 0.08910426397100728,\n",
              " 0.06656218684027436,\n",
              " 0.07492407229458783,\n",
              " 0.0422479289626219,\n",
              " 0.03829632921822862,\n",
              " 0.21857369915990602,\n",
              " 0.1643180731416926,\n",
              " 0.24671236790491247,\n",
              " 0.006289383482123517,\n",
              " 0.18116281296353345,\n",
              " 0.04285041265798415,\n",
              " 0.369977258821289,\n",
              " 0.37031279344366547,\n",
              " 0.26766123414259524,\n",
              " 0.3772047006299193,\n",
              " 0.3602932836967591,\n",
              " 0.428898138219977,\n",
              " 0,\n",
              " 0.1306693030925999,\n",
              " 0.05876004035891862,\n",
              " 0.11255206913875618,\n",
              " 0.03999918390334514,\n",
              " 0.11974591829776599,\n",
              " 0.13481588025819208,\n",
              " 0.13299623941646144,\n",
              " 0.07135359586158348,\n",
              " 0.06677451622915061,\n",
              " 0.03746341133662793,\n",
              " 0.13028691924124633,\n",
              " 0.10052967762916164,\n",
              " 0.09195409773666838,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.1582397068281056,\n",
              " 0,\n",
              " 0.1639876426341884,\n",
              " 0.1032526894840412,\n",
              " 0.11002229973587248,\n",
              " 0.04871977378028584,\n",
              " 0.07986327565601153,\n",
              " 0.0989919054940146,\n",
              " 0,\n",
              " 0.19675537887814717,\n",
              " 0.1482242779362144,\n",
              " 0.1947220873334637,\n",
              " 0.09695323386636158,\n",
              " 0.13660940361501123,\n",
              " 0.27123699049580396,\n",
              " 0.19058045207655536,\n",
              " 0.13102208583488845,\n",
              " 0.13851804809782806,\n",
              " 0.2369912755412432,\n",
              " 0.1399355166965283,\n",
              " 0.17895401650240364,\n",
              " 0.228982784094557,\n",
              " 0.36431361532657647,\n",
              " 0.19714853645398958,\n",
              " 0.2809120337665317,\n",
              " 0.3084993625660489,\n",
              " 0.2321271151444684,\n",
              " 0.5231777037626293,\n",
              " 0.39069467046264084,\n",
              " 0.4218832712214486,\n",
              " 0.39631174077557446,\n",
              " 0.3868752369067933,\n",
              " 0.29882243812488357,\n",
              " 0.14878705308533896,\n",
              " 0.23180752082826175,\n",
              " 0.2877013503308229,\n",
              " 0.1634149554323344,\n",
              " 0.15569157440847223,\n",
              " 0.254100055127672,\n",
              " 0.08353489699268339,\n",
              " 0.14132307421394585,\n",
              " 0.09723500436296406,\n",
              " 0.13035399777311404,\n",
              " 0.10574453898757778,\n",
              " 0.2039858924301866,\n",
              " 0,\n",
              " 0,\n",
              " 0.08251486371124836,\n",
              " 0.040644151293455145,\n",
              " 0.016580972072445837,\n",
              " 0.09547610265040715,\n",
              " 0.09159345719544848,\n",
              " 0.1045449025094849,\n",
              " 0,\n",
              " 0.15004592174833883,\n",
              " 0.13673847204477244,\n",
              " 0.037137058578546975,\n",
              " 0.13390080637491558,\n",
              " 0,\n",
              " 0.10098114011793863,\n",
              " 0.2264888820952442,\n",
              " 0.1989628896530093,\n",
              " 0.26879589060805936,\n",
              " 0.0837838252772934,\n",
              " 0.1110326650075518,\n",
              " 0.04014667706154909,\n",
              " 0.08780481434382331,\n",
              " 0.17512321580976395,\n",
              " 0.12353634084137581,\n",
              " 0.05265202021200321,\n",
              " 0.14145956748773164,\n",
              " 0.03850882534915992,\n",
              " 0.2352282463885903,\n",
              " 0.2796381644059776,\n",
              " 0.11773881824434294,\n",
              " 0.15192007520728243,\n",
              " 0.2784396833954374,\n",
              " 0.2169369618863432,\n",
              " 0,\n",
              " 0.15673792094809902,\n",
              " 0.03552159244445098,\n",
              " 0.25236410474375726,\n",
              " 0.10793006879198574,\n",
              " 0.1906415482936263,\n",
              " 0.046026109806846564,\n",
              " 0.07142292144640408,\n",
              " 0.16082534712433577,\n",
              " 0.16898131925981963,\n",
              " 0.12342269293767263,\n",
              " 0.13820413518254762,\n",
              " 0.11163790073146336,\n",
              " 0.08372414930309753,\n",
              " 0.0020668934132078496,\n",
              " 0.07770742328033806,\n",
              " 0.09344112166358029,\n",
              " 0.1850982782359222,\n",
              " 0.10667239334784487,\n",
              " 0.17418721940237614,\n",
              " 0.11710206245612731,\n",
              " 0.21420123780743577,\n",
              " 0.17739544983502642,\n",
              " 0.20510128919482506,\n",
              " 0.16424581134119717,\n",
              " 0.10156021032779901,\n",
              " 0.06175427863981911,\n",
              " 0.02333042114176795,\n",
              " 0.050391729114783804,\n",
              " 0,\n",
              " 0.24512015440958393,\n",
              " 0.27953282439104127,\n",
              " 0.05709279446880268,\n",
              " 0.21107613426027022,\n",
              " 0.1714141290786623,\n",
              " 0.1646775707796297,\n",
              " 0.10246295436533805,\n",
              " 0.1486562951627826,\n",
              " 0.14824872461440233,\n",
              " 0.20697503871006093,\n",
              " 0.13773874087311924,\n",
              " 0.08943630384036859,\n",
              " 0.18326048562941158,\n",
              " 0.29909110604364236,\n",
              " 0.3454106459720376,\n",
              " 0.33412881958410484,\n",
              " 0.26157504396275655,\n",
              " 0.37647577639078933,\n",
              " 0.3128034523111878,\n",
              " 0.36951761467252364,\n",
              " 0.3888021322386076,\n",
              " 0.3488559908716265,\n",
              " 0.19739951944829107,\n",
              " 0.12265656853859959,\n",
              " 0.24048180101228733,\n",
              " 0.28030049758997816,\n",
              " 0.27113303823223694,\n",
              " 0.2632689411202211,\n",
              " 0.3065536250574133,\n",
              " 0.18246160283034193,\n",
              " 0.1843766005672747,\n",
              " 0.1511658891749659,\n",
              " 0.015568853170116042,\n",
              " 0.23435980962764244,\n",
              " 0.14302805566302237,\n",
              " 0.10318512776418377,\n",
              " 0.01613589197780535,\n",
              " 0.12020879702180942,\n",
              " 0.03386703906504294,\n",
              " 0.04420729864021109,\n",
              " 0.10557301339756818,\n",
              " 0.069411558391224,\n",
              " 0.07927628822163155,\n",
              " 0.06751894504532253,\n",
              " 0.045282815570606504,\n",
              " 0.14421358060820696,\n",
              " 0.09128380686943294,\n",
              " 0.14168006007446873,\n",
              " 0.05159097068002175,\n",
              " 0.18479081680178142,\n",
              " 0.2620699336881667,\n",
              " 0.23514950727894882,\n",
              " 0.2680546596216492,\n",
              " 0.1657323312808129,\n",
              " 0.1591305203859025,\n",
              " 0.09816898465698594,\n",
              " 0.15402946071957488,\n",
              " 0.2249075641258043,\n",
              " 0.28667600940617755,\n",
              " 0.16833363034914026,\n",
              " 0.2577596265673555,\n",
              " 0.05705223723486479,\n",
              " 0.2863815153595785,\n",
              " 0.29637601383079426,\n",
              " 0.26082829277331876,\n",
              " 0.30421877761164146,\n",
              " 0.3086078247504414,\n",
              " 0.33822050187495295,\n",
              " 0,\n",
              " 0.2736500687889741,\n",
              " 0.11978785124383241,\n",
              " 0.2318730080447559,\n",
              " 0.24808299029757272,\n",
              " 0.330667597411475,\n",
              " 0.17971486426240765,\n",
              " 0.2209019771036408,\n",
              " 0.24049128490280441,\n",
              " 0.14294751403957096,\n",
              " 0.17022558246750888,\n",
              " 0.20152905088311474,\n",
              " 0.16960643734499495,\n",
              " 0.2062278049540014,\n",
              " 0,\n",
              " 0.09349122779298391,\n",
              " 0.10496961599081615,\n",
              " 0.1792255683127394,\n",
              " 0.07582757015980392,\n",
              " 0.2015590772961158,\n",
              " 0.04215042004550607,\n",
              " 0.302196266532457,\n",
              " 0.09375386341813151,\n",
              " 0.227903365951514,\n",
              " 0.15090873111195635,\n",
              " 0.21787601584093533,\n",
              " 0.059173675767702445,\n",
              " 0.12098026758615371,\n",
              " 0.12697661342672703,\n",
              " 0.002481691730876569,\n",
              " 0.2843397013736661,\n",
              " 0.2719834713814421,\n",
              " 0.23216109746891647,\n",
              " 0.2618512642820337,\n",
              " 0.21481258001189302,\n",
              " 0.2837629063474945,\n",
              " 0.2805578933358064,\n",
              " 0.24033839257230072,\n",
              " 0.2062749395859751,\n",
              " 0.273009794304269,\n",
              " 0.21334431557209896,\n",
              " 0.1797596777552423,\n",
              " 0.23519498095196414,\n",
              " 0.3638906274856045,\n",
              " 0.26655496070482904,\n",
              " 0.2031443715654928,\n",
              " 0.2727318579345151,\n",
              " 0.2693583882221434,\n",
              " 0.3315307164275542,\n",
              " 0.3364235471242058,\n",
              " 0.2640144143436809,\n",
              " 0.26258839086368463,\n",
              " 0.1635103562729542,\n",
              " 0.05792826711659906,\n",
              " 0.25033839311226186,\n",
              " 0.212085044224693,\n",
              " 0.1538080384234568,\n",
              " 0.09692060035114496,\n",
              " 0.20761956228748216,\n",
              " 0.11622732658399582,\n",
              " 0.09800972657258152,\n",
              " 0.0786177085243558,\n",
              " 0.0430409250854013,\n",
              " 0.18423797481174117,\n",
              " 0.18421551807335157,\n",
              " 0.10594780323400425,\n",
              " 0.1253472313570272,\n",
              " 0.14074296698495553,\n",
              " 0.10620954087110379,\n",
              " 0.25252817725881455,\n",
              " 0.0643302076746475,\n",
              " 0.15186495189276078,\n",
              " 0.08656391354214843,\n",
              " 0.10568443767556243,\n",
              " 0.10727888798097945,\n",
              " 0.0383810384472538,\n",
              " 0.10848428595179556,\n",
              " 0.1448730304543317,\n",
              " 0.21028425397358083,\n",
              " 0.17955461503860493,\n",
              " 0.18159842376406873,\n",
              " 0.1403878639746893,\n",
              " 0.1638148614712224,\n",
              " 0.17575248157993037,\n",
              " 0.14456382201194962,\n",
              " 0.22212390884771635,\n",
              " 0.16100842903481338,\n",
              " 0.15747411958123964,\n",
              " 0.07615903935700045,\n",
              " 0.16662953917588788,\n",
              " 0.10137010666980957,\n",
              " 0.19540819420321343,\n",
              " 0.24659478040697413,\n",
              " 0.17604392043859998,\n",
              " 0.21650733156277044,\n",
              " 0.2060063015966813,\n",
              " 0.1918882397973689,\n",
              " 0.03251077605488815,\n",
              " 0.1107009609584841,\n",
              " 0.16247070765381413,\n",
              " 0.08801249009013119,\n",
              " 0.10626112211227873,\n",
              " 0.15764992387655213,\n",
              " 0.1600586038006205,\n",
              " 0.13908312039162177,\n",
              " 0.14978892178828476,\n",
              " 0.051492467614298036,\n",
              " 0.09122177409768345,\n",
              " 0.14819625611374526,\n",
              " 0.09543892118857915,\n",
              " 0.16292894638238123,\n",
              " 0.07219254700400782,\n",
              " 0.12206599528982037,\n",
              " 0.08815323958831389,\n",
              " 0.12561297298342017,\n",
              " 0.122380681486771,\n",
              " 0.19284465864770867,\n",
              " 0.16989464154731107,\n",
              " 0.20513972314845844,\n",
              " 0.05073550455664179,\n",
              " 0.3019302653306926,\n",
              " 0.16948287686409058,\n",
              " 0.18196586219776753,\n",
              " 0.1611782138233348,\n",
              " 0.13403884451905493,\n",
              " 0.18608596962327967,\n",
              " 0.11386952212780102,\n",
              " 0.2307960220537163,\n",
              " 0.28139720215101366,\n",
              " 0.2761154544698594,\n",
              " 0.16214240209217026,\n",
              " 0.31512387920014706,\n",
              " 0.16917245991836743,\n",
              " 0.16058918395342406,\n",
              " 0.2227978305048207,\n",
              " 0.21775798890389858,\n",
              " 0.2794734384270587,\n",
              " 0.1893071179324148,\n",
              " 0.19726437997159765,\n",
              " 0.20542486228133866,\n",
              " 0.3624704110907744,\n",
              " 0.2553795173284647,\n",
              " 0.39815340788148473,\n",
              " 0.34632821192697544,\n",
              " 0.363766206366048,\n",
              " 0.36701275012281687,\n",
              " 0.27206941173787347,\n",
              " 0.31917858429850593,\n",
              " 0.15514532808341067,\n",
              " 0.12116598518809836,\n",
              " 0.2952017746167599,\n",
              " 0.2479357117420722,\n",
              " 0.2102039333219219,\n",
              " 0.14803697325059942,\n",
              " 0.15612073753398484,\n",
              " 0.08246817140409218,\n",
              " 0.1224031704361036,\n",
              " 0.11845735106568969,\n",
              " 0.1565942349175912,\n",
              " 0.2298509792322817,\n",
              " 0.11951215856913792,\n",
              " 0.1092963705429846,\n",
              " 0.11394740147872082,\n",
              " 0.1302934903736792,\n",
              " 0.16977681237816228,\n",
              " 0.1906955352533319,\n",
              " 0.1267060882493794,\n",
              " 0.15203867858768758,\n",
              " 0.08013802731296522,\n",
              " 0.12933561611546382,\n",
              " 0.161957086048901,\n",
              " 0.12905128080072575,\n",
              " 0.07753484545105797,\n",
              " 0.08778653322738046,\n",
              " 0.25590320918106924,\n",
              " 0.26276097196081133,\n",
              " 0.132998610980152,\n",
              " 0.19427313409509953,\n",
              " 0.20034389562815355,\n",
              " 0.1654394911964129,\n",
              " 0.1156950857284266,\n",
              " 0.1856510025437059,\n",
              " 0.29865888236747345,\n",
              " 0.21829597272897602,\n",
              " 0.12221675708995186,\n",
              " 0.1746684746897532,\n",
              " 0.128872803973364,\n",
              " 0.17866185881369753,\n",
              " 0.24941308306961826,\n",
              " 0.24357198653631237,\n",
              " 0.23110625816209385,\n",
              " 0.25155671893850184,\n",
              " 0.2928649949701404,\n",
              " 0,\n",
              " 0.17100966363531742,\n",
              " 0.18240998322389762,\n",
              " 0.1852755709353506,\n",
              " 0.22505905078895533,\n",
              " 0.25478407381457613,\n",
              " 0.18052743330143448,\n",
              " 0.20360183825203618,\n",
              " 0.1620566383425952,\n",
              " 0.08078321091084939,\n",
              " 0.14787113768557894,\n",
              " 0.1729862656335431,\n",
              " 0.12765794484099077,\n",
              " 0.1925994323568508,\n",
              " 0.06128075988042883,\n",
              " 0.16566838903216008,\n",
              " 0.09169569556749425,\n",
              " 0.23910664017830366,\n",
              " 0.17210720660521298,\n",
              " 0.27519214443780665,\n",
              " 0.1403714305401883,\n",
              " 0.22627395088297658,\n",
              " 0.130125884399586,\n",
              " 0.3069912419991953,\n",
              " 0.2794118904790242,\n",
              " 0.2632922831152641,\n",
              " 0.22940214072256598,\n",
              " 0.15888607697809096,\n",
              " 0.1824181733005638,\n",
              " 0.029260968969715924,\n",
              " 0.33488626818844563,\n",
              " 0.3077682232204528,\n",
              " 0.27000659913948305,\n",
              " 0.2529095290756917,\n",
              " 0.29708330854484793,\n",
              " 0.26883832907784905,\n",
              " 0.2229488500029324,\n",
              " 0.24226543997543062,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Edge_Data"
      ],
      "metadata": {
        "id": "gEhjcqG4_p2s",
        "outputId": "5c985edb-f405-4aee-bbdf-1b239590f635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "id": "gEhjcqG4_p2s",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Src Ids                                       Src_features  \\\n",
              "0            0  [-0.0719492961094098, -0.0098550092394312, -0....   \n",
              "1            0  [-0.1113884014991687, -0.0305490317733903, -0....   \n",
              "2            0  [-0.0674515801828772, -0.0406402310057144, -0....   \n",
              "3            0  [0.0447749842340791, -0.1003485770592565, 0.06...   \n",
              "4            0  [-0.0520437549067927, 0.0153562638969604, 0.00...   \n",
              "...        ...                                                ...   \n",
              "11231      105  [-0.017528796813097, -0.0164241249391789, -0.0...   \n",
              "11232      105  [-0.0783018778650633, 0.0362304355279775, -0.0...   \n",
              "11233      105  [-0.0594293215168405, -0.0006251063901419, -0....   \n",
              "11234      105  [-0.0735475643784465, -0.0545094212113112, -0....   \n",
              "11235      105  [-0.0802201613489217, 0.0501088253545781, -0.0...   \n",
              "\n",
              "                                            Dst_features  Dst Ids  \\\n",
              "0      [-0.0719492961094098, -0.0098550092394312, -0....        0   \n",
              "1      [-0.0719492961094098, -0.0098550092394312, -0....        1   \n",
              "2      [-0.0719492961094098, -0.0098550092394312, -0....        2   \n",
              "3      [-0.0719492961094098, -0.0098550092394312, -0....        3   \n",
              "4      [-0.0719492961094098, -0.0098550092394312, -0....        4   \n",
              "...                                                  ...      ...   \n",
              "11231  [-0.0802201613489217, 0.0501088253545781, -0.0...      101   \n",
              "11232  [-0.0802201613489217, 0.0501088253545781, -0.0...      102   \n",
              "11233  [-0.0802201613489217, 0.0501088253545781, -0.0...      103   \n",
              "11234  [-0.0802201613489217, 0.0501088253545781, -0.0...      104   \n",
              "11235  [-0.0802201613489217, 0.0501088253545781, -0.0...      105   \n",
              "\n",
              "       edge weights  \n",
              "0          1.000000  \n",
              "1          0.369335  \n",
              "2          0.201881  \n",
              "3          0.339160  \n",
              "4          0.330372  \n",
              "...             ...  \n",
              "11231      0.260843  \n",
              "11232      0.271235  \n",
              "11233      0.318002  \n",
              "11234      0.237736  \n",
              "11235      1.000000  \n",
              "\n",
              "[11236 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0590d56f-ea95-4231-8a6c-81296a9d72dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Src Ids</th>\n",
              "      <th>Src_features</th>\n",
              "      <th>Dst_features</th>\n",
              "      <th>Dst Ids</th>\n",
              "      <th>edge weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>1</td>\n",
              "      <td>0.369335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[-0.0674515801828772, -0.0406402310057144, -0....</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>2</td>\n",
              "      <td>0.201881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[0.0447749842340791, -0.1003485770592565, 0.06...</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>3</td>\n",
              "      <td>0.339160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[-0.0520437549067927, 0.0153562638969604, 0.00...</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>4</td>\n",
              "      <td>0.330372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11231</th>\n",
              "      <td>105</td>\n",
              "      <td>[-0.017528796813097, -0.0164241249391789, -0.0...</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>101</td>\n",
              "      <td>0.260843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11232</th>\n",
              "      <td>105</td>\n",
              "      <td>[-0.0783018778650633, 0.0362304355279775, -0.0...</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>102</td>\n",
              "      <td>0.271235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11233</th>\n",
              "      <td>105</td>\n",
              "      <td>[-0.0594293215168405, -0.0006251063901419, -0....</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>103</td>\n",
              "      <td>0.318002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11234</th>\n",
              "      <td>105</td>\n",
              "      <td>[-0.0735475643784465, -0.0545094212113112, -0....</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>104</td>\n",
              "      <td>0.237736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11235</th>\n",
              "      <td>105</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>105</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11236 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0590d56f-ea95-4231-8a6c-81296a9d72dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0590d56f-ea95-4231-8a6c-81296a9d72dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0590d56f-ea95-4231-8a6c-81296a9d72dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c929bfc5-d628-470e-a329-4e75b8e5925b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c929bfc5-d628-470e-a329-4e75b8e5925b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c929bfc5-d628-470e-a329-4e75b8e5925b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ef7060d5-2446-4572-bb93-fa7f5fee4c9c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Edge_Data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ef7060d5-2446-4572-bb93-fa7f5fee4c9c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Edge_Data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Edge_Data",
              "summary": "{\n  \"name\": \"Edge_Data\",\n  \"rows\": 11236,\n  \"fields\": [\n    {\n      \"column\": \"Src Ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 0,\n        \"max\": 105,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          100,\n          10,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Src_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dst_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dst Ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 0,\n        \"max\": 105,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          100,\n          10,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"edge weights\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1569159180743469,\n        \"min\": -0.3884884366226571,\n        \"max\": 1.0000000000000002,\n        \"num_unique_values\": 5569,\n        \"samples\": [\n          -0.1954652876417654,\n          0.05705223723486479,\n          0.017099253764300743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Edge_Data[Edge_Data['Dst Ids']==7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "Z_tRiN8c7_Th",
        "outputId": "509cdf2f-8068-4287-ca1c-2dc76c4fb06d"
      },
      "id": "Z_tRiN8c7_Th",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Src Ids                                       Src_features  \\\n",
              "7            0  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "113          1  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "219          2  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "325          3  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "431          4  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "...        ...                                                ...   \n",
              "10713      101  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "10819      102  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "10925      103  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "11031      104  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "11137      105  [-0.0580753783854015, 0.0122518085993215, -0.0...   \n",
              "\n",
              "                                            Dst_features  Dst Ids  \\\n",
              "7      [-0.0719492961094098, -0.0098550092394312, -0....        7   \n",
              "113    [-0.1113884014991687, -0.0305490317733903, -0....        7   \n",
              "219    [-0.0674515801828772, -0.0406402310057144, -0....        7   \n",
              "325    [0.0447749842340791, -0.1003485770592565, 0.06...        7   \n",
              "431    [-0.0520437549067927, 0.0153562638969604, 0.00...        7   \n",
              "...                                                  ...      ...   \n",
              "10713  [-0.017528796813097, -0.0164241249391789, -0.0...        7   \n",
              "10819  [-0.0783018778650633, 0.0362304355279775, -0.0...        7   \n",
              "10925  [-0.0594293215168405, -0.0006251063901419, -0....        7   \n",
              "11031  [-0.0735475643784465, -0.0545094212113112, -0....        7   \n",
              "11137  [-0.0802201613489217, 0.0501088253545781, -0.0...        7   \n",
              "\n",
              "       edge weights  \n",
              "7          0.351146  \n",
              "113        0.434792  \n",
              "219        0.230430  \n",
              "325        0.399481  \n",
              "431        0.390866  \n",
              "...             ...  \n",
              "10713      0.206275  \n",
              "10819      0.273010  \n",
              "10925      0.213344  \n",
              "11031      0.179760  \n",
              "11137      0.235195  \n",
              "\n",
              "[106 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9423e41d-161c-4256-8b8c-2a1c759b3a3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Src Ids</th>\n",
              "      <th>Src_features</th>\n",
              "      <th>Dst_features</th>\n",
              "      <th>Dst Ids</th>\n",
              "      <th>edge weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>7</td>\n",
              "      <td>0.351146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>7</td>\n",
              "      <td>0.434792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>2</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.0674515801828772, -0.0406402310057144, -0....</td>\n",
              "      <td>7</td>\n",
              "      <td>0.230430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>3</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[0.0447749842340791, -0.1003485770592565, 0.06...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.399481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>4</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.0520437549067927, 0.0153562638969604, 0.00...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.390866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10713</th>\n",
              "      <td>101</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.017528796813097, -0.0164241249391789, -0.0...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.206275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10819</th>\n",
              "      <td>102</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.0783018778650633, 0.0362304355279775, -0.0...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.273010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10925</th>\n",
              "      <td>103</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.0594293215168405, -0.0006251063901419, -0....</td>\n",
              "      <td>7</td>\n",
              "      <td>0.213344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11031</th>\n",
              "      <td>104</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.0735475643784465, -0.0545094212113112, -0....</td>\n",
              "      <td>7</td>\n",
              "      <td>0.179760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11137</th>\n",
              "      <td>105</td>\n",
              "      <td>[-0.0580753783854015, 0.0122518085993215, -0.0...</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>7</td>\n",
              "      <td>0.235195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9423e41d-161c-4256-8b8c-2a1c759b3a3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9423e41d-161c-4256-8b8c-2a1c759b3a3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9423e41d-161c-4256-8b8c-2a1c759b3a3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f37224d5-bff4-4cad-a669-a2de14ae1cd4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f37224d5-bff4-4cad-a669-a2de14ae1cd4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f37224d5-bff4-4cad-a669-a2de14ae1cd4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"Edge_Data[Edge_Data['Dst Ids']==7]\",\n  \"rows\": 106,\n  \"fields\": [\n    {\n      \"column\": \"Src Ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 0,\n        \"max\": 105,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          100,\n          10,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Src_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dst_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dst Ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"edge weights\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13170406351361577,\n        \"min\": -0.07956294001348259,\n        \"max\": 1.0000000000000002,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          0.24033839257230072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ff=Edge_Data[Edge_Data['Src Ids']!=0 ]"
      ],
      "metadata": {
        "id": "0sIwXywH8aF6"
      },
      "id": "0sIwXywH8aF6",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ff[ff['edge weights']>=0.329]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "0tlrtE5p6UFZ",
        "outputId": "40b84858-bec2-4c1e-d958-7080776cf9a9"
      },
      "id": "0tlrtE5p6UFZ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Src Ids                                       Src_features  \\\n",
              "106          1  [-0.0719492961094098, -0.0098550092394312, -0....   \n",
              "107          1  [-0.1113884014991687, -0.0305490317733903, -0....   \n",
              "109          1  [0.0447749842340791, -0.1003485770592565, 0.06...   \n",
              "110          1  [-0.0520437549067927, 0.0153562638969604, 0.00...   \n",
              "112          1  [-0.0887158440769454, -0.0402365605867742, 0.0...   \n",
              "...        ...                                                ...   \n",
              "10873      102  [-0.0430803643110814, -0.0166002562708003, -0....   \n",
              "10914      102  [-0.0783018778650633, 0.0362304355279775, -0.0...   \n",
              "11021      103  [-0.0594293215168405, -0.0006251063901419, -0....   \n",
              "11128      104  [-0.0735475643784465, -0.0545094212113112, -0....   \n",
              "11235      105  [-0.0802201613489217, 0.0501088253545781, -0.0...   \n",
              "\n",
              "                                            Dst_features  Dst Ids  \\\n",
              "106    [-0.1113884014991687, -0.0305490317733903, -0....        0   \n",
              "107    [-0.1113884014991687, -0.0305490317733903, -0....        1   \n",
              "109    [-0.1113884014991687, -0.0305490317733903, -0....        3   \n",
              "110    [-0.1113884014991687, -0.0305490317733903, -0....        4   \n",
              "112    [-0.1113884014991687, -0.0305490317733903, -0....        6   \n",
              "...                                                  ...      ...   \n",
              "10873  [-0.0783018778650633, 0.0362304355279775, -0.0...       61   \n",
              "10914  [-0.0783018778650633, 0.0362304355279775, -0.0...      102   \n",
              "11021  [-0.0594293215168405, -0.0006251063901419, -0....      103   \n",
              "11128  [-0.0735475643784465, -0.0545094212113112, -0....      104   \n",
              "11235  [-0.0802201613489217, 0.0501088253545781, -0.0...      105   \n",
              "\n",
              "       edge weights  \n",
              "106        0.369335  \n",
              "107        1.000000  \n",
              "109        0.437186  \n",
              "110        0.425758  \n",
              "112        0.374404  \n",
              "...             ...  \n",
              "10873      0.357029  \n",
              "10914      1.000000  \n",
              "11021      1.000000  \n",
              "11128      1.000000  \n",
              "11235      1.000000  \n",
              "\n",
              "[956 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8e04e90-c55f-4bd5-9f3b-f5bb0b5a1374\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Src Ids</th>\n",
              "      <th>Src_features</th>\n",
              "      <th>Dst_features</th>\n",
              "      <th>Dst Ids</th>\n",
              "      <th>edge weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0719492961094098, -0.0098550092394312, -0....</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>0</td>\n",
              "      <td>0.369335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>1</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.0447749842340791, -0.1003485770592565, 0.06...</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>3</td>\n",
              "      <td>0.437186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0520437549067927, 0.0153562638969604, 0.00...</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>4</td>\n",
              "      <td>0.425758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>1</td>\n",
              "      <td>[-0.0887158440769454, -0.0402365605867742, 0.0...</td>\n",
              "      <td>[-0.1113884014991687, -0.0305490317733903, -0....</td>\n",
              "      <td>6</td>\n",
              "      <td>0.374404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10873</th>\n",
              "      <td>102</td>\n",
              "      <td>[-0.0430803643110814, -0.0166002562708003, -0....</td>\n",
              "      <td>[-0.0783018778650633, 0.0362304355279775, -0.0...</td>\n",
              "      <td>61</td>\n",
              "      <td>0.357029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10914</th>\n",
              "      <td>102</td>\n",
              "      <td>[-0.0783018778650633, 0.0362304355279775, -0.0...</td>\n",
              "      <td>[-0.0783018778650633, 0.0362304355279775, -0.0...</td>\n",
              "      <td>102</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11021</th>\n",
              "      <td>103</td>\n",
              "      <td>[-0.0594293215168405, -0.0006251063901419, -0....</td>\n",
              "      <td>[-0.0594293215168405, -0.0006251063901419, -0....</td>\n",
              "      <td>103</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11128</th>\n",
              "      <td>104</td>\n",
              "      <td>[-0.0735475643784465, -0.0545094212113112, -0....</td>\n",
              "      <td>[-0.0735475643784465, -0.0545094212113112, -0....</td>\n",
              "      <td>104</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11235</th>\n",
              "      <td>105</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>[-0.0802201613489217, 0.0501088253545781, -0.0...</td>\n",
              "      <td>105</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>956 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8e04e90-c55f-4bd5-9f3b-f5bb0b5a1374')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8e04e90-c55f-4bd5-9f3b-f5bb0b5a1374 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8e04e90-c55f-4bd5-9f3b-f5bb0b5a1374');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-460ee121-ccfc-4333-9c9b-fae6255f59eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-460ee121-ccfc-4333-9c9b-fae6255f59eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-460ee121-ccfc-4333-9c9b-fae6255f59eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"ff[ff['edge weights']>=0\",\n  \"rows\": 956,\n  \"fields\": [\n    {\n      \"column\": \"Src Ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 1,\n        \"max\": 105,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          31,\n          66,\n          65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Src_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dst_features\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dst Ids\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 0,\n        \"max\": 105,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          91,\n          57,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"edge weights\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2035640660361457,\n        \"min\": 0.329002636795828,\n        \"max\": 1.0000000000000002,\n        \"num_unique_values\": 435,\n        \"samples\": [\n          0.5082457948168996,\n          0.35326024755640806,\n          0.3834714903585712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "beb96876-26f6-4e13-9109-12ac34c05812",
      "metadata": {
        "id": "beb96876-26f6-4e13-9109-12ac34c05812",
        "outputId": "9e121256-1805-4c43-977d-a66730788c59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    5565.000000\n",
            "mean        0.164894\n",
            "std         0.117433\n",
            "min         0.000000\n",
            "25%         0.085131\n",
            "50%         0.154901\n",
            "75%         0.225553\n",
            "max         0.871968\n",
            "Name: edge weights, dtype: float64\n",
            "95th percentile of edge weights column: 0.371543188964312\n"
          ]
        }
      ],
      "source": [
        "print(Edge['edge weights'].describe())\n",
        "ninetyfive_percentile = Edge['edge weights'].quantile(0.95)\n",
        "print(\"95th percentile of edge weights column:\", ninetyfive_percentile)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentiles=[round(0.154901,4),round(0.225553,4),round(0.371543188964312,4)]"
      ],
      "metadata": {
        "id": "Nmm7y74Lw_l_"
      },
      "id": "Nmm7y74Lw_l_",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample list of values\n",
        "\n",
        "# Calculate the 25th, 75th, and 95th percentiles\n",
        "percentiles = np.percentile(edge_weight, [25, 75, 95])\n",
        "percentile_labels = ['25th Percentile', '75th Percentile', '95th Percentile']\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(edge_weight, marker='o', linestyle='-', color='b', label='Data')\n",
        "\n",
        "# Mark the percentiles\n",
        "for i, perc in enumerate(percentiles):\n",
        "    plt.axhline(y=perc, color='r', linestyle='--')\n",
        "    plt.text(0, perc, f'{percentile_labels[i]}: {perc}', color='r', ha='right', va='bottom')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Data with 25th, 75th, and 95th Percentiles')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "G_rZrPZmt7QT",
        "outputId": "ed5442bc-185e-4c36-9c5b-4736c59cc3c9"
      },
      "id": "G_rZrPZmt7QT",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b8WbybKvw-Ew",
        "outputId": "bd9fb03d-c826-4c80-c47d-d7bbe3415f6e"
      },
      "id": "b8WbybKvw-Ew",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36933451923159044,\n",
              " 0.20188085075614823,\n",
              " 0.3391602067413753,\n",
              " 0.33037234503148327,\n",
              " 0.28229449927787037,\n",
              " 0.2875550201552659,\n",
              " 0.3511457016292417,\n",
              " 0.15215096049729687,\n",
              " 0.21189518293583792,\n",
              " 0.2854512993188685,\n",
              " 0.29565122913257996,\n",
              " 0.2558674276695262,\n",
              " 0.22130218869690407,\n",
              " 0.256761685113677,\n",
              " 0.22798070244793756,\n",
              " 0.13281087841787662,\n",
              " 0.09945622042315554,\n",
              " 0.07545900840395076,\n",
              " 0.16481297119925792,\n",
              " 0.2596408610691616,\n",
              " 0.1580320203962707,\n",
              " 0.22388388409340335,\n",
              " 0.1484426518829608,\n",
              " 0.0474646875399311,\n",
              " 0.07089522129913126,\n",
              " 0.051223797586399375,\n",
              " 0,\n",
              " 0.18388251646053883,\n",
              " 0.05588608269881084,\n",
              " 0.047746833467733674,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.17223772996179118,\n",
              " 0.022635868021772625,\n",
              " 0.046732687991621315,\n",
              " 0.0416183635583747,\n",
              " 0.1127354388838679,\n",
              " 0.08695977112626554,\n",
              " 0.1909792269673502,\n",
              " 0.11452951454739105,\n",
              " 0.10165351995877141,\n",
              " 0.13902229735716137,\n",
              " 0.050898828152738995,\n",
              " 0.2505215459049555,\n",
              " 0.2005614800450569,\n",
              " 0.21775836091732595,\n",
              " 0.09671464913845769,\n",
              " 0.276942776324164,\n",
              " 0.12359984937630517,\n",
              " 0.5061031246201846,\n",
              " 0.38810425584480795,\n",
              " 0.4217830913121329,\n",
              " 0.3861949803948578,\n",
              " 0.4295259634182974,\n",
              " 0.3969251478228268,\n",
              " 0,\n",
              " 0.2803362063448537,\n",
              " 0.10020550020153564,\n",
              " 0.13823528099461616,\n",
              " 0.08482970307405183,\n",
              " 0.19703735134095998,\n",
              " 0.28544250552399897,\n",
              " 0.1874169742646031,\n",
              " 0.26875938259401705,\n",
              " 0.15189128906725763,\n",
              " 0.14168068468859268,\n",
              " 0.17999670063740483,\n",
              " 0.182219474736803,\n",
              " 0.13163448380514303,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.18003546245678761,\n",
              " 0.0991576612274388,\n",
              " 0.27107916886836103,\n",
              " 0.11621717297912389,\n",
              " 0.16928415748272932,\n",
              " 0.06364375110284656,\n",
              " 0.1390919479572665,\n",
              " 0.1516482231098321,\n",
              " 0,\n",
              " 0.17537767677938923,\n",
              " 0.17151867368473775,\n",
              " 0.17954573438677018,\n",
              " 0.12376124484078548,\n",
              " 0.1936426236778649,\n",
              " 0.1815708163165289,\n",
              " 0.21280845695675854,\n",
              " 0.2810426746458225,\n",
              " 0.28622547263820397,\n",
              " 0.35616134241866165,\n",
              " 0.22283927387404237,\n",
              " 0.12813081134257165,\n",
              " 0.26688041181306654,\n",
              " 0.2772453524727999,\n",
              " 0.4371857314621728,\n",
              " 0.42575767623328703,\n",
              " 0.31428853463690365,\n",
              " 0.37440442379075867,\n",
              " 0.4347916635369329,\n",
              " 0.24005785921796768,\n",
              " 0.3142097709011973,\n",
              " 0.30138155378293313,\n",
              " 0.3334887285660895,\n",
              " 0.31226616323142387,\n",
              " 0.42551250796418,\n",
              " 0.41915127364895716,\n",
              " 0.404467396943856,\n",
              " 0.31290005457895814,\n",
              " 0.12559179246062901,\n",
              " 0.17010107655114112,\n",
              " 0.18977619573658863,\n",
              " 0.2344143893874898,\n",
              " 0.23872429538869144,\n",
              " 0.2025597901559338,\n",
              " 0.2017025011610135,\n",
              " 0.21478625928197734,\n",
              " 0.12936466712690542,\n",
              " 0.09750554547106875,\n",
              " 0.042394402608373905,\n",
              " 0.24864053364576913,\n",
              " 0.18165343779326565,\n",
              " 0.03329968781106375,\n",
              " 0.018147160205489805,\n",
              " 0.05128611699568195,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.20912851687116613,\n",
              " 0.05117209004441645,\n",
              " 0.07921330918177376,\n",
              " 0.036695875274070346,\n",
              " 0.11861447446311953,\n",
              " 0.2225699025523209,\n",
              " 0.2148273799091378,\n",
              " 0.22724957752688738,\n",
              " 0.1481528031775979,\n",
              " 0.10847554410335523,\n",
              " 0.15655860627195897,\n",
              " 0.20558579392899667,\n",
              " 0.18454598254341445,\n",
              " 0.21609753335204826,\n",
              " 0.07751216926668945,\n",
              " 0.26976543736314357,\n",
              " 0.16856302840756948,\n",
              " 0.3448406918543226,\n",
              " 0.3777960488195334,\n",
              " 0.3424690869767335,\n",
              " 0.41487931653204113,\n",
              " 0.39191469095140996,\n",
              " 0.4240543129810886,\n",
              " 0,\n",
              " 0.22772113433396107,\n",
              " 0.0403869758722212,\n",
              " 0.2551474195799983,\n",
              " 0.26484045594747296,\n",
              " 0.30590695057339923,\n",
              " 0.22380153133076525,\n",
              " 0.22577809980448416,\n",
              " 0.3003622106650139,\n",
              " 0.14962667321991344,\n",
              " 0.1323087415449487,\n",
              " 0.20977694452654136,\n",
              " 0.17734075388067982,\n",
              " 0.20275022067444742,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.05883197418772642,\n",
              " 0.062289742274512214,\n",
              " 0.059092504966558726,\n",
              " 0.03434667931734048,\n",
              " 0.315489621256072,\n",
              " 0.1158105252209395,\n",
              " 0.26363986439020193,\n",
              " 0.1201712580779688,\n",
              " 0.17666163904854745,\n",
              " 0.17436557903279598,\n",
              " 0.09938180460117242,\n",
              " 0.20084080801546508,\n",
              " 0,\n",
              " 0.31220968685125267,\n",
              " 0.24939629857353318,\n",
              " 0.22141783358672842,\n",
              " 0.2596885242068282,\n",
              " 0.1406505657386059,\n",
              " 0.31620280316537247,\n",
              " 0.25363434022305104,\n",
              " 0.24999566243848367,\n",
              " 0.25162160080287965,\n",
              " 0.30984468682628175,\n",
              " 0.23002919658127188,\n",
              " 0.24533116447394948,\n",
              " 0.26685597041983156,\n",
              " 0.2222587619269603,\n",
              " 0.30156109393796005,\n",
              " 0.3765769627081978,\n",
              " 0.2239624409129347,\n",
              " 0.2304303913200124,\n",
              " 0.18351890469511264,\n",
              " 0.2531813207518232,\n",
              " 0.05763350950577085,\n",
              " 0.22895638469393764,\n",
              " 0.18343228028350442,\n",
              " 0.0944365145288439,\n",
              " 0.1938827075320135,\n",
              " 0.19633775819407548,\n",
              " 0.10806159080994066,\n",
              " 0,\n",
              " 0.10768496885588595,\n",
              " 0.11900663738503944,\n",
              " 0.1603992490435124,\n",
              " 0.12459883243848764,\n",
              " 0.21293265267377104,\n",
              " 0.1592383955677921,\n",
              " 0.10326100871777788,\n",
              " 0.11753628313197541,\n",
              " 0.08923246914716228,\n",
              " 0.019045734021930036,\n",
              " 0.11676012671907793,\n",
              " 0.16345381552850832,\n",
              " 0,\n",
              " 0.0013305147463347883,\n",
              " 0.005970560269792654,\n",
              " 0.0760961439081718,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.21094919918824107,\n",
              " 0.14125495282041903,\n",
              " 0.03326938448475515,\n",
              " 0.0015285062131322213,\n",
              " 0.22762603890953834,\n",
              " 0.1531738802373138,\n",
              " 0.14755021410977107,\n",
              " 0.04674996969528097,\n",
              " 0.14030789258751422,\n",
              " 0.0473430903426496,\n",
              " 0.11959090212851367,\n",
              " 0.14481989519646926,\n",
              " 0,\n",
              " 0.2648159868221164,\n",
              " 0,\n",
              " 0.1768012917260456,\n",
              " 0.1345588320593072,\n",
              " 0.29960069202141204,\n",
              " 0.3521930872762381,\n",
              " 0.2462726822974652,\n",
              " 0.3618182796862917,\n",
              " 0.3576341554103438,\n",
              " 0.3879758721228795,\n",
              " 0,\n",
              " 0.05837284247936198,\n",
              " 0.1075092935239342,\n",
              " 0.0420453250405186,\n",
              " 0.08973611231858533,\n",
              " 0.10922448373101656,\n",
              " 0.11498076682578615,\n",
              " 0.06933866014118917,\n",
              " 0.08586538303682655,\n",
              " 0.0091292487432711,\n",
              " 0.03171151043276403,\n",
              " 0.09752348511156346,\n",
              " 0.04904656557521724,\n",
              " 0.0600750040094176,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.02289123299859889,\n",
              " 0.032059002314239325,\n",
              " 0.136971060966722,\n",
              " 0,\n",
              " 0.1527792241622333,\n",
              " 0.16344408787936873,\n",
              " 0.11092391212325527,\n",
              " 0.17157759114988153,\n",
              " 0.19676957845364285,\n",
              " 0.1351784546437818,\n",
              " 0,\n",
              " 0.20188565009499074,\n",
              " 0.17337090002208985,\n",
              " 0.12747649904676595,\n",
              " 0.1392171890255045,\n",
              " 0.2373852223521208,\n",
              " 0.1693940974818617,\n",
              " 0.21326331043331861,\n",
              " 0.0606656140042126,\n",
              " 0.1448218423116438,\n",
              " 0.2040387795710677,\n",
              " 0.13308628443305345,\n",
              " 0.1898200612247087,\n",
              " 0.108771002767798,\n",
              " 0.3996711519171054,\n",
              " 0.33470780888993207,\n",
              " 0.35733655809967374,\n",
              " 0.3994809772096679,\n",
              " 0.3049658506167775,\n",
              " 0.30429008086954645,\n",
              " 0.3852552564080064,\n",
              " 0.3262698177672079,\n",
              " 0.3644222844160887,\n",
              " 0.34522420198779025,\n",
              " 0.4843726068748377,\n",
              " 0.4287100593127323,\n",
              " 0.32652442403892645,\n",
              " 0.28927143181279763,\n",
              " 0.2025452468576917,\n",
              " 0.15498910403237356,\n",
              " 0.23287852630784062,\n",
              " 0.19262967815285484,\n",
              " 0.16806380675633656,\n",
              " 0.18672757568942283,\n",
              " 0.13540967029331838,\n",
              " 0.15107286690139896,\n",
              " 0.0895189472083957,\n",
              " 0.041212309847683586,\n",
              " 0.18866764493205074,\n",
              " 0.1330311751190256,\n",
              " 0.15327879379754847,\n",
              " 0.0760127668636289,\n",
              " 0.10445296184654194,\n",
              " 0.021156205107232928,\n",
              " 0.15933250237525298,\n",
              " 0.15223255904382885,\n",
              " 0.09316688045945644,\n",
              " 0.0918358195016007,\n",
              " 0.04886973466716961,\n",
              " 0.04016065545668691,\n",
              " 0.07054118787187647,\n",
              " 0.12704165122375286,\n",
              " 0.10816935438855525,\n",
              " 0.1044848030354632,\n",
              " 0.1792936936242595,\n",
              " 0.26047273389040393,\n",
              " 0.22451374901695495,\n",
              " 0.2720973493961414,\n",
              " 0.20744341586085166,\n",
              " 0.12041684979998424,\n",
              " 0.10744057538023095,\n",
              " 0.1392615134466742,\n",
              " 0.26596552599291423,\n",
              " 0.1885374938479659,\n",
              " 0.13456279579359595,\n",
              " 0.23930612159543885,\n",
              " 0.14938096274405505,\n",
              " 0.2590853140753387,\n",
              " 0.22371829805110094,\n",
              " 0.2586775711148567,\n",
              " 0.21812545565470526,\n",
              " 0.26772658785960135,\n",
              " 0.2140115008934133,\n",
              " 0,\n",
              " 0.32957444039319567,\n",
              " 0.13647108051594628,\n",
              " 0.29881120352917795,\n",
              " 0.22652317845874773,\n",
              " 0.2736811032119613,\n",
              " 0.12925645091842405,\n",
              " 0.23217769582948322,\n",
              " 0.2180879647405984,\n",
              " 0.168655693067228,\n",
              " 0.18734194787846772,\n",
              " 0.20588747285231324,\n",
              " 0.15221262899475288,\n",
              " 0.1862698236570314,\n",
              " 0.007141270959244626,\n",
              " 0.05987455501723872,\n",
              " 0.15630451599671122,\n",
              " 0.24457507156225547,\n",
              " 0.1848573649985902,\n",
              " 0.17990960371660386,\n",
              " 0.05615499426367996,\n",
              " 0.22386121470990744,\n",
              " 0.18845443224384711,\n",
              " 0.2110667667212954,\n",
              " 0.16013764715008066,\n",
              " 0.15007228627734398,\n",
              " 0.1981193749570404,\n",
              " 0.1181524361755492,\n",
              " 0.19685684106028092,\n",
              " 0.013261146205786266,\n",
              " 0.2004601289012157,\n",
              " 0.2741013262519318,\n",
              " 0.2306630498045766,\n",
              " 0.31059169499441586,\n",
              " 0.2706477171562839,\n",
              " 0.24434420862030154,\n",
              " 0.15821255846911406,\n",
              " 0.16800522920588273,\n",
              " 0.17252277578609312,\n",
              " 0.18888026728893328,\n",
              " 0.16105750822870238,\n",
              " 0.11687548668881272,\n",
              " 0.16978701644603145,\n",
              " 0.37506583494575824,\n",
              " 0.3153473195443715,\n",
              " 0.3908664511259766,\n",
              " 0.2650666632083369,\n",
              " 0.319108088996204,\n",
              " 0.33868268569349774,\n",
              " 0.3209728736146642,\n",
              " 0.2921965670682527,\n",
              " 0.2525060636161403,\n",
              " 0.32704582973123236,\n",
              " 0.28947696212661955,\n",
              " 0.18266414431842617,\n",
              " 0.10478219568035052,\n",
              " 0.1549008175388686,\n",
              " 0.14949146065341448,\n",
              " 0.2571425510739367,\n",
              " 0.1900093108221817,\n",
              " 0.2573449981244451,\n",
              " 0.18600686368507863,\n",
              " 0.1262035264652375,\n",
              " 0.14451796728261748,\n",
              " 0.07490625374159095,\n",
              " 0.06199649409033884,\n",
              " 0.20095606633239624,\n",
              " 0.1305343220492302,\n",
              " 0,\n",
              " 0.04262202245218019,\n",
              " 0.023830685780703225,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.16853130524870133,\n",
              " 0.09181633027140947,\n",
              " 0,\n",
              " 0.029826361969431323,\n",
              " 0.19631960233395557,\n",
              " 0.13229695613832199,\n",
              " 0.17897503571307152,\n",
              " 0.15512114941022837,\n",
              " 0.256159476111528,\n",
              " 0.12618671909422463,\n",
              " 0.17393510036891638,\n",
              " 0.3099456340090552,\n",
              " 0.2627057446505933,\n",
              " 0.2045673024744205,\n",
              " 0.017099253764300743,\n",
              " 0.25124051542328213,\n",
              " 0.14888230490190216,\n",
              " 0.33461720984960075,\n",
              " 0.3970665847975358,\n",
              " 0.3606337840368728,\n",
              " 0.3751244341870206,\n",
              " 0.40682183451849613,\n",
              " 0.39110305773947307,\n",
              " 0,\n",
              " 0.28632626846798115,\n",
              " 0.1629913127393043,\n",
              " 0.2914041850230918,\n",
              " 0.32003995208877933,\n",
              " 0.2657061306274703,\n",
              " 0.33356070860225623,\n",
              " 0.14228926535117703,\n",
              " 0.223482519393132,\n",
              " 0.19187490303067214,\n",
              " 0.2577965514440175,\n",
              " 0.25707096731283324,\n",
              " 0.23345024266956207,\n",
              " 0.1743178482049431,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.04599931792375348,\n",
              " 0.014897144585587755,\n",
              " 0.09134470436904216,\n",
              " 0.006330218535889241,\n",
              " 0.1994588484484248,\n",
              " 0.0926231607455419,\n",
              " 0.22106993535540165,\n",
              " 0.1641047021365051,\n",
              " 0.15795805042753028,\n",
              " 0.15066822677773503,\n",
              " 0.13476982560326226,\n",
              " 0.2103496047833255,\n",
              " 0,\n",
              " 0.1713318911346084,\n",
              " 0.17802854062519485,\n",
              " 0.15635632617927947,\n",
              " 0.20285817782428253,\n",
              " 0.21278697778789782,\n",
              " 0.28996666044216296,\n",
              " 0.34121582563198666,\n",
              " 0.2468284618691813,\n",
              " 0.27345067900381376,\n",
              " 0.3186380932947694,\n",
              " 0.260359817659871,\n",
              " 0.15328859675522266,\n",
              " 0.20280805928528778,\n",
              " 0.32720302270222196,\n",
              " 0.37488038826150355,\n",
              " 0.22564998404969905,\n",
              " 0.22055933516583504,\n",
              " 0.16671756308480623,\n",
              " 0.19345716759585052,\n",
              " 0.14372777120746003,\n",
              " 0.24001748236295764,\n",
              " 0.2595978485800601,\n",
              " 0.26494297630569724,\n",
              " 0.1576907642658029,\n",
              " 0.05747348207932388,\n",
              " 0.10972732865509204,\n",
              " 0.1406252657940032,\n",
              " 0.2714239977186839,\n",
              " 0.19978226680633523,\n",
              " 0.2784195872510473,\n",
              " 0.17432208628464388,\n",
              " 0.10743097167501324,\n",
              " 0.1819151852498766,\n",
              " 0.12170063765919684,\n",
              " 0.029031170956126798,\n",
              " 0.10858698824536507,\n",
              " 0.11405826514591151,\n",
              " 0.02117952922747168,\n",
              " 0,\n",
              " 0,\n",
              " 0.03267129928128023,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.1788213044039913,\n",
              " 0.13703437455096124,\n",
              " 0,\n",
              " 0,\n",
              " 0.19322646894569923,\n",
              " 0.12570736903011526,\n",
              " 0.08910426397100728,\n",
              " 0.06656218684027436,\n",
              " 0.07492407229458783,\n",
              " 0.0422479289626219,\n",
              " 0.03829632921822862,\n",
              " 0.21857369915990602,\n",
              " 0.1643180731416926,\n",
              " 0.24671236790491247,\n",
              " 0.006289383482123517,\n",
              " 0.18116281296353345,\n",
              " 0.04285041265798415,\n",
              " 0.369977258821289,\n",
              " 0.37031279344366547,\n",
              " 0.26766123414259524,\n",
              " 0.3772047006299193,\n",
              " 0.3602932836967591,\n",
              " 0.428898138219977,\n",
              " 0,\n",
              " 0.1306693030925999,\n",
              " 0.05876004035891862,\n",
              " 0.11255206913875618,\n",
              " 0.03999918390334514,\n",
              " 0.11974591829776599,\n",
              " 0.13481588025819208,\n",
              " 0.13299623941646144,\n",
              " 0.07135359586158348,\n",
              " 0.06677451622915061,\n",
              " 0.03746341133662793,\n",
              " 0.13028691924124633,\n",
              " 0.10052967762916164,\n",
              " 0.09195409773666838,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0.1582397068281056,\n",
              " 0,\n",
              " 0.1639876426341884,\n",
              " 0.1032526894840412,\n",
              " 0.11002229973587248,\n",
              " 0.04871977378028584,\n",
              " 0.07986327565601153,\n",
              " 0.0989919054940146,\n",
              " 0,\n",
              " 0.19675537887814717,\n",
              " 0.1482242779362144,\n",
              " 0.1947220873334637,\n",
              " 0.09695323386636158,\n",
              " 0.13660940361501123,\n",
              " 0.27123699049580396,\n",
              " 0.19058045207655536,\n",
              " 0.13102208583488845,\n",
              " 0.13851804809782806,\n",
              " 0.2369912755412432,\n",
              " 0.1399355166965283,\n",
              " 0.17895401650240364,\n",
              " 0.228982784094557,\n",
              " 0.36431361532657647,\n",
              " 0.19714853645398958,\n",
              " 0.2809120337665317,\n",
              " 0.3084993625660489,\n",
              " 0.2321271151444684,\n",
              " 0.5231777037626293,\n",
              " 0.39069467046264084,\n",
              " 0.4218832712214486,\n",
              " 0.39631174077557446,\n",
              " 0.3868752369067933,\n",
              " 0.29882243812488357,\n",
              " 0.14878705308533896,\n",
              " 0.23180752082826175,\n",
              " 0.2877013503308229,\n",
              " 0.1634149554323344,\n",
              " 0.15569157440847223,\n",
              " 0.254100055127672,\n",
              " 0.08353489699268339,\n",
              " 0.14132307421394585,\n",
              " 0.09723500436296406,\n",
              " 0.13035399777311404,\n",
              " 0.10574453898757778,\n",
              " 0.2039858924301866,\n",
              " 0,\n",
              " 0,\n",
              " 0.08251486371124836,\n",
              " 0.040644151293455145,\n",
              " 0.016580972072445837,\n",
              " 0.09547610265040715,\n",
              " 0.09159345719544848,\n",
              " 0.1045449025094849,\n",
              " 0,\n",
              " 0.15004592174833883,\n",
              " 0.13673847204477244,\n",
              " 0.037137058578546975,\n",
              " 0.13390080637491558,\n",
              " 0,\n",
              " 0.10098114011793863,\n",
              " 0.2264888820952442,\n",
              " 0.1989628896530093,\n",
              " 0.26879589060805936,\n",
              " 0.0837838252772934,\n",
              " 0.1110326650075518,\n",
              " 0.04014667706154909,\n",
              " 0.08780481434382331,\n",
              " 0.17512321580976395,\n",
              " 0.12353634084137581,\n",
              " 0.05265202021200321,\n",
              " 0.14145956748773164,\n",
              " 0.03850882534915992,\n",
              " 0.2352282463885903,\n",
              " 0.2796381644059776,\n",
              " 0.11773881824434294,\n",
              " 0.15192007520728243,\n",
              " 0.2784396833954374,\n",
              " 0.2169369618863432,\n",
              " 0,\n",
              " 0.15673792094809902,\n",
              " 0.03552159244445098,\n",
              " 0.25236410474375726,\n",
              " 0.10793006879198574,\n",
              " 0.1906415482936263,\n",
              " 0.046026109806846564,\n",
              " 0.07142292144640408,\n",
              " 0.16082534712433577,\n",
              " 0.16898131925981963,\n",
              " 0.12342269293767263,\n",
              " 0.13820413518254762,\n",
              " 0.11163790073146336,\n",
              " 0.08372414930309753,\n",
              " 0.0020668934132078496,\n",
              " 0.07770742328033806,\n",
              " 0.09344112166358029,\n",
              " 0.1850982782359222,\n",
              " 0.10667239334784487,\n",
              " 0.17418721940237614,\n",
              " 0.11710206245612731,\n",
              " 0.21420123780743577,\n",
              " 0.17739544983502642,\n",
              " 0.20510128919482506,\n",
              " 0.16424581134119717,\n",
              " 0.10156021032779901,\n",
              " 0.06175427863981911,\n",
              " 0.02333042114176795,\n",
              " 0.050391729114783804,\n",
              " 0,\n",
              " 0.24512015440958393,\n",
              " 0.27953282439104127,\n",
              " 0.05709279446880268,\n",
              " 0.21107613426027022,\n",
              " 0.1714141290786623,\n",
              " 0.1646775707796297,\n",
              " 0.10246295436533805,\n",
              " 0.1486562951627826,\n",
              " 0.14824872461440233,\n",
              " 0.20697503871006093,\n",
              " 0.13773874087311924,\n",
              " 0.08943630384036859,\n",
              " 0.18326048562941158,\n",
              " 0.29909110604364236,\n",
              " 0.3454106459720376,\n",
              " 0.33412881958410484,\n",
              " 0.26157504396275655,\n",
              " 0.37647577639078933,\n",
              " 0.3128034523111878,\n",
              " 0.36951761467252364,\n",
              " 0.3888021322386076,\n",
              " 0.3488559908716265,\n",
              " 0.19739951944829107,\n",
              " 0.12265656853859959,\n",
              " 0.24048180101228733,\n",
              " 0.28030049758997816,\n",
              " 0.27113303823223694,\n",
              " 0.2632689411202211,\n",
              " 0.3065536250574133,\n",
              " 0.18246160283034193,\n",
              " 0.1843766005672747,\n",
              " 0.1511658891749659,\n",
              " 0.015568853170116042,\n",
              " 0.23435980962764244,\n",
              " 0.14302805566302237,\n",
              " 0.10318512776418377,\n",
              " 0.01613589197780535,\n",
              " 0.12020879702180942,\n",
              " 0.03386703906504294,\n",
              " 0.04420729864021109,\n",
              " 0.10557301339756818,\n",
              " 0.069411558391224,\n",
              " 0.07927628822163155,\n",
              " 0.06751894504532253,\n",
              " 0.045282815570606504,\n",
              " 0.14421358060820696,\n",
              " 0.09128380686943294,\n",
              " 0.14168006007446873,\n",
              " 0.05159097068002175,\n",
              " 0.18479081680178142,\n",
              " 0.2620699336881667,\n",
              " 0.23514950727894882,\n",
              " 0.2680546596216492,\n",
              " 0.1657323312808129,\n",
              " 0.1591305203859025,\n",
              " 0.09816898465698594,\n",
              " 0.15402946071957488,\n",
              " 0.2249075641258043,\n",
              " 0.28667600940617755,\n",
              " 0.16833363034914026,\n",
              " 0.2577596265673555,\n",
              " 0.05705223723486479,\n",
              " 0.2863815153595785,\n",
              " 0.29637601383079426,\n",
              " 0.26082829277331876,\n",
              " 0.30421877761164146,\n",
              " 0.3086078247504414,\n",
              " 0.33822050187495295,\n",
              " 0,\n",
              " 0.2736500687889741,\n",
              " 0.11978785124383241,\n",
              " 0.2318730080447559,\n",
              " 0.24808299029757272,\n",
              " 0.330667597411475,\n",
              " 0.17971486426240765,\n",
              " 0.2209019771036408,\n",
              " 0.24049128490280441,\n",
              " 0.14294751403957096,\n",
              " 0.17022558246750888,\n",
              " 0.20152905088311474,\n",
              " 0.16960643734499495,\n",
              " 0.2062278049540014,\n",
              " 0,\n",
              " 0.09349122779298391,\n",
              " 0.10496961599081615,\n",
              " 0.1792255683127394,\n",
              " 0.07582757015980392,\n",
              " 0.2015590772961158,\n",
              " 0.04215042004550607,\n",
              " 0.302196266532457,\n",
              " 0.09375386341813151,\n",
              " 0.227903365951514,\n",
              " 0.15090873111195635,\n",
              " 0.21787601584093533,\n",
              " 0.059173675767702445,\n",
              " 0.12098026758615371,\n",
              " 0.12697661342672703,\n",
              " 0.002481691730876569,\n",
              " 0.2843397013736661,\n",
              " 0.2719834713814421,\n",
              " 0.23216109746891647,\n",
              " 0.2618512642820337,\n",
              " 0.21481258001189302,\n",
              " 0.2837629063474945,\n",
              " 0.2805578933358064,\n",
              " 0.24033839257230072,\n",
              " 0.2062749395859751,\n",
              " 0.273009794304269,\n",
              " 0.21334431557209896,\n",
              " 0.1797596777552423,\n",
              " 0.23519498095196414,\n",
              " 0.3638906274856045,\n",
              " 0.26655496070482904,\n",
              " 0.2031443715654928,\n",
              " 0.2727318579345151,\n",
              " 0.2693583882221434,\n",
              " 0.3315307164275542,\n",
              " 0.3364235471242058,\n",
              " 0.2640144143436809,\n",
              " 0.26258839086368463,\n",
              " 0.1635103562729542,\n",
              " 0.05792826711659906,\n",
              " 0.25033839311226186,\n",
              " 0.212085044224693,\n",
              " 0.1538080384234568,\n",
              " 0.09692060035114496,\n",
              " 0.20761956228748216,\n",
              " 0.11622732658399582,\n",
              " 0.09800972657258152,\n",
              " 0.0786177085243558,\n",
              " 0.0430409250854013,\n",
              " 0.18423797481174117,\n",
              " 0.18421551807335157,\n",
              " 0.10594780323400425,\n",
              " 0.1253472313570272,\n",
              " 0.14074296698495553,\n",
              " 0.10620954087110379,\n",
              " 0.25252817725881455,\n",
              " 0.0643302076746475,\n",
              " 0.15186495189276078,\n",
              " 0.08656391354214843,\n",
              " 0.10568443767556243,\n",
              " 0.10727888798097945,\n",
              " 0.0383810384472538,\n",
              " 0.10848428595179556,\n",
              " 0.1448730304543317,\n",
              " 0.21028425397358083,\n",
              " 0.17955461503860493,\n",
              " 0.18159842376406873,\n",
              " 0.1403878639746893,\n",
              " 0.1638148614712224,\n",
              " 0.17575248157993037,\n",
              " 0.14456382201194962,\n",
              " 0.22212390884771635,\n",
              " 0.16100842903481338,\n",
              " 0.15747411958123964,\n",
              " 0.07615903935700045,\n",
              " 0.16662953917588788,\n",
              " 0.10137010666980957,\n",
              " 0.19540819420321343,\n",
              " 0.24659478040697413,\n",
              " 0.17604392043859998,\n",
              " 0.21650733156277044,\n",
              " 0.2060063015966813,\n",
              " 0.1918882397973689,\n",
              " 0.03251077605488815,\n",
              " 0.1107009609584841,\n",
              " 0.16247070765381413,\n",
              " 0.08801249009013119,\n",
              " 0.10626112211227873,\n",
              " 0.15764992387655213,\n",
              " 0.1600586038006205,\n",
              " 0.13908312039162177,\n",
              " 0.14978892178828476,\n",
              " 0.051492467614298036,\n",
              " 0.09122177409768345,\n",
              " 0.14819625611374526,\n",
              " 0.09543892118857915,\n",
              " 0.16292894638238123,\n",
              " 0.07219254700400782,\n",
              " 0.12206599528982037,\n",
              " 0.08815323958831389,\n",
              " 0.12561297298342017,\n",
              " 0.122380681486771,\n",
              " 0.19284465864770867,\n",
              " 0.16989464154731107,\n",
              " 0.20513972314845844,\n",
              " 0.05073550455664179,\n",
              " 0.3019302653306926,\n",
              " 0.16948287686409058,\n",
              " 0.18196586219776753,\n",
              " 0.1611782138233348,\n",
              " 0.13403884451905493,\n",
              " 0.18608596962327967,\n",
              " 0.11386952212780102,\n",
              " 0.2307960220537163,\n",
              " 0.28139720215101366,\n",
              " 0.2761154544698594,\n",
              " 0.16214240209217026,\n",
              " 0.31512387920014706,\n",
              " 0.16917245991836743,\n",
              " 0.16058918395342406,\n",
              " 0.2227978305048207,\n",
              " 0.21775798890389858,\n",
              " 0.2794734384270587,\n",
              " 0.1893071179324148,\n",
              " 0.19726437997159765,\n",
              " 0.20542486228133866,\n",
              " 0.3624704110907744,\n",
              " 0.2553795173284647,\n",
              " 0.39815340788148473,\n",
              " 0.34632821192697544,\n",
              " 0.363766206366048,\n",
              " 0.36701275012281687,\n",
              " 0.27206941173787347,\n",
              " 0.31917858429850593,\n",
              " 0.15514532808341067,\n",
              " 0.12116598518809836,\n",
              " 0.2952017746167599,\n",
              " 0.2479357117420722,\n",
              " 0.2102039333219219,\n",
              " 0.14803697325059942,\n",
              " 0.15612073753398484,\n",
              " 0.08246817140409218,\n",
              " 0.1224031704361036,\n",
              " 0.11845735106568969,\n",
              " 0.1565942349175912,\n",
              " 0.2298509792322817,\n",
              " 0.11951215856913792,\n",
              " 0.1092963705429846,\n",
              " 0.11394740147872082,\n",
              " 0.1302934903736792,\n",
              " 0.16977681237816228,\n",
              " 0.1906955352533319,\n",
              " 0.1267060882493794,\n",
              " 0.15203867858768758,\n",
              " 0.08013802731296522,\n",
              " 0.12933561611546382,\n",
              " 0.161957086048901,\n",
              " 0.12905128080072575,\n",
              " 0.07753484545105797,\n",
              " 0.08778653322738046,\n",
              " 0.25590320918106924,\n",
              " 0.26276097196081133,\n",
              " 0.132998610980152,\n",
              " 0.19427313409509953,\n",
              " 0.20034389562815355,\n",
              " 0.1654394911964129,\n",
              " 0.1156950857284266,\n",
              " 0.1856510025437059,\n",
              " 0.29865888236747345,\n",
              " 0.21829597272897602,\n",
              " 0.12221675708995186,\n",
              " 0.1746684746897532,\n",
              " 0.128872803973364,\n",
              " 0.17866185881369753,\n",
              " 0.24941308306961826,\n",
              " 0.24357198653631237,\n",
              " 0.23110625816209385,\n",
              " 0.25155671893850184,\n",
              " 0.2928649949701404,\n",
              " 0,\n",
              " 0.17100966363531742,\n",
              " 0.18240998322389762,\n",
              " 0.1852755709353506,\n",
              " 0.22505905078895533,\n",
              " 0.25478407381457613,\n",
              " 0.18052743330143448,\n",
              " 0.20360183825203618,\n",
              " 0.1620566383425952,\n",
              " 0.08078321091084939,\n",
              " 0.14787113768557894,\n",
              " 0.1729862656335431,\n",
              " 0.12765794484099077,\n",
              " 0.1925994323568508,\n",
              " 0.06128075988042883,\n",
              " 0.16566838903216008,\n",
              " 0.09169569556749425,\n",
              " 0.23910664017830366,\n",
              " 0.17210720660521298,\n",
              " 0.27519214443780665,\n",
              " 0.1403714305401883,\n",
              " 0.22627395088297658,\n",
              " 0.130125884399586,\n",
              " 0.3069912419991953,\n",
              " 0.2794118904790242,\n",
              " 0.2632922831152641,\n",
              " 0.22940214072256598,\n",
              " 0.15888607697809096,\n",
              " 0.1824181733005638,\n",
              " 0.029260968969715924,\n",
              " 0.33488626818844563,\n",
              " 0.3077682232204528,\n",
              " 0.27000659913948305,\n",
              " 0.2529095290756917,\n",
              " 0.29708330854484793,\n",
              " 0.26883832907784905,\n",
              " 0.2229488500029324,\n",
              " 0.24226543997543062,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Sample list of values\n",
        "\n",
        "# Fit data to a normal distribution\n",
        "mu, std = stats.norm.fit(edge_weight)\n",
        "\n",
        "# Generate a range of values for the x-axis\n",
        "xmin, xmax = min(edge_weight), max(edge_weight)\n",
        "x = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "# Create the normal distribution curve\n",
        "p = stats.norm.pdf(x, mu, std)\n",
        "\n",
        "# Calculate the 25th, 75th, and 95th percentiles\n",
        "percentiles = np.percentile(edge_weight, [95])\n",
        "percentile_labels = ['95th Percentile']\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot the normal distribution curve\n",
        "plt.plot(x, p, 'k', linewidth=2)\n",
        "\n",
        "# Mark the percentiles\n",
        "for i, perc in enumerate(percentiles):\n",
        "    plt.axvline(x=perc, color='r', linestyle='--')\n",
        "    plt.text(perc, max(p)*0.5, f'{percentile_labels[i]}: {perc:.3f}', color='r', ha='center', va='bottom')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Cosine Similarity Value')\n",
        "plt.ylabel('Density')\n",
        "#plt.title('Cosine similarities with 95th Percentiles')\n",
        "plt.legend()\n",
        "#plt.ylim(0, 5)\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "X5-iHIQdvPM-",
        "outputId": "82a6fa7a-ea6b-45da-b551-22ddfb8fb07c"
      },
      "id": "X5-iHIQdvPM-",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f9bf4c21-b02d-4b7f-8b61-18fa54283b2b",
      "metadata": {
        "id": "f9bf4c21-b02d-4b7f-8b61-18fa54283b2b",
        "outputId": "c7519598-edb5-4ae9-c8bf-f40ffd05dc94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=106, num_edges=2722,\n",
            "      ndata_schemes={'feat': Scheme(shape=(394,), dtype=torch.float64), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-99bd73d0174d>:28: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  node_labels = torch.from_numpy(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import torch\n",
        "from dgl.data import DGLDataset\n",
        "edge_weight=[]\n",
        "\n",
        "\n",
        "class KarateClubDataset(DGLDataset):\n",
        "    def __init__(self,threshold):\n",
        "        self.threshold=threshold\n",
        "        super().__init__(name=\"karate_club\")\n",
        "\n",
        "    def process(self):\n",
        "        edge_remove=[]\n",
        "        C=edge_weights\n",
        "        for i in range(0,len(C)):\n",
        "            if C[i]<=self.threshold:\n",
        "                edge_remove.append(i)\n",
        "            else:\n",
        "                edge_weight.append(C[i])\n",
        "\n",
        "        nodes_data = Nodes_Data\n",
        "        edges_data = Edge_Data\n",
        "        features_array = np.array(nodes_data[\"features\"].tolist(), dtype=float)\n",
        "        node_features = torch.from_numpy(features_array)\n",
        "        node_labels = torch.from_numpy(\n",
        "                      nodes_data[\"label\"].astype(\"category\").cat.codes.to_numpy()\n",
        "                       ).clone().detach()  # Make the tensor writable\n",
        "\n",
        "        edge_features = torch.from_numpy(edges_data[\"edge weights\"].to_numpy())\n",
        "        edges_src = torch.from_numpy(edges_data[\"Src Ids\"].to_numpy())\n",
        "        edges_dst = torch.from_numpy(edges_data[\"Dst Ids\"].to_numpy())\n",
        "\n",
        "        self.graph = dgl.graph(\n",
        "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
        "\n",
        "        )\n",
        "\n",
        "        self.graph.ndata[\"feat\"] = node_features\n",
        "        self.graph.ndata[\"label\"] = node_labels\n",
        "        self.graph.edata[\"weight\"] = edge_features\n",
        "\n",
        "        self.graph=dgl.remove_edges(self.graph, torch.tensor(edge_remove))\n",
        "        n_nodes = nodes_data.shape[0]\n",
        "        n_train = int(n_nodes * 0.6)\n",
        "        n_val = int(n_nodes * 0.2)\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[:n_train] = True\n",
        "        val_mask[n_train : n_train + n_val] = True\n",
        "        test_mask[n_train + n_val :] = True\n",
        "        self.graph.ndata[\"train_mask\"] = train_mask\n",
        "        self.graph.ndata[\"val_mask\"] = val_mask\n",
        "        self.graph.ndata[\"test_mask\"] = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "\n",
        "dataset = KarateClubDataset(0.231)\n",
        "g = dataset[0]\n",
        "\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d34b2c91-acb3-4b15-b01c-568dfbec3e2b",
      "metadata": {
        "id": "d34b2c91-acb3-4b15-b01c-568dfbec3e2b"
      },
      "outputs": [],
      "source": [
        "new_g = dgl.compact_graphs(g)\n",
        "train_mask = g.ndata[\"train_mask\"]\n",
        "\n",
        "for i in range(106):\n",
        "    train_mask[i] = True\n",
        "\n",
        "indices_to_change = [4, 105, 84, 27, 98, 88, 18, 65, 9, 2, 5, 49, 99, 69, 86, 67, 7, 28, 78, 70, 18, 74]\n",
        "train_mask[indices_to_change] = False\n",
        "g.ndata[\"train_mask\"]=train_mask\n",
        "\n",
        "test_mask = ~train_mask\n",
        "g.ndata[\"test_mask\"]=test_mask\n",
        "\n",
        "Edge_Data_train = Edge_Data[~(Edge_Data['Src Ids'].isin(indices_to_change)) & ~(Edge_Data['Dst Ids'].isin(indices_to_change)) & Edge_Data['edge weights']>0.8258]\n",
        "Edge_Data_train = Edge_Data_train[Edge_Data_train['edge weights']>0.8258]\n",
        "\n",
        "\n",
        "Edge_Data_test = Edge_Data[Edge_Data['Src Ids'].isin(indices_to_change) & Edge_Data['Dst Ids'].isin(indices_to_change) & Edge_Data['edge weights']>0.8258]\n",
        "Edge_Data_test = Edge_Data_test[Edge_Data_test['edge weights']>0.8258]\n",
        "\n",
        "\n",
        "sg_train=dgl.node_subgraph(g, train_mask)\n",
        "\n",
        "sg_test = dgl.node_subgraph(g, test_mask)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "oSfyjv95d87v",
        "outputId": "9260412c-4816-4f15-8c6a-ba647f4f6b39"
      },
      "id": "oSfyjv95d87v",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index         0         1         2         3         4         5  \\\n",
              "0        0 -0.071949 -0.009855 -0.111473 -0.068437 -0.000051 -0.012275   \n",
              "1        1 -0.111388 -0.030549 -0.016111 -0.077624 -0.002134  0.010090   \n",
              "2        2 -0.067452 -0.040640 -0.062818 -0.045927  0.023676 -0.005763   \n",
              "3        3  0.044775 -0.100349  0.066181 -0.059720  0.038668 -0.014245   \n",
              "4        4 -0.052044  0.015356  0.009499 -0.078976  0.036031 -0.031392   \n",
              "..     ...       ...       ...       ...       ...       ...       ...   \n",
              "101    101 -0.017529 -0.016424 -0.022918 -0.076668  0.023412 -0.008844   \n",
              "102    102 -0.078302  0.036230 -0.012988 -0.078203  0.011558  0.016312   \n",
              "103    103 -0.059429 -0.000625 -0.073761 -0.109127  0.007848 -0.006962   \n",
              "104    104 -0.073548 -0.054509 -0.110383 -0.043330 -0.024826  0.008206   \n",
              "105    105 -0.080220  0.050109 -0.050153 -0.052790 -0.046015 -0.023670   \n",
              "\n",
              "            6         7         8  ...       384       385       386  \\\n",
              "0   -0.000518  0.067638  0.035197  ...  0.051921  0.232423  0.069028   \n",
              "1    0.014642 -0.010333  0.022948  ... -0.054559 -0.129065 -0.373943   \n",
              "2    0.071898  0.008058  0.032802  ... -0.013023 -0.108738 -0.267997   \n",
              "3    0.151271  0.205177  0.125014  ... -0.095884  0.358859  0.118848   \n",
              "4    0.102122  0.054999  0.026431  ... -0.071531 -0.031057  0.265448   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "101  0.006505  0.030281  0.017040  ... -0.034617 -0.099114  0.065589   \n",
              "102 -0.010550  0.040548  0.025831  ...  0.235054  0.006692  0.102590   \n",
              "103 -0.002142  0.003869  0.042504  ...  0.075110  0.079732 -0.312061   \n",
              "104 -0.065709  0.061760  0.000159  ... -0.035147 -0.124424  0.227205   \n",
              "105 -0.041520  0.019331 -0.023866  ...  0.164101  0.036017  0.068491   \n",
              "\n",
              "          387       388       389       390       391       392       393  \n",
              "0   -0.406838 -0.023879 -0.389306  0.495563  0.280061 -0.343126  0.119126  \n",
              "1    0.131601 -0.055215  0.492614 -0.247043  0.136156  0.030885  0.379053  \n",
              "2   -0.139976 -0.049751 -0.062366  0.222516  0.475124  0.105134 -0.136304  \n",
              "3   -0.216600  0.091018 -0.007132 -0.107883 -0.320094 -0.191975 -0.190078  \n",
              "4    0.067555 -0.107087  0.097043  0.088410  0.170019 -0.171663  0.001111  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "101 -0.175906 -0.050888 -0.036915 -0.186933 -0.126468  0.068655 -0.094472  \n",
              "102 -0.125759  0.205040  0.068494 -0.148689 -0.144618 -0.185295 -0.133205  \n",
              "103 -0.008066  0.202195  0.013542  0.121599  0.067179 -0.115572  0.149759  \n",
              "104  0.057589 -0.031966 -0.054929  0.133103  0.105809  0.025864  0.021637  \n",
              "105  0.217232 -0.203910 -0.223363  0.074961 -0.184382  0.100775 -0.274663  \n",
              "\n",
              "[106 rows x 395 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f05e136f-6825-4b87-a71c-6b0aa8cc86e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>384</th>\n",
              "      <th>385</th>\n",
              "      <th>386</th>\n",
              "      <th>387</th>\n",
              "      <th>388</th>\n",
              "      <th>389</th>\n",
              "      <th>390</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.071949</td>\n",
              "      <td>-0.009855</td>\n",
              "      <td>-0.111473</td>\n",
              "      <td>-0.068437</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>-0.012275</td>\n",
              "      <td>-0.000518</td>\n",
              "      <td>0.067638</td>\n",
              "      <td>0.035197</td>\n",
              "      <td>...</td>\n",
              "      <td>0.051921</td>\n",
              "      <td>0.232423</td>\n",
              "      <td>0.069028</td>\n",
              "      <td>-0.406838</td>\n",
              "      <td>-0.023879</td>\n",
              "      <td>-0.389306</td>\n",
              "      <td>0.495563</td>\n",
              "      <td>0.280061</td>\n",
              "      <td>-0.343126</td>\n",
              "      <td>0.119126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.111388</td>\n",
              "      <td>-0.030549</td>\n",
              "      <td>-0.016111</td>\n",
              "      <td>-0.077624</td>\n",
              "      <td>-0.002134</td>\n",
              "      <td>0.010090</td>\n",
              "      <td>0.014642</td>\n",
              "      <td>-0.010333</td>\n",
              "      <td>0.022948</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054559</td>\n",
              "      <td>-0.129065</td>\n",
              "      <td>-0.373943</td>\n",
              "      <td>0.131601</td>\n",
              "      <td>-0.055215</td>\n",
              "      <td>0.492614</td>\n",
              "      <td>-0.247043</td>\n",
              "      <td>0.136156</td>\n",
              "      <td>0.030885</td>\n",
              "      <td>0.379053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.067452</td>\n",
              "      <td>-0.040640</td>\n",
              "      <td>-0.062818</td>\n",
              "      <td>-0.045927</td>\n",
              "      <td>0.023676</td>\n",
              "      <td>-0.005763</td>\n",
              "      <td>0.071898</td>\n",
              "      <td>0.008058</td>\n",
              "      <td>0.032802</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013023</td>\n",
              "      <td>-0.108738</td>\n",
              "      <td>-0.267997</td>\n",
              "      <td>-0.139976</td>\n",
              "      <td>-0.049751</td>\n",
              "      <td>-0.062366</td>\n",
              "      <td>0.222516</td>\n",
              "      <td>0.475124</td>\n",
              "      <td>0.105134</td>\n",
              "      <td>-0.136304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.044775</td>\n",
              "      <td>-0.100349</td>\n",
              "      <td>0.066181</td>\n",
              "      <td>-0.059720</td>\n",
              "      <td>0.038668</td>\n",
              "      <td>-0.014245</td>\n",
              "      <td>0.151271</td>\n",
              "      <td>0.205177</td>\n",
              "      <td>0.125014</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.095884</td>\n",
              "      <td>0.358859</td>\n",
              "      <td>0.118848</td>\n",
              "      <td>-0.216600</td>\n",
              "      <td>0.091018</td>\n",
              "      <td>-0.007132</td>\n",
              "      <td>-0.107883</td>\n",
              "      <td>-0.320094</td>\n",
              "      <td>-0.191975</td>\n",
              "      <td>-0.190078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.052044</td>\n",
              "      <td>0.015356</td>\n",
              "      <td>0.009499</td>\n",
              "      <td>-0.078976</td>\n",
              "      <td>0.036031</td>\n",
              "      <td>-0.031392</td>\n",
              "      <td>0.102122</td>\n",
              "      <td>0.054999</td>\n",
              "      <td>0.026431</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.071531</td>\n",
              "      <td>-0.031057</td>\n",
              "      <td>0.265448</td>\n",
              "      <td>0.067555</td>\n",
              "      <td>-0.107087</td>\n",
              "      <td>0.097043</td>\n",
              "      <td>0.088410</td>\n",
              "      <td>0.170019</td>\n",
              "      <td>-0.171663</td>\n",
              "      <td>0.001111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>-0.017529</td>\n",
              "      <td>-0.016424</td>\n",
              "      <td>-0.022918</td>\n",
              "      <td>-0.076668</td>\n",
              "      <td>0.023412</td>\n",
              "      <td>-0.008844</td>\n",
              "      <td>0.006505</td>\n",
              "      <td>0.030281</td>\n",
              "      <td>0.017040</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.034617</td>\n",
              "      <td>-0.099114</td>\n",
              "      <td>0.065589</td>\n",
              "      <td>-0.175906</td>\n",
              "      <td>-0.050888</td>\n",
              "      <td>-0.036915</td>\n",
              "      <td>-0.186933</td>\n",
              "      <td>-0.126468</td>\n",
              "      <td>0.068655</td>\n",
              "      <td>-0.094472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>-0.078302</td>\n",
              "      <td>0.036230</td>\n",
              "      <td>-0.012988</td>\n",
              "      <td>-0.078203</td>\n",
              "      <td>0.011558</td>\n",
              "      <td>0.016312</td>\n",
              "      <td>-0.010550</td>\n",
              "      <td>0.040548</td>\n",
              "      <td>0.025831</td>\n",
              "      <td>...</td>\n",
              "      <td>0.235054</td>\n",
              "      <td>0.006692</td>\n",
              "      <td>0.102590</td>\n",
              "      <td>-0.125759</td>\n",
              "      <td>0.205040</td>\n",
              "      <td>0.068494</td>\n",
              "      <td>-0.148689</td>\n",
              "      <td>-0.144618</td>\n",
              "      <td>-0.185295</td>\n",
              "      <td>-0.133205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>103</td>\n",
              "      <td>-0.059429</td>\n",
              "      <td>-0.000625</td>\n",
              "      <td>-0.073761</td>\n",
              "      <td>-0.109127</td>\n",
              "      <td>0.007848</td>\n",
              "      <td>-0.006962</td>\n",
              "      <td>-0.002142</td>\n",
              "      <td>0.003869</td>\n",
              "      <td>0.042504</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075110</td>\n",
              "      <td>0.079732</td>\n",
              "      <td>-0.312061</td>\n",
              "      <td>-0.008066</td>\n",
              "      <td>0.202195</td>\n",
              "      <td>0.013542</td>\n",
              "      <td>0.121599</td>\n",
              "      <td>0.067179</td>\n",
              "      <td>-0.115572</td>\n",
              "      <td>0.149759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>-0.073548</td>\n",
              "      <td>-0.054509</td>\n",
              "      <td>-0.110383</td>\n",
              "      <td>-0.043330</td>\n",
              "      <td>-0.024826</td>\n",
              "      <td>0.008206</td>\n",
              "      <td>-0.065709</td>\n",
              "      <td>0.061760</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035147</td>\n",
              "      <td>-0.124424</td>\n",
              "      <td>0.227205</td>\n",
              "      <td>0.057589</td>\n",
              "      <td>-0.031966</td>\n",
              "      <td>-0.054929</td>\n",
              "      <td>0.133103</td>\n",
              "      <td>0.105809</td>\n",
              "      <td>0.025864</td>\n",
              "      <td>0.021637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>105</td>\n",
              "      <td>-0.080220</td>\n",
              "      <td>0.050109</td>\n",
              "      <td>-0.050153</td>\n",
              "      <td>-0.052790</td>\n",
              "      <td>-0.046015</td>\n",
              "      <td>-0.023670</td>\n",
              "      <td>-0.041520</td>\n",
              "      <td>0.019331</td>\n",
              "      <td>-0.023866</td>\n",
              "      <td>...</td>\n",
              "      <td>0.164101</td>\n",
              "      <td>0.036017</td>\n",
              "      <td>0.068491</td>\n",
              "      <td>0.217232</td>\n",
              "      <td>-0.203910</td>\n",
              "      <td>-0.223363</td>\n",
              "      <td>0.074961</td>\n",
              "      <td>-0.184382</td>\n",
              "      <td>0.100775</td>\n",
              "      <td>-0.274663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 395 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f05e136f-6825-4b87-a71c-6b0aa8cc86e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f05e136f-6825-4b87-a71c-6b0aa8cc86e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f05e136f-6825-4b87-a71c-6b0aa8cc86e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a9af86a4-15ac-4f17-9a43-e24470fde036\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9af86a4-15ac-4f17-9a43-e24470fde036')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a9af86a4-15ac-4f17-9a43-e24470fde036 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7bd3e822-4dc9-4d89-9b82-78764d16d057\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7bd3e822-4dc9-4d89-9b82-78764d16d057 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_df"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.ndata['feat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N7xzsCvd_Xy",
        "outputId": "a2d3835e-ab43-4403-c9be-cdb23844a831"
      },
      "id": "0N7xzsCvd_Xy",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0719, -0.0099, -0.1115,  ...,  0.2801, -0.3431,  0.1191],\n",
              "        [-0.1114, -0.0305, -0.0161,  ...,  0.1362,  0.0309,  0.3791],\n",
              "        [-0.0675, -0.0406, -0.0628,  ...,  0.4751,  0.1051, -0.1363],\n",
              "        ...,\n",
              "        [-0.0594, -0.0006, -0.0738,  ...,  0.0672, -0.1156,  0.1498],\n",
              "        [-0.0735, -0.0545, -0.1104,  ...,  0.1058,  0.0259,  0.0216],\n",
              "        [-0.0802,  0.0501, -0.0502,  ..., -0.1844,  0.1008, -0.2747]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sg_train.ndata['feat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nKst0lteHNu",
        "outputId": "18315047-e18c-491e-aea0-4dfc177542c6"
      },
      "id": "1nKst0lteHNu",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0719, -0.0099, -0.1115,  ...,  0.2801, -0.3431,  0.1191],\n",
              "        [-0.1114, -0.0305, -0.0161,  ...,  0.1362,  0.0309,  0.3791],\n",
              "        [ 0.0448, -0.1003,  0.0662,  ..., -0.3201, -0.1920, -0.1901],\n",
              "        ...,\n",
              "        [-0.0783,  0.0362, -0.0130,  ..., -0.1446, -0.1853, -0.1332],\n",
              "        [-0.0594, -0.0006, -0.0738,  ...,  0.0672, -0.1156,  0.1498],\n",
              "        [-0.0735, -0.0545, -0.1104,  ...,  0.1058,  0.0259,  0.0216]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sg_test.ndata['feat']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3qCwqljeLbl",
        "outputId": "a00db524-7344-4470-fd07-da2c904e9a83"
      },
      "id": "J3qCwqljeLbl",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0675, -0.0406, -0.0628,  ...,  0.4751,  0.1051, -0.1363],\n",
              "        [-0.0520,  0.0154,  0.0095,  ...,  0.1700, -0.1717,  0.0011],\n",
              "        [-0.0686,  0.0198,  0.0283,  ...,  0.1440, -0.1472,  0.0253],\n",
              "        ...,\n",
              "        [-0.1190, -0.0265, -0.0155,  ..., -0.1820, -0.1102, -0.1316],\n",
              "        [-0.1519,  0.0422, -0.0592,  ..., -0.0138, -0.1123,  0.0677],\n",
              "        [-0.0802,  0.0501, -0.0502,  ..., -0.1844,  0.1008, -0.2747]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "57ba9e91-e07f-435e-aa83-2949c9909810",
      "metadata": {
        "id": "57ba9e91-e07f-435e-aa83-2949c9909810"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats,norm='both')\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        in_feat = in_feat.float()\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.elu(h)\n",
        "\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "\n",
        "\n",
        "los=[]\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "epoch=[]\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "def train(sg_train,sg_test, model):\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "    best_train_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features_train = sg_train.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "\n",
        "    for e in range(600):\n",
        "        # Forward\n",
        "        logits = model(sg_train,features_train)\n",
        "\n",
        "        # Compute prediction\n",
        "\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        labels = g.ndata[\"label\"].long()\n",
        "        loss = F.cross_entropy(logits, labels[train_mask])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            logits_test = model(sg_test,sg_test.ndata[\"feat\"])\n",
        "\n",
        "\n",
        "        pred_test = logits_test.argmax(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        train_acc = (pred == labels[train_mask]).float().mean()\n",
        "        test_acc = (pred_test == labels[test_mask]).float().mean()\n",
        "\n",
        "        if best_train_acc < train_acc:\n",
        "            best_train_acc = train_acc\n",
        "        if best_test_acc < test_acc:\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        if e == 510:\n",
        "            # Save features h after the first layer at epoch 1430\n",
        "            import numpy as np\n",
        "\n",
        "            feat_train = features_train.clone()\n",
        "            feat_train = feat_train.float()\n",
        "            h_train = model.conv1(sg_train, feat_train)\n",
        "\n",
        "            h_train = F.elu(h_train)\n",
        "            h_train_numpy = h_train.detach().numpy()  # Convert tensor to NumPy array\n",
        "            np.savetxt('final_animal_train_features.csv',h_train_numpy, delimiter=',')  # Save NumPy array to CSV file\n",
        "            FileLink('final_animal_train_features.csv')\n",
        "\n",
        "        # Backward\n",
        "            graph_features = g.ndata[\"feat\"].clone()\n",
        "            graph_features = graph_features.float()\n",
        "            graph_features = model.conv1(g, graph_features)\n",
        "            graph_features = F.elu(graph_features)\n",
        "\n",
        "\n",
        "            feat_test =  sg_test.ndata[\"feat\"].clone()\n",
        "\n",
        "            feat_test = feat_test.float()\n",
        "            print(type(feat_test[0]))\n",
        "\n",
        "            print(feat_test[0])\n",
        "            print(feat_test[2])\n",
        "            print(feat_test.shape)\n",
        "            h_test = model.conv1(sg_test,feat_test)\n",
        "\n",
        "\n",
        "            feat_test_0_numpy = feat_test[0].detach().numpy()  # Convert tensor to NumPy array\n",
        "            np.savetxt('feat_test_0.csv', feat_test_0_numpy, delimiter=',')  # Save NumPy array to CSV file\n",
        "\n",
        "# To provide a link for downloading in Jupyter Notebook (if you are using it)\n",
        "            FileLink('feat_test_0.csv')\n",
        "\n",
        "            feat_train_0_numpy = feat_train[0].detach().numpy()  # Convert tensor to NumPy array\n",
        "            np.savetxt('feat_train_0.csv', feat_train_0_numpy, delimiter=',')  # Save NumPy array to CSV file\n",
        "\n",
        "# To provide a link for downloading in Jupyter Notebook (if you are using it)\n",
        "            FileLink('feat_train_0.csv')\n",
        "\n",
        "\n",
        "\n",
        "            print(h_test[0])\n",
        "            print(h_test[2])\n",
        "            print(feat_test.shape)\n",
        "            h_test = F.elu(h_test)\n",
        "            h_test_numpy = h_test.detach().numpy()  # Convert tensor to NumPy array\n",
        "            np.savetxt('final_animal_test_features.csv',h_test_numpy, delimiter=',')  # Save NumPy array to CSV file\n",
        "            FileLink('final_animal_test_features.csv')\n",
        "        # Backward\n",
        "\n",
        "\n",
        "# Assuming features_h is a PyTorch tensor\n",
        "            graph_features_numpy = graph_features.detach().numpy()  # Convert tensor to NumPy array\n",
        "            np.savetxt('graph_features.csv',graph_features_numpy, delimiter=',')  # Save NumPy array to CSV file\n",
        "            FileLink('graph_features.csv')\n",
        "\n",
        "\n",
        "            np.savetxt('animal_train_predictions.csv', pred, delimiter=',')\n",
        "            np.savetxt('animal_test_predictions.csv', pred_test, delimiter=',')\n",
        "\n",
        "            FileLink('animal_train_predictions.csv')\n",
        "            FileLink('animal_test_predictions.csv')\n",
        "            print(pred_test)\n",
        "            print(pred_test)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            epoch.append(e)\n",
        "            los.append(round(loss.item(),3))\n",
        "            train_accuracy.append(round(train_acc.item(),3))\n",
        "            test_accuracy.append(round(test_acc.item(),3))\n",
        "            print(\n",
        "                f\"In epoch {e}, loss: {loss:.3f}, train acc: {train_acc:.3f} (train {best_train_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
        "            )\n",
        "\n",
        "\n",
        "model = GCN(g.ndata[\"feat\"].shape[1],18, 2)\n",
        "train(sg_train,sg_test,model)"
      ],
      "metadata": {
        "id": "tKH22hLevpUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e51ef83-4e62-46e2-f45e-522b5eca208f"
      },
      "id": "tKH22hLevpUE",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 0.710, train acc: 0.353 (train 0.353), test acc: 0.476 (best 0.476)\n",
            "In epoch 5, loss: 0.599, train acc: 0.671 (train 0.671), test acc: 0.667 (best 0.667)\n",
            "In epoch 10, loss: 0.701, train acc: 0.647 (train 0.671), test acc: 0.667 (best 0.667)\n",
            "In epoch 15, loss: 0.614, train acc: 0.659 (train 0.671), test acc: 0.667 (best 0.667)\n",
            "In epoch 20, loss: 0.614, train acc: 0.694 (train 0.694), test acc: 0.619 (best 0.667)\n",
            "In epoch 25, loss: 0.587, train acc: 0.694 (train 0.694), test acc: 0.667 (best 0.667)\n",
            "In epoch 30, loss: 0.590, train acc: 0.694 (train 0.694), test acc: 0.667 (best 0.667)\n",
            "In epoch 35, loss: 0.579, train acc: 0.706 (train 0.718), test acc: 0.667 (best 0.667)\n",
            "In epoch 40, loss: 0.577, train acc: 0.729 (train 0.729), test acc: 0.667 (best 0.667)\n",
            "In epoch 45, loss: 0.572, train acc: 0.729 (train 0.729), test acc: 0.667 (best 0.667)\n",
            "In epoch 50, loss: 0.570, train acc: 0.694 (train 0.729), test acc: 0.667 (best 0.667)\n",
            "In epoch 55, loss: 0.566, train acc: 0.718 (train 0.729), test acc: 0.667 (best 0.667)\n",
            "In epoch 60, loss: 0.563, train acc: 0.718 (train 0.729), test acc: 0.667 (best 0.667)\n",
            "In epoch 65, loss: 0.559, train acc: 0.718 (train 0.741), test acc: 0.667 (best 0.667)\n",
            "In epoch 70, loss: 0.555, train acc: 0.706 (train 0.741), test acc: 0.667 (best 0.667)\n",
            "In epoch 75, loss: 0.551, train acc: 0.741 (train 0.741), test acc: 0.667 (best 0.667)\n",
            "In epoch 80, loss: 0.546, train acc: 0.718 (train 0.741), test acc: 0.667 (best 0.667)\n",
            "In epoch 85, loss: 0.542, train acc: 0.718 (train 0.741), test acc: 0.667 (best 0.667)\n",
            "In epoch 90, loss: 0.538, train acc: 0.729 (train 0.741), test acc: 0.619 (best 0.667)\n",
            "In epoch 95, loss: 0.532, train acc: 0.706 (train 0.741), test acc: 0.714 (best 0.714)\n",
            "In epoch 100, loss: 0.525, train acc: 0.718 (train 0.741), test acc: 0.714 (best 0.714)\n",
            "In epoch 105, loss: 0.516, train acc: 0.741 (train 0.741), test acc: 0.714 (best 0.714)\n",
            "In epoch 110, loss: 0.505, train acc: 0.753 (train 0.776), test acc: 0.619 (best 0.714)\n",
            "In epoch 115, loss: 0.495, train acc: 0.753 (train 0.776), test acc: 0.619 (best 0.714)\n",
            "In epoch 120, loss: 0.500, train acc: 0.765 (train 0.776), test acc: 0.619 (best 0.714)\n",
            "In epoch 125, loss: 0.488, train acc: 0.729 (train 0.776), test acc: 0.381 (best 0.714)\n",
            "In epoch 130, loss: 0.475, train acc: 0.753 (train 0.776), test acc: 0.333 (best 0.714)\n",
            "In epoch 135, loss: 0.468, train acc: 0.741 (train 0.776), test acc: 0.286 (best 0.714)\n",
            "In epoch 140, loss: 0.452, train acc: 0.776 (train 0.776), test acc: 0.190 (best 0.714)\n",
            "In epoch 145, loss: 0.443, train acc: 0.800 (train 0.800), test acc: 0.190 (best 0.714)\n",
            "In epoch 150, loss: 0.435, train acc: 0.812 (train 0.812), test acc: 0.286 (best 0.714)\n",
            "In epoch 155, loss: 0.446, train acc: 0.800 (train 0.812), test acc: 0.238 (best 0.714)\n",
            "In epoch 160, loss: 0.426, train acc: 0.824 (train 0.824), test acc: 0.238 (best 0.714)\n",
            "In epoch 165, loss: 0.424, train acc: 0.776 (train 0.824), test acc: 0.238 (best 0.714)\n",
            "In epoch 170, loss: 0.429, train acc: 0.776 (train 0.847), test acc: 0.238 (best 0.714)\n",
            "In epoch 175, loss: 0.410, train acc: 0.824 (train 0.847), test acc: 0.238 (best 0.714)\n",
            "In epoch 180, loss: 0.422, train acc: 0.812 (train 0.847), test acc: 0.238 (best 0.714)\n",
            "In epoch 185, loss: 0.402, train acc: 0.835 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 190, loss: 0.428, train acc: 0.824 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 195, loss: 0.394, train acc: 0.847 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 200, loss: 0.405, train acc: 0.824 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 205, loss: 0.398, train acc: 0.824 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 210, loss: 0.391, train acc: 0.812 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 215, loss: 0.387, train acc: 0.812 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 220, loss: 0.419, train acc: 0.835 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 225, loss: 0.394, train acc: 0.847 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 230, loss: 0.376, train acc: 0.835 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 235, loss: 0.370, train acc: 0.847 (train 0.859), test acc: 0.190 (best 0.714)\n",
            "In epoch 240, loss: 0.385, train acc: 0.824 (train 0.859), test acc: 0.190 (best 0.714)\n",
            "In epoch 245, loss: 0.370, train acc: 0.835 (train 0.859), test acc: 0.190 (best 0.714)\n",
            "In epoch 250, loss: 0.359, train acc: 0.835 (train 0.859), test acc: 0.190 (best 0.714)\n",
            "In epoch 255, loss: 0.356, train acc: 0.859 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 260, loss: 0.531, train acc: 0.753 (train 0.859), test acc: 0.333 (best 0.714)\n",
            "In epoch 265, loss: 0.560, train acc: 0.753 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 270, loss: 0.573, train acc: 0.741 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 275, loss: 0.578, train acc: 0.729 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 280, loss: 0.497, train acc: 0.729 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 285, loss: 0.444, train acc: 0.824 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 290, loss: 0.413, train acc: 0.847 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 295, loss: 0.394, train acc: 0.847 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 300, loss: 0.380, train acc: 0.847 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 305, loss: 0.370, train acc: 0.835 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 310, loss: 0.364, train acc: 0.835 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 315, loss: 0.361, train acc: 0.835 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 320, loss: 0.360, train acc: 0.859 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 325, loss: 0.356, train acc: 0.835 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 330, loss: 0.352, train acc: 0.847 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 335, loss: 0.349, train acc: 0.847 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 340, loss: 0.346, train acc: 0.835 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 345, loss: 0.343, train acc: 0.835 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 350, loss: 0.341, train acc: 0.835 (train 0.859), test acc: 0.286 (best 0.714)\n",
            "In epoch 355, loss: 0.338, train acc: 0.847 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 360, loss: 0.335, train acc: 0.847 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 365, loss: 0.332, train acc: 0.835 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 370, loss: 0.329, train acc: 0.847 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 375, loss: 0.326, train acc: 0.847 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 380, loss: 0.323, train acc: 0.859 (train 0.859), test acc: 0.238 (best 0.714)\n",
            "In epoch 385, loss: 0.320, train acc: 0.871 (train 0.871), test acc: 0.238 (best 0.714)\n",
            "In epoch 390, loss: 0.364, train acc: 0.859 (train 0.871), test acc: 0.238 (best 0.714)\n",
            "In epoch 395, loss: 0.415, train acc: 0.835 (train 0.871), test acc: 0.238 (best 0.714)\n",
            "In epoch 400, loss: 0.335, train acc: 0.859 (train 0.871), test acc: 0.238 (best 0.714)\n",
            "In epoch 405, loss: 0.340, train acc: 0.847 (train 0.871), test acc: 0.238 (best 0.714)\n",
            "In epoch 410, loss: 0.317, train acc: 0.871 (train 0.871), test acc: 0.238 (best 0.714)\n",
            "In epoch 415, loss: 0.318, train acc: 0.859 (train 0.882), test acc: 0.238 (best 0.714)\n",
            "In epoch 420, loss: 0.317, train acc: 0.871 (train 0.882), test acc: 0.238 (best 0.714)\n",
            "In epoch 425, loss: 0.311, train acc: 0.871 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 430, loss: 0.303, train acc: 0.871 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 435, loss: 0.319, train acc: 0.871 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 440, loss: 0.336, train acc: 0.859 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 445, loss: 0.314, train acc: 0.882 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 450, loss: 0.298, train acc: 0.882 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 455, loss: 0.298, train acc: 0.882 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 460, loss: 0.382, train acc: 0.812 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 465, loss: 0.325, train acc: 0.847 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 470, loss: 0.293, train acc: 0.882 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 475, loss: 0.284, train acc: 0.894 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 480, loss: 0.306, train acc: 0.894 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 485, loss: 0.296, train acc: 0.882 (train 0.894), test acc: 0.238 (best 0.714)\n",
            "In epoch 490, loss: 0.277, train acc: 0.894 (train 0.906), test acc: 0.238 (best 0.714)\n",
            "In epoch 495, loss: 0.281, train acc: 0.894 (train 0.906), test acc: 0.238 (best 0.714)\n",
            "In epoch 500, loss: 0.393, train acc: 0.835 (train 0.906), test acc: 0.238 (best 0.714)\n",
            "In epoch 505, loss: 0.337, train acc: 0.835 (train 0.906), test acc: 0.238 (best 0.714)\n",
            "<class 'torch.Tensor'>\n",
            "tensor([-6.7452e-02, -4.0640e-02, -6.2818e-02, -4.5927e-02,  2.3676e-02,\n",
            "        -5.7632e-03,  7.1898e-02,  8.0579e-03,  3.2802e-02, -4.9369e-01,\n",
            "         9.7414e-02,  1.9457e-02, -6.9753e-02,  8.0507e-03, -2.4173e-02,\n",
            "         3.5092e-02, -5.5473e-03, -5.8222e-02, -1.3108e-02,  1.7833e-02,\n",
            "        -6.4821e-02,  8.7698e-02,  9.0541e-03,  5.9425e-02, -2.6664e-02,\n",
            "         1.9275e-02, -2.2206e-02, -3.0085e-02,  2.9098e-02,  3.5482e-02,\n",
            "         1.6152e-02,  9.0903e-02, -1.3149e-01,  2.6217e-02, -3.3631e-01,\n",
            "        -2.1023e-02, -4.2812e-02, -1.3266e-02, -1.7166e-02,  8.8978e-02,\n",
            "        -2.8938e-02, -1.7689e-02, -1.6705e-02,  6.2831e-02,  1.9689e-02,\n",
            "         4.3304e-02,  8.3747e-02,  3.6734e-02,  3.7620e-02,  8.3830e-02,\n",
            "        -4.6353e-02, -1.4505e-02,  8.1391e-02, -4.5628e-02, -6.6266e-02,\n",
            "         3.0930e-02,  2.3993e-02,  2.7660e-02,  9.8198e-02, -3.6665e-02,\n",
            "        -1.3838e-02,  1.5485e-02,  1.5654e-01, -6.6859e-03, -1.4457e-02,\n",
            "        -1.1427e-01,  7.5369e-03, -1.8038e-02, -4.4084e-02, -4.5583e-02,\n",
            "         6.8960e-03, -5.6670e-02, -7.6052e-02,  1.6356e-02, -2.9557e-02,\n",
            "        -2.8987e-02,  3.4216e-02, -1.3161e-02, -9.0702e-03, -4.1999e-02,\n",
            "        -2.7319e-02,  4.4198e-02,  1.6450e-02,  8.9825e-02, -9.3319e-03,\n",
            "         4.7683e-02,  1.1551e-02,  4.7613e-03,  5.2118e-02,  7.1904e-03,\n",
            "         4.1789e-02,  5.9963e-03, -8.6771e-02, -3.1094e-02,  4.7549e-03,\n",
            "         2.7919e-02, -2.4646e-03, -5.9111e-02,  9.0547e-02, -8.7673e-02,\n",
            "         3.0295e-02,  3.7809e-02,  1.5336e-02,  3.2083e-02, -9.6883e-03,\n",
            "        -7.2203e-04,  1.5549e-01, -2.1485e-02, -2.8613e-02,  2.8105e-02,\n",
            "        -2.4050e-02,  2.9221e-02, -1.7450e-03, -7.3368e-03,  9.9307e-02,\n",
            "         3.0594e-02,  3.2465e-02,  6.6679e-02,  3.2291e-02, -9.2020e-02,\n",
            "        -3.9264e-02, -9.4207e-02, -9.2902e-02,  1.1971e-01, -1.5592e-03,\n",
            "         4.7688e-03,  3.1624e-02,  6.0153e-02,  4.9028e-02, -4.5012e-03,\n",
            "        -9.2105e-03,  1.2112e-01,  5.1950e-02,  5.2449e-02, -8.2299e-02,\n",
            "         1.9770e-02,  1.2976e-02, -5.4268e-02, -5.9889e-02,  4.1714e-02,\n",
            "        -7.1377e-02,  4.8036e-02, -9.5887e-02,  8.6863e-02, -1.8335e-01,\n",
            "        -7.0697e-03,  6.2921e-02,  7.0688e-02, -4.4627e-02, -5.1811e-03,\n",
            "         1.2377e-01,  1.1508e-03,  1.1185e-02, -4.7826e-02,  1.0609e-01,\n",
            "         8.5008e-03, -7.5112e-02, -4.8688e-02,  5.0724e-02, -2.7026e-02,\n",
            "         7.7191e-02, -1.0777e-01,  8.0784e-02, -7.6627e-03, -6.1575e-02,\n",
            "         5.5350e-02,  5.3802e-02,  1.2350e-02, -6.0307e-03,  3.6846e-02,\n",
            "        -4.7519e-02,  1.0371e-02, -8.2961e-02,  4.9170e-02, -2.5487e-02,\n",
            "         1.1472e-02, -5.2474e-02, -3.2396e-03,  5.1203e-03,  6.8701e-02,\n",
            "         2.2841e-02,  9.0054e-03,  4.6425e-02, -1.9187e-02,  2.7937e-02,\n",
            "        -9.2835e-02, -3.8980e-02,  1.9633e-02,  2.9883e-02,  3.2726e-02,\n",
            "        -7.9228e-02, -1.6406e-02, -5.9673e-04, -4.2295e-02,  9.0458e-03,\n",
            "        -2.0730e-02, -5.9084e-02, -8.1108e-02, -5.9442e-02, -2.1421e-02,\n",
            "         4.5785e-01,  2.6641e-02,  3.7948e-02, -1.0134e-02,  4.4998e-02,\n",
            "        -3.3183e-03, -9.7050e-03,  1.5112e-02, -5.2583e-02, -4.7427e-02,\n",
            "        -7.7490e-02,  4.9655e-02,  2.4383e-02, -3.5790e-02,  5.2403e-02,\n",
            "        -6.9114e-02,  4.4272e-02, -2.3482e-02,  1.7439e-02,  8.8521e-02,\n",
            "         2.1497e-01, -9.1649e-03,  2.0177e-02,  1.6055e-02, -3.1282e-02,\n",
            "         2.6086e-02,  1.2684e-01, -1.2623e-01, -4.6841e-02, -1.9100e-03,\n",
            "         8.0481e-03, -3.8279e-03, -7.3813e-02, -8.2439e-02, -3.4417e-03,\n",
            "         4.9270e-02, -1.1152e-02,  1.4133e-02, -1.4771e-02, -1.0938e-02,\n",
            "         3.4355e-02,  2.8321e-02,  3.7607e-03,  3.8531e-02, -1.3473e-01,\n",
            "        -1.5884e-02,  6.1481e-02,  1.8779e-02, -1.7009e-03,  6.1051e-02,\n",
            "        -2.9567e-02, -5.4482e-02,  1.0351e-03,  1.1896e-02,  2.4448e-01,\n",
            "         3.4504e-02,  2.1112e-02, -4.7656e-02,  8.9861e-04,  2.0288e-03,\n",
            "        -2.4633e-02, -5.4750e-02, -1.1530e-02, -1.2329e-02, -4.5614e-02,\n",
            "        -1.5175e-02, -6.6661e-02, -1.1943e-01,  1.5989e-02,  3.7046e-02,\n",
            "        -1.7059e-02, -6.4592e-02,  7.6883e-02,  1.3450e-02,  5.7869e-02,\n",
            "         3.0955e-02, -6.9568e-01,  4.8884e-03,  6.3459e-02,  3.2030e-02,\n",
            "        -7.5407e-02,  6.8219e-02,  6.3612e-02, -8.1735e-02, -3.2377e-02,\n",
            "         4.7832e-02, -7.1622e-02,  1.0000e-02,  4.0449e-02,  2.8059e-02,\n",
            "        -5.9697e-02, -3.9049e-02, -8.4915e-03,  3.0392e-03,  3.3637e-02,\n",
            "         5.4579e-02, -1.6033e-03, -2.0318e-02,  1.9826e-02,  4.4889e-02,\n",
            "         1.2576e+00, -1.1030e+00,  2.2493e-01, -3.8581e-01, -1.6390e-01,\n",
            "         6.2709e-01, -1.5082e-01,  5.3796e-02,  8.1338e-01,  2.1987e-01,\n",
            "         4.2049e-01, -2.6644e-01,  3.3331e-01, -9.7440e-01, -5.1890e-01,\n",
            "        -4.7620e-01, -1.1811e-01, -2.5406e-01, -3.2198e-01, -6.0735e-02,\n",
            "         4.2693e-01, -3.0288e-01,  7.8571e-02, -4.6603e-01,  3.9049e-01,\n",
            "         9.8460e-01, -2.3239e-01,  9.9771e-02, -3.2238e-01, -3.3088e-02,\n",
            "         3.0245e-02, -1.0092e-01, -6.0478e-01, -2.0906e-01, -1.9663e-01,\n",
            "         3.0509e-03, -5.4484e-01, -7.5190e-01,  2.9727e-01, -3.7347e-02,\n",
            "        -2.6385e-01,  3.3359e-01, -3.6934e-01,  2.6267e-01, -9.0881e-01,\n",
            "         4.2358e-02,  2.6368e-01, -8.0359e-01, -5.2744e-02,  6.0397e-01,\n",
            "        -1.4335e-01,  1.2423e-01,  1.5464e-01,  3.9539e-01, -9.1753e-01,\n",
            "         2.1562e-01, -3.5692e-01, -1.8047e-02, -7.9580e-02, -2.3285e-01,\n",
            "         3.0173e-01, -1.9576e-01, -5.1085e-02, -6.8276e-02, -3.8356e-01,\n",
            "        -2.0309e-02, -1.3498e-01,  2.6001e-01,  2.6814e-01,  3.8836e-01,\n",
            "         1.6075e-01, -1.9705e-02, -2.3868e-01,  2.9190e-01,  2.2266e-01,\n",
            "        -1.9020e-01,  2.7510e-03,  4.7091e-01, -8.9080e-02,  3.1705e-01,\n",
            "        -2.1390e-01, -1.3401e-01, -2.0237e-01,  4.3061e-01, -1.3023e-02,\n",
            "        -1.0874e-01, -2.6800e-01, -1.3998e-01, -4.9751e-02, -6.2366e-02,\n",
            "         2.2252e-01,  4.7512e-01,  1.0513e-01, -1.3630e-01])\n",
            "tensor([-6.8634e-02,  1.9838e-02,  2.8341e-02, -5.8880e-02,  7.4479e-02,\n",
            "         3.3309e-02,  2.5620e-02,  6.2367e-02,  2.1002e-02, -6.3978e-01,\n",
            "         2.7089e-02, -4.0455e-02, -6.1564e-02,  4.2343e-02, -1.4336e-02,\n",
            "         1.1167e-02,  1.5267e-02, -7.0245e-02, -2.0539e-02, -2.7313e-02,\n",
            "        -3.6535e-03,  9.9906e-02,  9.4498e-02,  4.0833e-02, -7.0732e-02,\n",
            "        -9.9857e-02, -1.9390e-03, -1.3002e-01,  7.7957e-02,  4.0524e-02,\n",
            "         3.4678e-02,  1.0002e-01, -1.4107e-01,  4.0389e-02, -4.0162e-01,\n",
            "         6.5103e-03,  2.0501e-02,  1.2949e-03, -6.3360e-03, -2.2235e-02,\n",
            "        -6.1424e-02, -1.6117e-01,  1.3802e-02,  9.0589e-02,  3.6339e-02,\n",
            "        -3.2819e-02,  4.2192e-02, -5.6018e-02, -4.1860e-02, -2.7802e-02,\n",
            "         5.2944e-02, -7.7121e-02,  6.9078e-02, -8.5081e-02, -4.8826e-02,\n",
            "         9.1577e-02, -2.3572e-02, -8.8644e-03,  1.2379e-01,  8.8801e-02,\n",
            "         7.4873e-02,  4.4906e-02,  7.5779e-02,  2.2391e-01,  1.8612e-02,\n",
            "        -1.3959e-01,  7.9690e-02, -8.8830e-03, -8.4840e-03,  2.9010e-04,\n",
            "        -5.0963e-02, -1.1861e-02, -2.2374e-03,  2.9494e-02,  7.8835e-02,\n",
            "        -2.7867e-02, -1.8175e-02, -6.3817e-02, -3.8695e-02, -3.5563e-02,\n",
            "        -1.4710e-02, -2.5354e-02, -2.3845e-02,  9.5660e-02, -1.7067e-02,\n",
            "         5.0112e-02,  2.7242e-02,  6.0184e-02, -2.6589e-02,  1.4746e-02,\n",
            "        -6.4879e-02, -1.0916e-02, -1.3149e-01,  7.7073e-02, -2.5395e-03,\n",
            "        -5.5708e-03, -2.9621e-02,  1.0019e-02,  6.8048e-02, -2.8167e-01,\n",
            "         3.5307e-02, -6.7017e-02, -3.9300e-04,  1.5487e-02, -2.9514e-02,\n",
            "         8.0557e-02,  8.0782e-02, -1.2719e-03, -5.3559e-02,  1.0142e-01,\n",
            "        -1.4758e-02,  2.5812e-02,  6.7039e-02, -4.4356e-02,  3.2951e-02,\n",
            "         1.1216e-01,  3.0554e-02, -3.4087e-02,  3.6623e-02, -1.6581e-01,\n",
            "        -1.0331e-01, -5.9036e-02, -7.3527e-03, -3.0834e-03, -5.6494e-02,\n",
            "        -1.3850e-02, -4.1553e-02,  9.1386e-02,  5.2372e-02, -2.2902e-03,\n",
            "         1.7943e-02,  6.4369e-02,  4.6741e-02,  3.8658e-02, -6.8697e-02,\n",
            "        -4.2522e-02, -2.9876e-02, -6.2011e-02, -5.0390e-02,  3.8073e-02,\n",
            "        -1.6216e-02,  5.6867e-02, -2.7311e-02,  1.1637e-01, -8.6619e-02,\n",
            "        -1.1178e-02,  1.8355e-02,  4.0352e-02, -8.7012e-02, -3.4497e-02,\n",
            "         4.8335e-02,  1.9017e-02, -3.3502e-02,  6.7263e-02,  1.2214e-01,\n",
            "        -2.1271e-02,  1.1105e-02,  5.7605e-02,  2.7235e-02, -3.2631e-02,\n",
            "         4.9042e-02, -1.1488e-03,  3.3336e-02,  3.3793e-02,  6.1945e-02,\n",
            "         8.9493e-02, -6.1456e-02,  3.2377e-02, -1.0122e-01,  7.9118e-02,\n",
            "         9.6860e-02, -3.0181e-02, -1.4763e-01, -7.6598e-02,  1.3198e-02,\n",
            "        -3.5493e-03,  3.1066e-02,  7.7960e-02, -1.3080e-02,  1.4888e-01,\n",
            "         1.0444e-02,  8.2182e-02,  1.4887e-03, -1.8683e-02, -1.2739e-02,\n",
            "        -8.8995e-02, -3.1706e-02,  2.4875e-02,  5.7871e-02,  3.9835e-02,\n",
            "        -9.4094e-02, -2.0082e-02,  3.8338e-02,  3.3254e-02, -1.0316e-02,\n",
            "        -6.4186e-02, -3.1582e-02, -3.4814e-02, -7.0084e-02,  9.6135e-03,\n",
            "         5.5704e-01, -1.6167e-02,  1.8155e-03, -3.1067e-02,  1.7376e-02,\n",
            "        -1.2502e-01, -2.8337e-02,  3.4045e-03, -8.8066e-02, -2.6918e-02,\n",
            "         6.3480e-03, -6.3985e-03,  4.8156e-02, -5.9472e-02,  4.8634e-02,\n",
            "        -9.0571e-02,  7.4138e-02,  5.1194e-02,  7.2958e-02,  3.5704e-02,\n",
            "         1.1559e-01, -9.8754e-03,  4.6106e-02, -2.6256e-02, -7.0036e-02,\n",
            "         1.9532e-02,  2.6360e-02, -6.6182e-03, -5.3395e-02, -6.2596e-02,\n",
            "        -5.7426e-02,  6.1826e-02,  4.8009e-03, -5.4010e-02, -5.7146e-02,\n",
            "         6.8144e-02,  1.5874e-02,  7.1522e-02, -9.9102e-02, -1.5204e-02,\n",
            "         3.4638e-03,  4.7445e-02,  1.3852e-01,  1.0671e-01, -2.1008e-01,\n",
            "        -4.8121e-02,  6.3547e-02, -6.9318e-02, -5.2582e-02,  8.1449e-02,\n",
            "         5.5991e-02, -1.0417e-02, -1.8260e-02,  6.3114e-02,  1.6181e-01,\n",
            "         7.7479e-02,  7.6649e-02,  2.3145e-02, -9.5435e-02, -1.0888e-02,\n",
            "         2.4948e-02, -3.8620e-02,  1.0531e-01, -3.3503e-02, -4.2049e-02,\n",
            "        -9.8624e-02, -4.2359e-02, -4.5927e-02, -1.9154e-02,  6.5599e-02,\n",
            "        -3.3402e-02, -2.7360e-02,  1.1846e-01,  2.0264e-02, -8.1456e-02,\n",
            "        -2.9018e-02, -7.4823e-01, -5.2056e-02,  2.2560e-01,  4.6572e-02,\n",
            "         6.7030e-02,  4.3795e-02,  6.7937e-03,  1.0467e-02, -6.3111e-02,\n",
            "         2.7940e-02, -2.6495e-02,  9.0491e-02,  2.9341e-02, -1.5241e-02,\n",
            "        -3.8830e-02, -7.4075e-02, -2.3806e-02,  2.2464e-02, -5.1369e-02,\n",
            "        -1.5460e-02,  5.8777e-02, -1.8810e-02, -5.3303e-02,  2.7880e-02,\n",
            "         1.5114e+00, -1.0434e+00,  8.0072e-01, -3.3214e-01, -9.5001e-02,\n",
            "         6.0186e-01, -2.9215e-01,  9.8803e-02,  2.3653e-01,  3.1323e-01,\n",
            "        -1.5714e-01,  8.6556e-01, -1.8242e-01, -8.1419e-01, -1.3461e-01,\n",
            "         5.4798e-01, -1.2763e-01, -4.1432e-01,  8.4424e-02, -4.6290e-01,\n",
            "         2.8168e-01, -7.9532e-02, -5.4682e-01, -3.6357e-01,  1.0059e-01,\n",
            "         2.6001e-01, -3.2016e-01,  4.2681e-02, -6.2260e-01, -1.5350e-01,\n",
            "        -1.1543e-02,  5.0187e-01,  1.1578e-02, -2.4930e-01, -2.0656e-01,\n",
            "        -3.0383e-01, -5.4510e-01, -1.0860e-01,  1.8754e-01, -2.7037e-01,\n",
            "        -5.5385e-01, -4.1038e-01, -5.1683e-01,  7.2271e-01, -9.5301e-02,\n",
            "        -2.9001e-01, -2.9464e-01, -3.8007e-02, -3.3136e-01, -6.3899e-01,\n",
            "         7.3137e-01, -6.1092e-01,  2.3481e-02, -4.0825e-02,  5.2506e-01,\n",
            "        -3.7177e-02, -4.3512e-01, -6.0740e-01, -3.9093e-01, -1.8120e-01,\n",
            "         2.5929e-01,  2.3093e-01, -7.6359e-02, -5.3769e-02,  6.0097e-01,\n",
            "         6.0533e-01, -2.0536e-02,  2.3010e-01, -6.8389e-03, -2.8184e-01,\n",
            "        -4.9499e-02,  4.9698e-02,  6.5894e-02, -4.4617e-02, -1.3589e-01,\n",
            "        -2.6382e-01, -2.2977e-02, -5.5689e-01,  1.6805e-01, -2.8135e-01,\n",
            "         6.0520e-02, -3.2165e-01, -7.9562e-02, -3.7280e-01,  1.2916e-01,\n",
            "        -5.6053e-01, -1.0219e-02,  3.1639e-02,  2.1625e-02, -2.6218e-01,\n",
            "        -1.0120e-01,  1.4400e-01, -1.4723e-01,  2.5295e-02])\n",
            "torch.Size([21, 394])\n",
            "tensor([ -7.7000,  -5.3371,  -5.7759,  -1.6600,   4.0316,  -5.8258,  -5.2065,\n",
            "        -10.5021,  -5.3736,  -7.9062,  -6.0285,  -1.1088,  -5.8482,  -8.8559,\n",
            "          1.0120,  -0.9446,  -2.2047,   0.8024], grad_fn=<SelectBackward0>)\n",
            "tensor([-7.8302, -5.1779, -5.9843, -2.2460,  4.2192, -5.6607, -5.3319, -7.1776,\n",
            "        -5.0765, -8.0480, -6.1544, -1.4204, -5.0698, -5.4563, -0.3243, -1.0278,\n",
            "        -0.6705,  1.2505], grad_fn=<SelectBackward0>)\n",
            "torch.Size([21, 394])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1])\n",
            "In epoch 510, loss: 0.292, train acc: 0.906 (train 0.906), test acc: 0.238 (best 0.714)\n",
            "In epoch 515, loss: 0.280, train acc: 0.906 (train 0.906), test acc: 0.238 (best 0.714)\n",
            "In epoch 520, loss: 0.285, train acc: 0.894 (train 0.906), test acc: 0.238 (best 0.714)\n",
            "In epoch 525, loss: 0.281, train acc: 0.894 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 530, loss: 0.275, train acc: 0.894 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 535, loss: 0.262, train acc: 0.918 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 540, loss: 0.281, train acc: 0.918 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 545, loss: 0.324, train acc: 0.812 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 550, loss: 0.280, train acc: 0.906 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 555, loss: 0.263, train acc: 0.918 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 560, loss: 0.267, train acc: 0.918 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 565, loss: 0.315, train acc: 0.835 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 570, loss: 0.268, train acc: 0.906 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 575, loss: 0.262, train acc: 0.918 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 580, loss: 0.259, train acc: 0.918 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 585, loss: 0.307, train acc: 0.835 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 590, loss: 0.244, train acc: 0.906 (train 0.918), test acc: 0.238 (best 0.714)\n",
            "In epoch 595, loss: 0.294, train acc: 0.871 (train 0.918), test acc: 0.238 (best 0.714)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import torch\n",
        "from dgl.data import DGLDataset\n",
        "\n",
        "\n",
        "class KarateClubDataset(DGLDataset):\n",
        "    def __init__(self,params):\n",
        "        self.params=params\n",
        "        #self.threshold=threshold\n",
        "        super().__init__(name=\"karate_club\")\n",
        "        self.process()\n",
        "    def process(self):\n",
        "        edge_remove=[]\n",
        "        C=edge_weights\n",
        "        for i in range(0,len(C)):\n",
        "            if C[i]<=self.params['percentile']:\n",
        "                edge_remove.append(i)\n",
        "        nodes_data = Nodes_Data\n",
        "        edges_data = Edge_Data\n",
        "        features_array = np.array(nodes_data[\"features\"].tolist(), dtype=float)\n",
        "        node_features = torch.from_numpy(features_array)\n",
        "        node_labels = torch.from_numpy(\n",
        "                      nodes_data[\"label\"].astype(\"category\").cat.codes.to_numpy()\n",
        "                       ).clone().detach()\n",
        "        edge_features = torch.from_numpy(edges_data[\"edge weights\"].to_numpy())\n",
        "        edges_src = torch.from_numpy(edges_data[\"Src Ids\"].to_numpy())\n",
        "        edges_dst = torch.from_numpy(edges_data[\"Dst Ids\"].to_numpy())\n",
        "        self.graph = dgl.graph(\n",
        "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
        "        )\n",
        "        self.graph.ndata[\"feat\"] = node_features\n",
        "        self.graph.ndata[\"label\"] = node_labels\n",
        "        self.graph.edata[\"weight\"] = edge_features\n",
        "\n",
        "        self.graph=dgl.remove_edges(self.graph, torch.tensor(edge_remove))\n",
        "        n_nodes = nodes_data.shape[0]\n",
        "        n_train = int(n_nodes * 0.6)\n",
        "        n_val = int(n_nodes * 0.2)\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[:n_train] = True\n",
        "        val_mask[n_train : n_train + n_val] = True\n",
        "        test_mask[n_train + n_val :] = True\n",
        "        self.graph.ndata[\"train_mask\"] = train_mask\n",
        "        self.graph.ndata[\"val_mask\"] = val_mask\n",
        "        self.graph.ndata[\"test_mask\"] = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1"
      ],
      "metadata": {
        "id": "vOnTCKaZwBfm"
      },
      "id": "vOnTCKaZwBfm",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self,in_feats,params,num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, params['output_features'])\n",
        "        self.conv2 = GraphConv(params['output_features'], num_classes)\n",
        "\n",
        "    def forward(self, g,in_feat,params):\n",
        "        in_feat = in_feat.float()\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = getattr(F, params['activation'])(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "s98khP4RwRm4"
      },
      "id": "s98khP4RwRm4",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "los=[]\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "TT=[]\n",
        "CT=[]\n",
        "epoch=[]\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "def train(g,sg_train,sg_test, model,params):\n",
        "    model.train()\n",
        "    optimizer = getattr(optim, params['optimizer'])(model.parameters(), lr= params['learning_rate'])\n",
        "    best_train_acc = 0\n",
        "    best_test_acc = 0\n",
        "    corresponding_test=0\n",
        "\n",
        "    features_train = sg_train.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(sg_train,features_train,params)\n",
        "\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "\n",
        "        labels = g.ndata[\"label\"].long()\n",
        "        if params['loss'] == 'binary_cross_entropy':\n",
        "            loss = getattr(F, params['loss'])(torch.sigmoid(logits), labels[train_mask])\n",
        "        else:\n",
        "            loss = getattr(F, params['loss'])(logits, labels[train_mask])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            logits_test = model(sg_test,sg_test.ndata[\"feat\"],params)\n",
        "\n",
        "\n",
        "        pred_test = logits_test.argmax(1)\n",
        "\n",
        "        train_acc = (pred == labels[train_mask]).float().mean()\n",
        "        test_acc = (pred_test == labels[test_mask]).float().mean()\n",
        "\n",
        "        if best_train_acc < train_acc:\n",
        "            best_train_acc = train_acc\n",
        "            corresponding_test=test_acc\n",
        "        if best_test_acc < test_acc:\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            epoch.append(e)\n",
        "            los.append(round(loss.item(),3))\n",
        "            train_accuracy.append(round(train_acc.item(),3))\n",
        "\n",
        "    TT.append({'train_accuracy':best_train_acc})\n",
        "    CT.append({'test_accuracy': corresponding_test})\n",
        "\n",
        "    print(f'Train Accuracy: {best_train_acc}, Test Accuracy: {corresponding_test}')\n",
        "    return best_train_acc"
      ],
      "metadata": {
        "id": "ls8Rsgc5wSEd"
      },
      "id": "ls8Rsgc5wSEd",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgGHl72bwikI",
        "outputId": "d063da15-320f-42c5-968d-c0c7ad425a70"
      },
      "id": "fgGHl72bwikI",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentiles=[round(0.371543188964312,4)]"
      ],
      "metadata": {
        "id": "TEeEjr-gwipT"
      },
      "id": "TEeEjr-gwipT",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    percentile_values=[percentiles[0]]\n",
        "    learning_rate=[0.01,0.1,1,10,100,200]\n",
        "    output_features=[10,12,14,16,18,20,22]\n",
        "    params={'output_features':trial.suggest_categorical('output_features',output_features),\n",
        "           'optimizer':trial.suggest_categorical('optimizer',[\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "           'percentile':trial.suggest_categorical('percentile',percentile_values),\n",
        "           'learning_rate':trial.suggest_categorical('learning_rate',learning_rate),\n",
        "           'loss':trial.suggest_categorical('loss',['cross_entropy']),\n",
        "           'activation':trial.suggest_categorical('activation',['relu','selu','elu','leaky_relu','tanh'])}\n",
        "    dataset = KarateClubDataset(params)\n",
        "    g = dataset[0]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    for i in range(106):\n",
        "        train_mask[i] = True\n",
        "\n",
        "    indices_to_change = [4, 105, 84, 27, 98, 88, 18, 65, 9, 2, 5, 49, 99, 69, 86, 67, 7, 28, 78, 70, 18, 74]\n",
        "    train_mask[indices_to_change] = False\n",
        "    g.ndata[\"train_mask\"]=train_mask\n",
        "    test_mask = ~train_mask\n",
        "    g.ndata[\"test_mask\"]=test_mask\n",
        "    sg_train=dgl.node_subgraph(g, train_mask)\n",
        "    sg_test = dgl.node_subgraph(g, test_mask)\n",
        "    model=GCN(g.ndata[\"feat\"].shape[1],params, 2)\n",
        "    accuracy=train(g,sg_train,sg_test,model,params)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "rSyGDfHgwy1t"
      },
      "id": "rSyGDfHgwy1t",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=630)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpRxquLowy5P",
        "outputId": "353cfcbc-ddba-4899-a503-6fbad8a193e0"
      },
      "id": "bpRxquLowy5P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:30,223] A new study created in memory with name: no-name-91cc1826-7041-40c2-95ca-73459a4d92a6\n",
            "[I 2024-11-05 00:31:32,067] Trial 0 finished with value: 0.7882353067398071 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 0 with value: 0.7882353067398071.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7882353067398071, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:35,043] Trial 1 finished with value: 0.8470588326454163 and parameters: {'output_features': 12, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 1 with value: 0.8470588326454163.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:37,573] Trial 2 finished with value: 0.8235294222831726 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 1 with value: 0.8470588326454163.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:39,331] Trial 3 finished with value: 0.6470588445663452 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 1 with value: 0.8470588326454163.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6470588445663452, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:41,603] Trial 4 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 4 with value: 0.8705882430076599.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:43,439] Trial 5 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 4 with value: 0.8705882430076599.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.2380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:45,128] Trial 6 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 4 with value: 0.8705882430076599.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.2380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:47,881] Trial 7 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 4 with value: 0.8705882430076599.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:51,492] Trial 8 finished with value: 0.9058823585510254 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.8095238208770752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:53,736] Trial 9 finished with value: 0.6470588445663452 and parameters: {'output_features': 20, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6470588445663452, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:55,034] Trial 10 finished with value: 0.6823529601097107 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6823529601097107, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:56,205] Trial 11 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:57,598] Trial 12 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:59,157] Trial 13 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:31:59,981] Trial 14 finished with value: 0.8352941274642944 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:00,622] Trial 15 finished with value: 0.8117647171020508 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:01,327] Trial 16 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.8571428656578064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:02,153] Trial 17 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:03,007] Trial 18 finished with value: 0.8588235378265381 and parameters: {'output_features': 10, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:03,893] Trial 19 finished with value: 0.6941176652908325 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6941176652908325, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:04,661] Trial 20 finished with value: 0.8470588326454163 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:05,284] Trial 21 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:05,928] Trial 22 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:06,565] Trial 23 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:07,189] Trial 24 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:07,828] Trial 25 finished with value: 0.7529411911964417 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7529411911964417, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:08,461] Trial 26 finished with value: 0.658823549747467 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:09,085] Trial 27 finished with value: 0.7647058963775635 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7647058963775635, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:09,727] Trial 28 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:10,327] Trial 29 finished with value: 0.658823549747467 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:10,959] Trial 30 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:11,590] Trial 31 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:12,212] Trial 32 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:12,851] Trial 33 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:13,461] Trial 34 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:14,105] Trial 35 finished with value: 0.729411780834198 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.729411780834198, Test Accuracy: 0.2857142984867096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:14,920] Trial 36 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:15,744] Trial 37 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:16,949] Trial 38 finished with value: 0.8235294222831726 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:17,705] Trial 39 finished with value: 0.6470588445663452 and parameters: {'output_features': 16, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6470588445663452, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:18,332] Trial 40 finished with value: 0.6823529601097107 and parameters: {'output_features': 22, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6823529601097107, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:18,969] Trial 41 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:19,603] Trial 42 finished with value: 0.8941176533699036 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:20,234] Trial 43 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:20,868] Trial 44 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:21,489] Trial 45 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:22,124] Trial 46 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:22,749] Trial 47 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:23,348] Trial 48 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:23,991] Trial 49 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:24,617] Trial 50 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:25,251] Trial 51 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:25,889] Trial 52 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:26,521] Trial 53 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:27,152] Trial 54 finished with value: 0.658823549747467 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:27,932] Trial 55 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:28,809] Trial 56 finished with value: 0.7647058963775635 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7647058963775635, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:29,725] Trial 57 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:30,693] Trial 58 finished with value: 0.8352941274642944 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:31,420] Trial 59 finished with value: 0.7647058963775635 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7647058963775635, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:32,059] Trial 60 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:32,718] Trial 61 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:33,351] Trial 62 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:33,995] Trial 63 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:34,636] Trial 64 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:35,263] Trial 65 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:35,912] Trial 66 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:36,555] Trial 67 finished with value: 0.6941176652908325 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6941176652908325, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:37,183] Trial 68 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:37,830] Trial 69 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:38,464] Trial 70 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:39,103] Trial 71 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:39,744] Trial 72 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:40,370] Trial 73 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:41,022] Trial 74 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:41,882] Trial 75 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:43,015] Trial 76 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:43,932] Trial 77 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:44,661] Trial 78 finished with value: 0.8117647171020508 and parameters: {'output_features': 12, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:45,310] Trial 79 finished with value: 0.8117647171020508 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:45,943] Trial 80 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:46,570] Trial 81 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:47,232] Trial 82 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:47,885] Trial 83 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:48,519] Trial 84 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:49,162] Trial 85 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:49,823] Trial 86 finished with value: 0.8470588326454163 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:50,435] Trial 87 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:51,079] Trial 88 finished with value: 0.9058823585510254 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:51,699] Trial 89 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:52,333] Trial 90 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:52,981] Trial 91 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 8 with value: 0.9058823585510254.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:53,608] Trial 92 finished with value: 0.9176470637321472 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:54,239] Trial 93 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:55,069] Trial 94 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:55,895] Trial 95 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:56,763] Trial 96 finished with value: 0.7058823704719543 and parameters: {'output_features': 20, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7058823704719543, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:57,688] Trial 97 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:58,456] Trial 98 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:59,103] Trial 99 finished with value: 0.9058823585510254 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:32:59,736] Trial 100 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:00,381] Trial 101 finished with value: 0.9058823585510254 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:01,006] Trial 102 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:01,641] Trial 103 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:02,290] Trial 104 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:02,921] Trial 105 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:03,566] Trial 106 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:04,209] Trial 107 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:04,852] Trial 108 finished with value: 0.658823549747467 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:05,491] Trial 109 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:06,121] Trial 110 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:06,761] Trial 111 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:07,397] Trial 112 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:08,030] Trial 113 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:08,869] Trial 114 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:09,714] Trial 115 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:10,580] Trial 116 finished with value: 0.6941176652908325 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6941176652908325, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:11,427] Trial 117 finished with value: 0.9058823585510254 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:12,067] Trial 118 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:12,953] Trial 119 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:14,284] Trial 120 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:15,385] Trial 121 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:16,706] Trial 122 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:17,353] Trial 123 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:18,002] Trial 124 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:18,636] Trial 125 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:19,292] Trial 126 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:20,080] Trial 127 finished with value: 0.8117647171020508 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:20,707] Trial 128 finished with value: 0.8470588326454163 and parameters: {'output_features': 12, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.2380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:21,419] Trial 129 finished with value: 0.9176470637321472 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:22,280] Trial 130 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:23,176] Trial 131 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:25,183] Trial 132 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:26,101] Trial 133 finished with value: 0.8352941274642944 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:26,998] Trial 134 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:27,650] Trial 135 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:28,293] Trial 136 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:28,922] Trial 137 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:29,569] Trial 138 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:30,177] Trial 139 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:30,811] Trial 140 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:31,454] Trial 141 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:32,080] Trial 142 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:32,728] Trial 143 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:33,364] Trial 144 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:33,989] Trial 145 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:34,632] Trial 146 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:35,402] Trial 147 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:36,218] Trial 148 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:37,132] Trial 149 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:38,055] Trial 150 finished with value: 0.729411780834198 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.729411780834198, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:38,879] Trial 151 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:39,505] Trial 152 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:40,152] Trial 153 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:40,803] Trial 154 finished with value: 0.7882353067398071 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7882353067398071, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:41,431] Trial 155 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:42,070] Trial 156 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:42,725] Trial 157 finished with value: 0.7058823704719543 and parameters: {'output_features': 16, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7058823704719543, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:43,358] Trial 158 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:43,996] Trial 159 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:44,625] Trial 160 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:45,268] Trial 161 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:45,909] Trial 162 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:46,547] Trial 163 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:47,198] Trial 164 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:47,852] Trial 165 finished with value: 0.8588235378265381 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:48,495] Trial 166 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:49,301] Trial 167 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:50,106] Trial 168 finished with value: 0.8235294222831726 and parameters: {'output_features': 16, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:51,033] Trial 169 finished with value: 0.9058823585510254 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:51,938] Trial 170 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:52,759] Trial 171 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:53,401] Trial 172 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:54,041] Trial 173 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:54,675] Trial 174 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:55,313] Trial 175 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:55,943] Trial 176 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:56,590] Trial 177 finished with value: 0.7764706015586853 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7764706015586853, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:57,249] Trial 178 finished with value: 0.9058823585510254 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:57,892] Trial 179 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:58,556] Trial 180 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:33:59,293] Trial 181 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:00,169] Trial 182 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:01,076] Trial 183 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:01,997] Trial 184 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:02,962] Trial 185 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:03,839] Trial 186 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:04,725] Trial 187 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:05,677] Trial 188 finished with value: 0.800000011920929 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:06,319] Trial 189 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:06,957] Trial 190 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:07,609] Trial 191 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:08,251] Trial 192 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:08,901] Trial 193 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:09,539] Trial 194 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:10,255] Trial 195 finished with value: 0.8117647171020508 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:10,909] Trial 196 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:11,552] Trial 197 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:12,185] Trial 198 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:12,802] Trial 199 finished with value: 0.6823529601097107 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6823529601097107, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:13,442] Trial 200 finished with value: 0.8235294222831726 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:14,088] Trial 201 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:14,752] Trial 202 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:15,380] Trial 203 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:16,172] Trial 204 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:17,022] Trial 205 finished with value: 0.8117647171020508 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:17,956] Trial 206 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:18,900] Trial 207 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:19,536] Trial 208 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:20,199] Trial 209 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:20,835] Trial 210 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:21,484] Trial 211 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:22,131] Trial 212 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:22,769] Trial 213 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:23,403] Trial 214 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:24,041] Trial 215 finished with value: 0.8941176533699036 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:24,696] Trial 216 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:25,334] Trial 217 finished with value: 0.8235294222831726 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:25,976] Trial 218 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:26,602] Trial 219 finished with value: 0.8352941274642944 and parameters: {'output_features': 14, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:27,237] Trial 220 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:27,886] Trial 221 finished with value: 0.9176470637321472 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:28,542] Trial 222 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:29,294] Trial 223 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:30,132] Trial 224 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:31,068] Trial 225 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:31,994] Trial 226 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:32,674] Trial 227 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:33,301] Trial 228 finished with value: 0.6941176652908325 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6941176652908325, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:33,945] Trial 229 finished with value: 0.8588235378265381 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:34,598] Trial 230 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:35,242] Trial 231 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:35,888] Trial 232 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:36,543] Trial 233 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:37,180] Trial 234 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:37,833] Trial 235 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:38,456] Trial 236 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:39,111] Trial 237 finished with value: 0.8235294222831726 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:39,758] Trial 238 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:40,389] Trial 239 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:41,012] Trial 240 finished with value: 0.8235294222831726 and parameters: {'output_features': 18, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:41,678] Trial 241 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:42,449] Trial 242 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:43,307] Trial 243 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:44,238] Trial 244 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:45,196] Trial 245 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:45,842] Trial 246 finished with value: 0.7411764860153198 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7411764860153198, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:46,477] Trial 247 finished with value: 0.800000011920929 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:47,130] Trial 248 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:47,781] Trial 249 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:48,414] Trial 250 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:49,064] Trial 251 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 92 with value: 0.9176470637321472.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:49,704] Trial 252 finished with value: 0.929411768913269 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.929411768913269, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:50,371] Trial 253 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:51,016] Trial 254 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:51,661] Trial 255 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:52,307] Trial 256 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:52,939] Trial 257 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.2857142984867096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:53,593] Trial 258 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:54,245] Trial 259 finished with value: 0.7764706015586853 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7764706015586853, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:54,889] Trial 260 finished with value: 0.8588235378265381 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:55,700] Trial 261 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:56,523] Trial 262 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:57,469] Trial 263 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:58,339] Trial 264 finished with value: 0.6470588445663452 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6470588445663452, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:58,976] Trial 265 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:34:59,622] Trial 266 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:00,252] Trial 267 finished with value: 0.8470588326454163 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:01,043] Trial 268 finished with value: 0.8352941274642944 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:01,696] Trial 269 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:02,340] Trial 270 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:02,977] Trial 271 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:03,622] Trial 272 finished with value: 0.8470588326454163 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:04,262] Trial 273 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:04,914] Trial 274 finished with value: 0.7647058963775635 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7647058963775635, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:05,562] Trial 275 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:06,193] Trial 276 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:06,831] Trial 277 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:07,470] Trial 278 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:08,116] Trial 279 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:08,950] Trial 280 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:09,816] Trial 281 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:10,768] Trial 282 finished with value: 0.9058823585510254 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:11,621] Trial 283 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:12,267] Trial 284 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:12,922] Trial 285 finished with value: 0.800000011920929 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:13,566] Trial 286 finished with value: 0.7176470756530762 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7176470756530762, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:14,179] Trial 287 finished with value: 0.8352941274642944 and parameters: {'output_features': 20, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:14,828] Trial 288 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:15,460] Trial 289 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:16,118] Trial 290 finished with value: 0.800000011920929 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:16,758] Trial 291 finished with value: 0.658823549747467 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:17,406] Trial 292 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:18,060] Trial 293 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:18,699] Trial 294 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:19,345] Trial 295 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:19,991] Trial 296 finished with value: 0.8352941274642944 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:20,658] Trial 297 finished with value: 0.6941176652908325 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6941176652908325, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:21,296] Trial 298 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:22,130] Trial 299 finished with value: 0.9176470637321472 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:22,973] Trial 300 finished with value: 0.8352941274642944 and parameters: {'output_features': 14, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:23,905] Trial 301 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:24,807] Trial 302 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:25,583] Trial 303 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:26,214] Trial 304 finished with value: 0.8117647171020508 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:26,878] Trial 305 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:27,517] Trial 306 finished with value: 0.800000011920929 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:28,161] Trial 307 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:28,806] Trial 308 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:29,471] Trial 309 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:30,082] Trial 310 finished with value: 0.8117647171020508 and parameters: {'output_features': 18, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:30,716] Trial 311 finished with value: 0.8588235378265381 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:31,342] Trial 312 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:31,988] Trial 313 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:32,636] Trial 314 finished with value: 0.7529411911964417 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7529411911964417, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:33,276] Trial 315 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:33,931] Trial 316 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:34,577] Trial 317 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:35,229] Trial 318 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:36,097] Trial 319 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:36,970] Trial 320 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:37,914] Trial 321 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:38,662] Trial 322 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:39,299] Trial 323 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:39,957] Trial 324 finished with value: 0.8117647171020508 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:40,604] Trial 325 finished with value: 0.9058823585510254 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:41,254] Trial 326 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.8571428656578064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:41,998] Trial 327 finished with value: 0.8470588326454163 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:42,633] Trial 328 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:43,277] Trial 329 finished with value: 0.9058823585510254 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:43,920] Trial 330 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:44,554] Trial 331 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:45,205] Trial 332 finished with value: 0.8588235378265381 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:45,850] Trial 333 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:46,488] Trial 334 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:47,114] Trial 335 finished with value: 0.8235294222831726 and parameters: {'output_features': 16, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:47,766] Trial 336 finished with value: 0.9058823585510254 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:48,493] Trial 337 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:49,344] Trial 338 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:50,244] Trial 339 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:51,235] Trial 340 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:51,911] Trial 341 finished with value: 0.9176470637321472 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:52,555] Trial 342 finished with value: 0.9058823585510254 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:53,194] Trial 343 finished with value: 0.8588235378265381 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:53,820] Trial 344 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:54,457] Trial 345 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:55,082] Trial 346 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:55,751] Trial 347 finished with value: 0.8823529481887817 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:56,388] Trial 348 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:57,012] Trial 349 finished with value: 0.8588235378265381 and parameters: {'output_features': 12, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:57,660] Trial 350 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:58,303] Trial 351 finished with value: 0.8588235378265381 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:58,940] Trial 352 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:35:59,588] Trial 353 finished with value: 0.8588235378265381 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:00,235] Trial 354 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:00,881] Trial 355 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:01,598] Trial 356 finished with value: 0.7647058963775635 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7647058963775635, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:02,442] Trial 357 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:03,324] Trial 358 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:04,226] Trial 359 finished with value: 0.8235294222831726 and parameters: {'output_features': 12, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:04,974] Trial 360 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:05,627] Trial 361 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:06,271] Trial 362 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:06,916] Trial 363 finished with value: 0.7058823704719543 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7058823704719543, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:07,555] Trial 364 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:08,196] Trial 365 finished with value: 0.9058823585510254 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:08,851] Trial 366 finished with value: 0.8470588326454163 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:09,480] Trial 367 finished with value: 0.8470588326454163 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:10,126] Trial 368 finished with value: 0.8470588326454163 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:10,790] Trial 369 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:11,425] Trial 370 finished with value: 0.9058823585510254 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:12,070] Trial 371 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:12,705] Trial 372 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:13,352] Trial 373 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:14,000] Trial 374 finished with value: 0.9058823585510254 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:14,690] Trial 375 finished with value: 0.8588235378265381 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:15,547] Trial 376 finished with value: 0.8941176533699036 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:16,445] Trial 377 finished with value: 0.8588235378265381 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:17,390] Trial 378 finished with value: 0.8588235378265381 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:18,253] Trial 379 finished with value: 0.7882353067398071 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7882353067398071, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:18,889] Trial 380 finished with value: 0.9176470637321472 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:19,542] Trial 381 finished with value: 0.8588235378265381 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:20,154] Trial 382 finished with value: 0.8235294222831726 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:20,833] Trial 383 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:21,480] Trial 384 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:22,132] Trial 385 finished with value: 0.7176470756530762 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7176470756530762, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:22,769] Trial 386 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:23,413] Trial 387 finished with value: 0.8941176533699036 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:24,052] Trial 388 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:24,708] Trial 389 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:25,368] Trial 390 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:26,012] Trial 391 finished with value: 0.6823529601097107 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6823529601097107, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:26,673] Trial 392 finished with value: 0.8352941274642944 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:27,325] Trial 393 finished with value: 0.9058823585510254 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:27,973] Trial 394 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:28,825] Trial 395 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.2857142984867096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:29,669] Trial 396 finished with value: 0.8470588326454163 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:30,594] Trial 397 finished with value: 0.800000011920929 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:31,433] Trial 398 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:32,083] Trial 399 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:32,748] Trial 400 finished with value: 0.8588235378265381 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:33,404] Trial 401 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:34,053] Trial 402 finished with value: 0.8117647171020508 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:34,710] Trial 403 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:35,348] Trial 404 finished with value: 0.8705882430076599 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:35,973] Trial 405 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:36,617] Trial 406 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:37,253] Trial 407 finished with value: 0.8823529481887817 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:37,915] Trial 408 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:38,555] Trial 409 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:39,203] Trial 410 finished with value: 0.9176470637321472 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:39,856] Trial 411 finished with value: 0.800000011920929 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:40,494] Trial 412 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:41,141] Trial 413 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:42,026] Trial 414 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:42,928] Trial 415 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:43,889] Trial 416 finished with value: 0.8117647171020508 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:44,825] Trial 417 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:45,515] Trial 418 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:46,172] Trial 419 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:46,817] Trial 420 finished with value: 0.8588235378265381 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:47,476] Trial 421 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:48,133] Trial 422 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:48,776] Trial 423 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:49,423] Trial 424 finished with value: 0.8588235378265381 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:50,068] Trial 425 finished with value: 0.800000011920929 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:50,718] Trial 426 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:51,373] Trial 427 finished with value: 0.7529411911964417 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7529411911964417, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:52,022] Trial 428 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:52,665] Trial 429 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:53,310] Trial 430 finished with value: 0.8470588326454163 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:53,952] Trial 431 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:54,609] Trial 432 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:55,398] Trial 433 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:56,243] Trial 434 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:57,270] Trial 435 finished with value: 0.8352941274642944 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:58,203] Trial 436 finished with value: 0.8352941274642944 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:59,032] Trial 437 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:36:59,686] Trial 438 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:00,326] Trial 439 finished with value: 0.8941176533699036 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:00,983] Trial 440 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:01,637] Trial 441 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:02,282] Trial 442 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:02,939] Trial 443 finished with value: 0.8470588326454163 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:03,581] Trial 444 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:04,232] Trial 445 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:04,889] Trial 446 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:05,531] Trial 447 finished with value: 0.6823529601097107 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6823529601097107, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:06,184] Trial 448 finished with value: 0.8470588326454163 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.2857142984867096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:06,810] Trial 449 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:07,454] Trial 450 finished with value: 0.7647058963775635 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7647058963775635, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:08,105] Trial 451 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:08,746] Trial 452 finished with value: 0.8941176533699036 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:09,627] Trial 453 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:10,510] Trial 454 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:11,439] Trial 455 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:12,386] Trial 456 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:13,060] Trial 457 finished with value: 0.7882353067398071 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7882353067398071, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:13,700] Trial 458 finished with value: 0.9058823585510254 and parameters: {'output_features': 12, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:14,341] Trial 459 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:14,979] Trial 460 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:15,623] Trial 461 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:16,269] Trial 462 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:16,937] Trial 463 finished with value: 0.7764706015586853 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7764706015586853, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:17,594] Trial 464 finished with value: 0.8705882430076599 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:18,249] Trial 465 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:18,896] Trial 466 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:19,564] Trial 467 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:20,217] Trial 468 finished with value: 0.9176470637321472 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:20,897] Trial 469 finished with value: 0.7529411911964417 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7529411911964417, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:21,549] Trial 470 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:22,156] Trial 471 finished with value: 0.7058823704719543 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7058823704719543, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:22,968] Trial 472 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:23,812] Trial 473 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:24,763] Trial 474 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:25,699] Trial 475 finished with value: 0.658823549747467 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:26,513] Trial 476 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:27,169] Trial 477 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:27,836] Trial 478 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:28,472] Trial 479 finished with value: 0.9176470637321472 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:29,133] Trial 480 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:29,795] Trial 481 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:30,438] Trial 482 finished with value: 0.8235294222831726 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:31,100] Trial 483 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:31,754] Trial 484 finished with value: 0.7529411911964417 and parameters: {'output_features': 14, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7529411911964417, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:32,398] Trial 485 finished with value: 0.8705882430076599 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:33,061] Trial 486 finished with value: 0.8470588326454163 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:33,716] Trial 487 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:34,357] Trial 488 finished with value: 0.8235294222831726 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:35,024] Trial 489 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:35,660] Trial 490 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:36,376] Trial 491 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:37,258] Trial 492 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:38,290] Trial 493 finished with value: 0.9058823585510254 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:39,276] Trial 494 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:40,315] Trial 495 finished with value: 0.6705882549285889 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6705882549285889, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:41,427] Trial 496 finished with value: 0.8117647171020508 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:42,356] Trial 497 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:43,009] Trial 498 finished with value: 0.8470588326454163 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:43,669] Trial 499 finished with value: 0.7058823704719543 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7058823704719543, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:44,323] Trial 500 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:44,974] Trial 501 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:45,642] Trial 502 finished with value: 0.8117647171020508 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:46,297] Trial 503 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:46,951] Trial 504 finished with value: 0.8588235378265381 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:47,615] Trial 505 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:48,269] Trial 506 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:48,934] Trial 507 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:49,585] Trial 508 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:50,230] Trial 509 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.8095238208770752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:50,905] Trial 510 finished with value: 0.8823529481887817 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:51,553] Trial 511 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:52,423] Trial 512 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:53,288] Trial 513 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:54,217] Trial 514 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:55,145] Trial 515 finished with value: 0.8235294222831726 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:55,853] Trial 516 finished with value: 0.9058823585510254 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:56,441] Trial 517 finished with value: 0.658823549747467 and parameters: {'output_features': 10, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:57,114] Trial 518 finished with value: 0.8470588326454163 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:57,781] Trial 519 finished with value: 0.6823529601097107 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6823529601097107, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:58,424] Trial 520 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:59,079] Trial 521 finished with value: 0.8705882430076599 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:37:59,718] Trial 522 finished with value: 0.8941176533699036 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:00,368] Trial 523 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:01,028] Trial 524 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:01,671] Trial 525 finished with value: 0.8117647171020508 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:02,329] Trial 526 finished with value: 0.8117647171020508 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8117647171020508, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:02,987] Trial 527 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:03,630] Trial 528 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:04,271] Trial 529 finished with value: 0.800000011920929 and parameters: {'output_features': 22, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:04,922] Trial 530 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:05,690] Trial 531 finished with value: 0.800000011920929 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:06,548] Trial 532 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:07,460] Trial 533 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:08,390] Trial 534 finished with value: 0.8588235378265381 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:09,263] Trial 535 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:09,914] Trial 536 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'selu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:10,589] Trial 537 finished with value: 0.6823529601097107 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.6823529601097107, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:11,234] Trial 538 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:11,878] Trial 539 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:12,543] Trial 540 finished with value: 0.8470588326454163 and parameters: {'output_features': 22, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:13,198] Trial 541 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:13,855] Trial 542 finished with value: 0.9176470637321472 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9176470637321472, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:14,502] Trial 543 finished with value: 0.8352941274642944 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:15,144] Trial 544 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:15,792] Trial 545 finished with value: 0.9058823585510254 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:16,441] Trial 546 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:17,098] Trial 547 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:17,747] Trial 548 finished with value: 0.729411780834198 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.729411780834198, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:18,403] Trial 549 finished with value: 0.8823529481887817 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:19,049] Trial 550 finished with value: 0.8941176533699036 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:19,895] Trial 551 finished with value: 0.8705882430076599 and parameters: {'output_features': 16, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.380952388048172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:20,783] Trial 552 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:21,727] Trial 553 finished with value: 0.800000011920929 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:22,654] Trial 554 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:23,306] Trial 555 finished with value: 0.8470588326454163 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:23,964] Trial 556 finished with value: 0.8823529481887817 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:24,601] Trial 557 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:25,281] Trial 558 finished with value: 0.8588235378265381 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 1, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:25,940] Trial 559 finished with value: 0.8588235378265381 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:26,565] Trial 560 finished with value: 0.658823549747467 and parameters: {'output_features': 14, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.658823549747467, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:27,229] Trial 561 finished with value: 0.8588235378265381 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:27,888] Trial 562 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.8095238208770752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:28,536] Trial 563 finished with value: 0.9058823585510254 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9058823585510254, Test Accuracy: 0.3333333432674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:29,186] Trial 564 finished with value: 0.8705882430076599 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:29,836] Trial 565 finished with value: 0.8588235378265381 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8588235378265381, Test Accuracy: 0.4761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:30,489] Trial 566 finished with value: 0.7411764860153198 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 10, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.7411764860153198, Test Accuracy: 0.4285714328289032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:31,149] Trial 567 finished with value: 0.800000011920929 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:31,798] Trial 568 finished with value: 0.8470588326454163 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.761904776096344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:32,458] Trial 569 finished with value: 0.8352941274642944 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8352941274642944, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:33,316] Trial 570 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'leaky_relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:34,158] Trial 571 finished with value: 0.8470588326454163 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:35,103] Trial 572 finished with value: 0.8941176533699036 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:36,050] Trial 573 finished with value: 0.8470588326454163 and parameters: {'output_features': 12, 'optimizer': 'RMSprop', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'elu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:36,714] Trial 574 finished with value: 0.800000011920929 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 100, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.800000011920929, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:37,360] Trial 575 finished with value: 0.8823529481887817 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:38,005] Trial 576 finished with value: 0.8941176533699036 and parameters: {'output_features': 16, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'tanh'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.523809552192688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:38,672] Trial 577 finished with value: 0.8470588326454163 and parameters: {'output_features': 10, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8470588326454163, Test Accuracy: 0.8095238208770752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:39,321] Trial 578 finished with value: 0.8941176533699036 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.7142857313156128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:39,965] Trial 579 finished with value: 0.8941176533699036 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8941176533699036, Test Accuracy: 0.6190476417541504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:40,618] Trial 580 finished with value: 0.8705882430076599 and parameters: {'output_features': 14, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.01, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8705882430076599, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:41,278] Trial 581 finished with value: 0.8235294222831726 and parameters: {'output_features': 20, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 200, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.6666666865348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:41,893] Trial 582 finished with value: 0.8235294222831726 and parameters: {'output_features': 22, 'optimizer': 'SGD', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8235294222831726, Test Accuracy: 0.5714285969734192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-11-05 00:38:42,560] Trial 583 finished with value: 0.8823529481887817 and parameters: {'output_features': 18, 'optimizer': 'Adam', 'percentile': 0.3715, 'learning_rate': 0.1, 'loss': 'cross_entropy', 'activation': 'relu'}. Best is trial 252 with value: 0.929411768913269.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.8823529481887817, Test Accuracy: 0.7142857313156128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "# Assuming CT is a list of dictionaries and each dictionary has a 'test_accuracy' key\n",
        "top_ten_max_results = heapq.nlargest(50, enumerate(CT), key=lambda x: x[1]['test_accuracy'])\n",
        "\n",
        "# Print the top ten results along with their indices\n",
        "for index, result in top_ten_max_results:\n",
        "    print(f'Index: {index}, Test Accuracy: {result[\"test_accuracy\"]}')"
      ],
      "metadata": {
        "id": "_M3gBwZJxu6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602d10d8-3e15-44a0-da55-b0fdffe349e0"
      },
      "id": "_M3gBwZJxu6I",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 16, Test Accuracy: 0.8571428656578064\n",
            "Index: 326, Test Accuracy: 0.8571428656578064\n",
            "Index: 8, Test Accuracy: 0.8095238208770752\n",
            "Index: 509, Test Accuracy: 0.8095238208770752\n",
            "Index: 562, Test Accuracy: 0.8095238208770752\n",
            "Index: 577, Test Accuracy: 0.8095238208770752\n",
            "Index: 601, Test Accuracy: 0.8095238208770752\n",
            "Index: 28, Test Accuracy: 0.761904776096344\n",
            "Index: 97, Test Accuracy: 0.761904776096344\n",
            "Index: 139, Test Accuracy: 0.761904776096344\n",
            "Index: 267, Test Accuracy: 0.761904776096344\n",
            "Index: 394, Test Accuracy: 0.761904776096344\n",
            "Index: 417, Test Accuracy: 0.761904776096344\n",
            "Index: 498, Test Accuracy: 0.761904776096344\n",
            "Index: 503, Test Accuracy: 0.761904776096344\n",
            "Index: 568, Test Accuracy: 0.761904776096344\n",
            "Index: 584, Test Accuracy: 0.761904776096344\n",
            "Index: 591, Test Accuracy: 0.761904776096344\n",
            "Index: 598, Test Accuracy: 0.761904776096344\n",
            "Index: 12, Test Accuracy: 0.7142857313156128\n",
            "Index: 27, Test Accuracy: 0.7142857313156128\n",
            "Index: 33, Test Accuracy: 0.7142857313156128\n",
            "Index: 34, Test Accuracy: 0.7142857313156128\n",
            "Index: 36, Test Accuracy: 0.7142857313156128\n",
            "Index: 57, Test Accuracy: 0.7142857313156128\n",
            "Index: 80, Test Accuracy: 0.7142857313156128\n",
            "Index: 82, Test Accuracy: 0.7142857313156128\n",
            "Index: 105, Test Accuracy: 0.7142857313156128\n",
            "Index: 114, Test Accuracy: 0.7142857313156128\n",
            "Index: 120, Test Accuracy: 0.7142857313156128\n",
            "Index: 124, Test Accuracy: 0.7142857313156128\n",
            "Index: 131, Test Accuracy: 0.7142857313156128\n",
            "Index: 134, Test Accuracy: 0.7142857313156128\n",
            "Index: 136, Test Accuracy: 0.7142857313156128\n",
            "Index: 153, Test Accuracy: 0.7142857313156128\n",
            "Index: 156, Test Accuracy: 0.7142857313156128\n",
            "Index: 158, Test Accuracy: 0.7142857313156128\n",
            "Index: 173, Test Accuracy: 0.7142857313156128\n",
            "Index: 180, Test Accuracy: 0.7142857313156128\n",
            "Index: 182, Test Accuracy: 0.7142857313156128\n",
            "Index: 190, Test Accuracy: 0.7142857313156128\n",
            "Index: 200, Test Accuracy: 0.7142857313156128\n",
            "Index: 207, Test Accuracy: 0.7142857313156128\n",
            "Index: 210, Test Accuracy: 0.7142857313156128\n",
            "Index: 228, Test Accuracy: 0.7142857313156128\n",
            "Index: 253, Test Accuracy: 0.7142857313156128\n",
            "Index: 254, Test Accuracy: 0.7142857313156128\n",
            "Index: 255, Test Accuracy: 0.7142857313156128\n",
            "Index: 260, Test Accuracy: 0.7142857313156128\n",
            "Index: 294, Test Accuracy: 0.7142857313156128\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}