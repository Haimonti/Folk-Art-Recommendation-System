{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5269fd86",
      "metadata": {
        "id": "5269fd86"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import os\n",
        "from natsort import natsorted\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import string\n",
        "from numpy.linalg import norm\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import FastText\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import dgl.data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense,Bidirectional\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "from dgl.nn import GraphConv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import os\n",
        "from natsort import natsorted\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import FastText\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import dgl.data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense,Bidirectional\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
        "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7g88TYNFQ9PW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g88TYNFQ9PW",
        "outputId": "d623853e-f067-48f7-e086-ecd9339e2a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.13.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, nvidia-cusolver-cu12, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torch_geometric-2.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl torch_geometric tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78493f0c-b58b-45b4-8979-c48b0adc3428",
      "metadata": {
        "id": "78493f0c-b58b-45b4-8979-c48b0adc3428"
      },
      "outputs": [],
      "source": [
        "model= DenseNet121()\n",
        "model1=Model(inputs=model.inputs,outputs=model.layers[-2].output)\n",
        "print(model1.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b3e9f7-a59a-43c8-80eb-3f565637ea10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5b3e9f7-a59a-43c8-80eb-3f565637ea10",
        "outputId": "95771461-f8a9-4acc-e85a-3f3aa69ba08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d58485c-a94a-4de2-a603-c0179e9aa7fa",
      "metadata": {
        "id": "1d58485c-a94a-4de2-a603-c0179e9aa7fa"
      },
      "outputs": [],
      "source": [
        "print(model1.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3abe0404-2e1f-4818-a194-57eccea695ed",
      "metadata": {
        "id": "3abe0404-2e1f-4818-a194-57eccea695ed"
      },
      "outputs": [],
      "source": [
        "column_names = [f\"col_{i}\" for i in range(1024)]\n",
        "Image_dataframe = pd.DataFrame(columns=column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eXXGoA8USiVE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXXGoA8USiVE",
        "outputId": "9fe7874b-5a45-4465-89d3-c07aa8bb4fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of the extracted subfolder: ['s8', 's7', 's9', 's1', 's5', 's2', 's10', 's6', 's13', 's4', 's11', 's3', '.DS_Store', 's12']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Replace 'your_uploaded_zip_file.zip' with the actual name of your uploaded zip file\n",
        "zip_file_path = '/content/Image_text_data_Project.zip'\n",
        "extracted_folder_path = '/content/extracted_folder/'\n",
        "\n",
        "# Create the target directory for extraction\n",
        "os.makedirs(extracted_folder_path, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# Check the contents of the extracted folder\n",
        "extracted_subfolder = os.path.join(extracted_folder_path, 'Image_text_data_Project')\n",
        "extracted_subfolder_contents = os.listdir(extracted_subfolder)\n",
        "print(\"Contents of the extracted subfolder:\", extracted_subfolder_contents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd14b57-371e-4895-baf4-585c0f4d5989",
      "metadata": {
        "id": "2dd14b57-371e-4895-baf4-585c0f4d5989"
      },
      "outputs": [],
      "source": [
        "def Images_read(root_directory):\n",
        "    file_list = [file for file in os.listdir(root_directory) if not file.startswith('.DS_Store')]\n",
        "    file_list = natsorted(file_list)\n",
        "   # print(file_list)\n",
        "    for subdirectory in file_list:\n",
        "        subdirectory_path = os.path.join(os.path.sep,root_directory, subdirectory, 'img')\n",
        "        file_list_t = [file for file in os.listdir(subdirectory_path) if not file.startswith('.DS_Store')]\n",
        "        file_list_t = natsorted(file_list_t)\n",
        "        B=[]\n",
        "        for filename in file_list_t:\n",
        "            file_path = os.path.join(subdirectory_path, filename)\n",
        "            #print(file_path)\n",
        "            img = cv2.imread(file_path, 1)\n",
        "            R_img = cv2.resize(img, (224, 224))\n",
        "                #R_img.shape\n",
        "            reshaped_img = np.reshape(R_img, (1, 224, 224, 3))\n",
        "            features=model1.predict(reshaped_img,verbose=0)\n",
        "            Image_dataframe.loc[Image_dataframe.shape[0]+1] = features.reshape(-1)\n",
        "    return  Image_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b28969-b59d-4089-9e66-38886c82d8c3",
      "metadata": {
        "id": "18b28969-b59d-4089-9e66-38886c82d8c3"
      },
      "outputs": [],
      "source": [
        "dataframe=Images_read(extracted_subfolder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37023744-34c6-4246-9df1-001161aed2aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37023744-34c6-4246-9df1-001161aed2aa",
        "outputId": "79ef5702-525a-4456-ddf8-7815553b5693"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7e1cd46-f66c-49d8-8c8a-92bd382150b5",
      "metadata": {
        "id": "a7e1cd46-f66c-49d8-8c8a-92bd382150b5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=100)\n",
        "pca.fit(dataframe)\n",
        "\n",
        "# Get the principal components and explained variance ratio\n",
        "components = pca.components_\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Project the data onto the principal components\n",
        "transformed_data = pd.DataFrame(pca.transform(dataframe))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ce0479-4669-462f-bc90-1dd79dbb31d6",
      "metadata": {
        "id": "73ce0479-4669-462f-bc90-1dd79dbb31d6"
      },
      "outputs": [],
      "source": [
        "X_train=transformed_data.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3ce829-933d-4e1e-9389-0c895b18f872",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb3ce829-933d-4e1e-9389-0c895b18f872",
        "outputId": "0931249a-a1b2-4020-cf6f-25caff3c8d56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "transformed_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de48ad9b-39dd-462b-bb0a-57bedcc0f9d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "de48ad9b-39dd-462b-bb0a-57bedcc0f9d8",
        "outputId": "fe3516a1-b23d-4b9a-9494-b975aa07b0b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            col_0       col_1       col_2       col_3       col_4       col_5  \\\n",
              "count  106.000000  106.000000  106.000000  106.000000  106.000000  106.000000   \n",
              "mean     0.000123    0.001596    0.013115    0.028490    0.008604    1.067306   \n",
              "std      0.000171    0.003280    0.014912    0.011983    0.020568    1.473539   \n",
              "min      0.000000    0.000000    0.000000    0.006891    0.000000    0.000000   \n",
              "25%      0.000008    0.000000    0.001953    0.018879    0.000000    0.068232   \n",
              "50%      0.000065    0.000439    0.007047    0.027899    0.000000    0.426330   \n",
              "75%      0.000157    0.001517    0.018837    0.036742    0.004838    1.536959   \n",
              "max      0.001028    0.019375    0.058558    0.064134    0.119419    6.501442   \n",
              "\n",
              "            col_6       col_7       col_8       col_9  ...    col_1014  \\\n",
              "count  106.000000  106.000000  106.000000  106.000000  ...  106.000000   \n",
              "mean     0.003759    0.009692    0.820851    0.000341  ...    2.574852   \n",
              "std      0.001750    0.005831    0.880453    0.000449  ...    2.034847   \n",
              "min      0.000709    0.001137    0.000000    0.000000  ...    0.088338   \n",
              "25%      0.002526    0.005572    0.104984    0.000060  ...    1.263401   \n",
              "50%      0.003601    0.008399    0.482936    0.000162  ...    2.257722   \n",
              "75%      0.004792    0.012330    1.273322    0.000462  ...    3.237285   \n",
              "max      0.009723    0.031457    4.076707    0.002417  ...   14.442286   \n",
              "\n",
              "         col_1015    col_1016    col_1017    col_1018    col_1019    col_1020  \\\n",
              "count  106.000000  106.000000  106.000000  106.000000  106.000000  106.000000   \n",
              "mean     1.793822    1.863258    0.057073    1.563864    4.832652    0.472520   \n",
              "std      2.359615    1.540987    0.158559    1.730997    4.040925    0.708980   \n",
              "min      0.000000    0.000000    0.000000    0.000000    0.062467    0.000000   \n",
              "25%      0.238908    0.665239    0.000000    0.333118    1.718837    0.016078   \n",
              "50%      0.724648    1.526832    0.000387    0.868006    3.584292    0.149909   \n",
              "75%      2.402002    2.774607    0.047685    2.047933    6.655710    0.551298   \n",
              "max     12.272985    7.946444    1.157102    7.420816   18.426809    4.624881   \n",
              "\n",
              "         col_1021    col_1022    col_1023  \n",
              "count  106.000000  106.000000  106.000000  \n",
              "mean     7.973285    9.658976    2.003007  \n",
              "std      6.645405    6.318368    3.265116  \n",
              "min      0.127351    1.237950    0.000000  \n",
              "25%      2.953168    5.186445    0.185229  \n",
              "50%      6.123486    7.510556    0.755417  \n",
              "75%      9.690434   13.127022    2.107612  \n",
              "max     30.552481   28.587507   15.474657  \n",
              "\n",
              "[8 rows x 1024 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27d50a4a-0a26-4de1-a0ef-eda266b0e3c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col_0</th>\n",
              "      <th>col_1</th>\n",
              "      <th>col_2</th>\n",
              "      <th>col_3</th>\n",
              "      <th>col_4</th>\n",
              "      <th>col_5</th>\n",
              "      <th>col_6</th>\n",
              "      <th>col_7</th>\n",
              "      <th>col_8</th>\n",
              "      <th>col_9</th>\n",
              "      <th>...</th>\n",
              "      <th>col_1014</th>\n",
              "      <th>col_1015</th>\n",
              "      <th>col_1016</th>\n",
              "      <th>col_1017</th>\n",
              "      <th>col_1018</th>\n",
              "      <th>col_1019</th>\n",
              "      <th>col_1020</th>\n",
              "      <th>col_1021</th>\n",
              "      <th>col_1022</th>\n",
              "      <th>col_1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>106.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.001596</td>\n",
              "      <td>0.013115</td>\n",
              "      <td>0.028490</td>\n",
              "      <td>0.008604</td>\n",
              "      <td>1.067306</td>\n",
              "      <td>0.003759</td>\n",
              "      <td>0.009692</td>\n",
              "      <td>0.820851</td>\n",
              "      <td>0.000341</td>\n",
              "      <td>...</td>\n",
              "      <td>2.574852</td>\n",
              "      <td>1.793822</td>\n",
              "      <td>1.863258</td>\n",
              "      <td>0.057073</td>\n",
              "      <td>1.563864</td>\n",
              "      <td>4.832652</td>\n",
              "      <td>0.472520</td>\n",
              "      <td>7.973285</td>\n",
              "      <td>9.658976</td>\n",
              "      <td>2.003007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.003280</td>\n",
              "      <td>0.014912</td>\n",
              "      <td>0.011983</td>\n",
              "      <td>0.020568</td>\n",
              "      <td>1.473539</td>\n",
              "      <td>0.001750</td>\n",
              "      <td>0.005831</td>\n",
              "      <td>0.880453</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>...</td>\n",
              "      <td>2.034847</td>\n",
              "      <td>2.359615</td>\n",
              "      <td>1.540987</td>\n",
              "      <td>0.158559</td>\n",
              "      <td>1.730997</td>\n",
              "      <td>4.040925</td>\n",
              "      <td>0.708980</td>\n",
              "      <td>6.645405</td>\n",
              "      <td>6.318368</td>\n",
              "      <td>3.265116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.001137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.088338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062467</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.127351</td>\n",
              "      <td>1.237950</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001953</td>\n",
              "      <td>0.018879</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068232</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.005572</td>\n",
              "      <td>0.104984</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>...</td>\n",
              "      <td>1.263401</td>\n",
              "      <td>0.238908</td>\n",
              "      <td>0.665239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333118</td>\n",
              "      <td>1.718837</td>\n",
              "      <td>0.016078</td>\n",
              "      <td>2.953168</td>\n",
              "      <td>5.186445</td>\n",
              "      <td>0.185229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0.007047</td>\n",
              "      <td>0.027899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.426330</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.008399</td>\n",
              "      <td>0.482936</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>...</td>\n",
              "      <td>2.257722</td>\n",
              "      <td>0.724648</td>\n",
              "      <td>1.526832</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.868006</td>\n",
              "      <td>3.584292</td>\n",
              "      <td>0.149909</td>\n",
              "      <td>6.123486</td>\n",
              "      <td>7.510556</td>\n",
              "      <td>0.755417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.001517</td>\n",
              "      <td>0.018837</td>\n",
              "      <td>0.036742</td>\n",
              "      <td>0.004838</td>\n",
              "      <td>1.536959</td>\n",
              "      <td>0.004792</td>\n",
              "      <td>0.012330</td>\n",
              "      <td>1.273322</td>\n",
              "      <td>0.000462</td>\n",
              "      <td>...</td>\n",
              "      <td>3.237285</td>\n",
              "      <td>2.402002</td>\n",
              "      <td>2.774607</td>\n",
              "      <td>0.047685</td>\n",
              "      <td>2.047933</td>\n",
              "      <td>6.655710</td>\n",
              "      <td>0.551298</td>\n",
              "      <td>9.690434</td>\n",
              "      <td>13.127022</td>\n",
              "      <td>2.107612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.019375</td>\n",
              "      <td>0.058558</td>\n",
              "      <td>0.064134</td>\n",
              "      <td>0.119419</td>\n",
              "      <td>6.501442</td>\n",
              "      <td>0.009723</td>\n",
              "      <td>0.031457</td>\n",
              "      <td>4.076707</td>\n",
              "      <td>0.002417</td>\n",
              "      <td>...</td>\n",
              "      <td>14.442286</td>\n",
              "      <td>12.272985</td>\n",
              "      <td>7.946444</td>\n",
              "      <td>1.157102</td>\n",
              "      <td>7.420816</td>\n",
              "      <td>18.426809</td>\n",
              "      <td>4.624881</td>\n",
              "      <td>30.552481</td>\n",
              "      <td>28.587507</td>\n",
              "      <td>15.474657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 1024 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27d50a4a-0a26-4de1-a0ef-eda266b0e3c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27d50a4a-0a26-4de1-a0ef-eda266b0e3c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27d50a4a-0a26-4de1-a0ef-eda266b0e3c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f622134-eab1-479a-86fa-80f1eec1485d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f622134-eab1-479a-86fa-80f1eec1485d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f622134-eab1-479a-86fa-80f1eec1485d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4aeaec-c6a1-49c3-94f7-de5df8c6b13d",
      "metadata": {
        "id": "fa4aeaec-c6a1-49c3-94f7-de5df8c6b13d"
      },
      "outputs": [],
      "source": [
        "X_train_df=pd.DataFrame(X_train)\n",
        "X_train_df_copy=X_train_df.copy()\n",
        "X_train_df.reset_index(inplace=True)\n",
        "\n",
        "\n",
        "Src_ID=[i for i in range(0,106) for _ in range(0,105-i)]\n",
        "Dst_ID=[i for i in range(0,106) for i in range(1+i,106)]\n",
        "elements_to_repeat=X_train.tolist()\n",
        "repetition_counts=[105-i for i in range(0,105)]\n",
        "\n",
        "Src_feature=[]\n",
        "for element, count in zip(elements_to_repeat, repetition_counts):\n",
        "    Src_feature.extend([element] * count)\n",
        "\n",
        "Dst_feature=[]\n",
        "for i in range(1,106):\n",
        "    for j in range(i,106):\n",
        "        Dst_feature.append(X_train.tolist()[j])\n",
        "\n",
        "Nodes_Data=pd.DataFrame()\n",
        "Nodes_Data['Id']=[i for i in range(0,106)]\n",
        "labels = pd.read_csv(\"TreeLabels.csv\")\n",
        "labels['majority_vote'] = labels.mode(axis=1, numeric_only=True).astype(int)\n",
        "Nodes_Data['features']=X_train.tolist()\n",
        "Nodes_Data['label']=labels['majority_vote']\n",
        "\n",
        "dup=[0 for i in range(0,106)]\n",
        "Edge=pd.DataFrame()\n",
        "Edge['Src Id']=Src_ID\n",
        "Edge['Src_feature']=Src_feature\n",
        "Edge['Dst_feature']=Dst_feature\n",
        "Edge['Dst Id']=Dst_ID\n",
        "\n",
        "\n",
        "Src_Ids=[i for i in range(0,106) for _ in range(0,106)]\n",
        "Dst_Ids = [i % 106 for i in range(106 * 106)]\n",
        "Src_features=[X_train.tolist()[i] for i in range(0,106)  for i in range(0,106)]\n",
        "elements_to_repeat=X_train.tolist()\n",
        "repetition_counts=[106 for i in range(0,106)]\n",
        "Dst_features=[]\n",
        "for element, count in zip(elements_to_repeat, repetition_counts):\n",
        "    Dst_features.extend([element] * count)\n",
        "\n",
        "Edge_Data=pd.DataFrame()\n",
        "Edge_Data['Src Ids']=Src_Ids\n",
        "Edge_Data['Src_features']=Src_features\n",
        "Edge_Data['Dst_features']=Dst_features\n",
        "Edge_Data['Dst Ids']=Dst_Ids\n",
        "\n",
        "edge_weight=[]\n",
        "for i in range(0,5565):\n",
        "    A=np.array(Edge['Src_feature'][i])\n",
        "    B=np.array(Edge['Dst_feature'][i])\n",
        "    Cosine_similarity=np.dot(A,B)/(norm(A)*norm(B))\n",
        "    edge_weight.append(Cosine_similarity)\n",
        "\n",
        "for i in range(len(edge_weight)):\n",
        "    if edge_weight[i]<0:\n",
        "        edge_weight[i]=0\n",
        "\n",
        "Edge['edge weights']=edge_weight\n",
        "\n",
        "\n",
        "edge_weights=[]\n",
        "for i in range(0,11236):\n",
        "    A=np.array(Edge_Data['Src_features'][i])\n",
        "    B=np.array(Edge_Data['Dst_features'][i])\n",
        "    Cosine_similarity=np.dot(A,B)/(norm(A)*norm(B))\n",
        "    edge_weights.append(Cosine_similarity)\n",
        "\n",
        "Edge_Data['edge weights']=edge_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a21cb3a5-1768-4115-adbc-ca9531823828",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a21cb3a5-1768-4115-adbc-ca9531823828",
        "outputId": "650876ff-e150-4b7a-faf0-1721cff3b67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    5565.000000\n",
            "mean        0.135051\n",
            "std         0.211894\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         0.218532\n",
            "max         0.980530\n",
            "Name: edge weights, dtype: float64\n",
            "95th percentile of edge weights column: 0.5999891722334085\n"
          ]
        }
      ],
      "source": [
        "print(Edge['edge weights'].describe())\n",
        "ninetyfive_percentile = Edge['edge weights'].quantile(0.95)\n",
        "print(\"95th percentile of edge weights column:\", ninetyfive_percentile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e0d5d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3e0d5d0",
        "outputId": "3f573dab-138d-4118-cdf4-cb5f3ca495f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph(num_nodes=106, num_edges=664,\n",
            "      ndata_schemes={'feat': Scheme(shape=(100,), dtype=torch.float64), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-864d847c8354>:28: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  node_labels = torch.from_numpy(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import torch\n",
        "from dgl.data import DGLDataset\n",
        "edge_weight=[]\n",
        "\n",
        "\n",
        "class KarateClubDataset(DGLDataset):\n",
        "    def __init__(self,threshold):\n",
        "        self.threshold=threshold\n",
        "        super().__init__(name=\"karate_club\")\n",
        "\n",
        "    def process(self):\n",
        "        edge_remove=[]\n",
        "        C=edge_weights\n",
        "        for i in range(0,len(C)):\n",
        "            if C[i]<=self.threshold:\n",
        "                edge_remove.append(i)\n",
        "            else:\n",
        "                edge_weight.append(C[i])\n",
        "\n",
        "        nodes_data = Nodes_Data\n",
        "        edges_data = Edge_Data\n",
        "        features_array = np.array(nodes_data[\"features\"].tolist(), dtype=float)\n",
        "        node_features = torch.from_numpy(features_array)\n",
        "        node_labels = torch.from_numpy(\n",
        "                      nodes_data[\"label\"].astype(\"category\").cat.codes.to_numpy()\n",
        "                       ).clone().detach()  # Make the tensor writable\n",
        "\n",
        "        edge_features = torch.from_numpy(edges_data[\"edge weights\"].to_numpy())\n",
        "        edges_src = torch.from_numpy(edges_data[\"Src Ids\"].to_numpy())\n",
        "        edges_dst = torch.from_numpy(edges_data[\"Dst Ids\"].to_numpy())\n",
        "\n",
        "        self.graph = dgl.graph(\n",
        "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
        "\n",
        "        )\n",
        "\n",
        "        self.graph.ndata[\"feat\"] = node_features\n",
        "        self.graph.ndata[\"label\"] = node_labels\n",
        "        self.graph.edata[\"weight\"] = edge_features\n",
        "\n",
        "        self.graph=dgl.remove_edges(self.graph, torch.tensor(edge_remove))\n",
        "        n_nodes = nodes_data.shape[0]\n",
        "        n_train = int(n_nodes * 0.6)\n",
        "        n_val = int(n_nodes * 0.2)\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[:n_train] = True\n",
        "        val_mask[n_train : n_train + n_val] = True\n",
        "        test_mask[n_train + n_val :] = True\n",
        "        self.graph.ndata[\"train_mask\"] = train_mask\n",
        "        self.graph.ndata[\"val_mask\"] = val_mask\n",
        "        self.graph.ndata[\"test_mask\"] = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "\n",
        "dataset = KarateClubDataset(0.6)\n",
        "g = dataset[0]\n",
        "\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ca11d1-4e73-4c8c-ab56-5a4aede6063b",
      "metadata": {
        "id": "c6ca11d1-4e73-4c8c-ab56-5a4aede6063b"
      },
      "outputs": [],
      "source": [
        "#new_g = dgl.compact_graphs(g)\n",
        "train_mask = g.ndata[\"train_mask\"]\n",
        "\n",
        "for i in range(106):\n",
        "    train_mask[i] = True\n",
        "\n",
        "indices_to_change = [4, 105, 84, 27, 98, 88, 18, 65, 9, 2, 5, 49, 99, 69, 86, 67, 7, 28, 78, 70, 18, 74]\n",
        "train_mask[indices_to_change] = False\n",
        "g.ndata[\"train_mask\"]=train_mask\n",
        "\n",
        "test_mask = ~train_mask\n",
        "g.ndata[\"test_mask\"]=test_mask\n",
        "\n",
        "Edge_Data_train = Edge_Data[~(Edge_Data['Src Ids'].isin(indices_to_change)) & ~(Edge_Data['Dst Ids'].isin(indices_to_change)) & Edge_Data['edge weights']>0.8258]\n",
        "Edge_Data_train = Edge_Data_train[Edge_Data_train['edge weights']>0.8258]\n",
        "\n",
        "\n",
        "Edge_Data_test = Edge_Data[Edge_Data['Src Ids'].isin(indices_to_change) & Edge_Data['Dst Ids'].isin(indices_to_change) & Edge_Data['edge weights']>0.8258]\n",
        "Edge_Data_test = Edge_Data_test[Edge_Data_test['edge weights']>0.8258]\n",
        "\n",
        "\n",
        "#adj_matrix=g.adj(etype=None)\n",
        "#dense_matrix = adj_matrix.to_dense().numpy()\n",
        "\n",
        "#new_column = np.arange(0,dense_matrix.shape[0])\n",
        "#new_column=np.reshape(new_column,(106,1))\n",
        "#new_column.shape\n",
        "#dense_matrix=np.concatenate((new_column,dense_matrix),axis=1)\n",
        "\n",
        "#new_row = np.arange(0,106)\n",
        "#new_row=np.reshape(new_row,(1,106))\n",
        "#new_row = np.insert(new_row, 0, 0)\n",
        "#new_row=np.reshape(new_row,(1,107))\n",
        "\n",
        "#result_matrix = np.vstack([new_row,dense_matrix])\n",
        "\n",
        "#np.savetxt('dense_matrix_avg.csv',result_matrix , delimiter=',',fmt='%d')\n",
        "#FileLink(r'dense_matrix_avg.csv')\n",
        "\n",
        "sg_train=dgl.node_subgraph(g, train_mask)\n",
        "#sg_adjacency_train=sg_train.adj()\n",
        "#dense_matrix_sg_train = sg_adjacency_train.to_dense().numpy()\n",
        "\n",
        "#np.savetxt('dense_matrix_sg_train.csv',dense_matrix_sg_train, delimiter=',',fmt='%d')\n",
        "#FileLink(r'dense_matrix_sg_train.csv')\n",
        "\n",
        "sg_test = dgl.node_subgraph(g, test_mask)\n",
        "#sg_adjacency_test=sg_test.adj()\n",
        "#dense_matrix_sg_test = sg_adjacency_test.to_dense().numpy()\n",
        "\n",
        "#np.savetxt('dense_matrix_sg_test.csv',dense_matrix_sg_test, delimiter=',',fmt='%d')\n",
        "#FileLink(r'dense_matrix_sg_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81296801",
      "metadata": {
        "id": "81296801"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats,norm='both')\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        in_feat = in_feat.float()\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.leaky_relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e5bbcac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e5bbcac",
        "outputId": "d6c74481-c6c4-455c-debe-caddbed33c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 3.863, train acc: 0.718 (train 0.718), test acc: 0.762 (best 0.762)\n",
            "In epoch 5, loss: 0.770, train acc: 0.824 (train 0.824), test acc: 0.714 (best 0.762)\n",
            "In epoch 10, loss: 0.442, train acc: 0.824 (train 0.824), test acc: 0.571 (best 0.762)\n",
            "In epoch 15, loss: 0.558, train acc: 0.847 (train 0.859), test acc: 0.571 (best 0.762)\n",
            "In epoch 20, loss: 0.433, train acc: 0.847 (train 0.859), test acc: 0.476 (best 0.762)\n",
            "In epoch 25, loss: 0.387, train acc: 0.729 (train 0.859), test acc: 0.476 (best 0.762)\n",
            "In epoch 30, loss: 0.337, train acc: 0.847 (train 0.859), test acc: 0.476 (best 0.762)\n",
            "In epoch 35, loss: 0.301, train acc: 0.847 (train 0.859), test acc: 0.476 (best 0.762)\n",
            "In epoch 40, loss: 0.298, train acc: 0.847 (train 0.871), test acc: 0.476 (best 0.762)\n",
            "In epoch 45, loss: 0.288, train acc: 0.859 (train 0.871), test acc: 0.476 (best 0.762)\n",
            "In epoch 50, loss: 0.286, train acc: 0.859 (train 0.871), test acc: 0.476 (best 0.762)\n",
            "In epoch 55, loss: 0.283, train acc: 0.871 (train 0.871), test acc: 0.476 (best 0.762)\n",
            "In epoch 60, loss: 0.282, train acc: 0.859 (train 0.882), test acc: 0.476 (best 0.762)\n",
            "In epoch 65, loss: 0.280, train acc: 0.859 (train 0.882), test acc: 0.476 (best 0.762)\n",
            "In epoch 70, loss: 0.277, train acc: 0.871 (train 0.882), test acc: 0.476 (best 0.762)\n",
            "In epoch 75, loss: 0.273, train acc: 0.871 (train 0.882), test acc: 0.476 (best 0.762)\n",
            "In epoch 80, loss: 0.269, train acc: 0.871 (train 0.882), test acc: 0.476 (best 0.762)\n",
            "In epoch 85, loss: 0.267, train acc: 0.882 (train 0.882), test acc: 0.476 (best 0.762)\n",
            "In epoch 90, loss: 0.265, train acc: 0.871 (train 0.882), test acc: 0.524 (best 0.762)\n",
            "In epoch 95, loss: 0.263, train acc: 0.882 (train 0.882), test acc: 0.524 (best 0.762)\n",
            "In epoch 100, loss: 0.261, train acc: 0.871 (train 0.882), test acc: 0.524 (best 0.762)\n",
            "In epoch 105, loss: 0.259, train acc: 0.882 (train 0.882), test acc: 0.524 (best 0.762)\n",
            "In epoch 110, loss: 0.257, train acc: 0.882 (train 0.882), test acc: 0.524 (best 0.762)\n",
            "In epoch 115, loss: 0.255, train acc: 0.882 (train 0.882), test acc: 0.524 (best 0.762)\n",
            "In epoch 120, loss: 0.253, train acc: 0.871 (train 0.882), test acc: 0.524 (best 0.762)\n",
            "In epoch 125, loss: 0.250, train acc: 0.882 (train 0.882), test acc: 0.571 (best 0.762)\n",
            "In epoch 130, loss: 0.247, train acc: 0.882 (train 0.882), test acc: 0.571 (best 0.762)\n",
            "In epoch 135, loss: 0.244, train acc: 0.882 (train 0.894), test acc: 0.571 (best 0.762)\n",
            "In epoch 140, loss: 0.241, train acc: 0.906 (train 0.918), test acc: 0.571 (best 0.762)\n",
            "In epoch 145, loss: 0.238, train acc: 0.918 (train 0.918), test acc: 0.571 (best 0.762)\n",
            "In epoch 150, loss: 0.235, train acc: 0.918 (train 0.918), test acc: 0.571 (best 0.762)\n",
            "In epoch 155, loss: 0.232, train acc: 0.906 (train 0.918), test acc: 0.571 (best 0.762)\n",
            "In epoch 160, loss: 0.229, train acc: 0.918 (train 0.918), test acc: 0.571 (best 0.762)\n",
            "In epoch 165, loss: 0.226, train acc: 0.918 (train 0.918), test acc: 0.571 (best 0.762)\n",
            "In epoch 170, loss: 0.224, train acc: 0.918 (train 0.918), test acc: 0.571 (best 0.762)\n",
            "In epoch 175, loss: 0.221, train acc: 0.918 (train 0.918), test acc: 0.619 (best 0.762)\n",
            "In epoch 180, loss: 0.218, train acc: 0.918 (train 0.918), test acc: 0.619 (best 0.762)\n",
            "In epoch 185, loss: 0.215, train acc: 0.918 (train 0.918), test acc: 0.619 (best 0.762)\n",
            "In epoch 190, loss: 0.213, train acc: 0.918 (train 0.918), test acc: 0.619 (best 0.762)\n",
            "In epoch 195, loss: 0.210, train acc: 0.918 (train 0.918), test acc: 0.619 (best 0.762)\n",
            "In epoch 200, loss: 0.207, train acc: 0.918 (train 0.918), test acc: 0.619 (best 0.762)\n",
            "In epoch 205, loss: 0.205, train acc: 0.918 (train 0.918), test acc: 0.667 (best 0.762)\n",
            "In epoch 210, loss: 0.202, train acc: 0.918 (train 0.918), test acc: 0.667 (best 0.762)\n",
            "In epoch 215, loss: 0.200, train acc: 0.918 (train 0.918), test acc: 0.667 (best 0.762)\n",
            "In epoch 220, loss: 0.198, train acc: 0.918 (train 0.918), test acc: 0.667 (best 0.762)\n",
            "In epoch 225, loss: 0.195, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 230, loss: 0.193, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 235, loss: 0.191, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 240, loss: 0.189, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 245, loss: 0.186, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 250, loss: 0.184, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 255, loss: 0.183, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 260, loss: 0.181, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 265, loss: 0.179, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 270, loss: 0.177, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 275, loss: 0.176, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 280, loss: 0.174, train acc: 0.929 (train 0.929), test acc: 0.667 (best 0.762)\n",
            "In epoch 285, loss: 0.173, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 290, loss: 0.171, train acc: 0.929 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 295, loss: 0.170, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 300, loss: 0.169, train acc: 0.929 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 305, loss: 0.167, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 310, loss: 0.166, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 315, loss: 0.165, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 320, loss: 0.164, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 325, loss: 0.163, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 330, loss: 0.162, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 335, loss: 0.161, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 340, loss: 0.160, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 345, loss: 0.159, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 350, loss: 0.158, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 355, loss: 0.157, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 360, loss: 0.156, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 365, loss: 0.155, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 370, loss: 0.154, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 375, loss: 0.154, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 380, loss: 0.155, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 385, loss: 0.153, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 390, loss: 0.152, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 395, loss: 0.152, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 400, loss: 0.151, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 405, loss: 0.150, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 410, loss: 0.149, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 415, loss: 0.148, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 420, loss: 0.147, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 425, loss: 0.147, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 430, loss: 0.146, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 435, loss: 0.145, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 440, loss: 0.145, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 445, loss: 0.146, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 450, loss: 0.145, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 455, loss: 0.146, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 460, loss: 0.144, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 465, loss: 0.142, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 470, loss: 0.143, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 475, loss: 0.142, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 480, loss: 0.141, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 485, loss: 0.141, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 490, loss: 0.140, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 495, loss: 0.140, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 500, loss: 0.143, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 505, loss: 0.141, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 510, loss: 0.139, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 515, loss: 0.138, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 520, loss: 0.140, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 525, loss: 0.140, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 530, loss: 0.138, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 535, loss: 0.137, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 540, loss: 0.137, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 545, loss: 0.138, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 550, loss: 0.137, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 555, loss: 0.135, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 560, loss: 0.141, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 565, loss: 0.140, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 570, loss: 0.138, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 575, loss: 0.136, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 580, loss: 0.135, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 585, loss: 0.134, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 590, loss: 0.133, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 595, loss: 0.136, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 600, loss: 0.135, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 605, loss: 0.134, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 610, loss: 0.135, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 615, loss: 0.133, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 620, loss: 0.134, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 625, loss: 0.133, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 630, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 635, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 640, loss: 0.134, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 645, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 650, loss: 0.133, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 655, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 660, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 665, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 670, loss: 0.131, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 675, loss: 0.134, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 680, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 685, loss: 0.134, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 690, loss: 0.133, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 695, loss: 0.135, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 700, loss: 0.132, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 705, loss: 0.131, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 710, loss: 0.130, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 715, loss: 0.130, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 720, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 725, loss: 0.130, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 730, loss: 0.130, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 735, loss: 0.136, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 740, loss: 0.134, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 745, loss: 0.281, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 750, loss: 0.245, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 755, loss: 0.405, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 760, loss: 0.135, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 765, loss: 0.153, train acc: 0.929 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 770, loss: 0.193, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 775, loss: 0.472, train acc: 0.800 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 780, loss: 0.391, train acc: 0.812 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 785, loss: 0.514, train acc: 0.776 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 790, loss: 0.240, train acc: 0.906 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 795, loss: 0.186, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 800, loss: 0.175, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 805, loss: 0.145, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 810, loss: 0.143, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 815, loss: 0.144, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 820, loss: 0.135, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 825, loss: 0.133, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 830, loss: 0.133, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 835, loss: 0.131, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 840, loss: 0.130, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 845, loss: 0.130, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 850, loss: 0.130, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 855, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 860, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 865, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 870, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 875, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 880, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 885, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 890, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 895, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 900, loss: 0.129, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 905, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 910, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 915, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 920, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 925, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 930, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 935, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 940, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 945, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 950, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 955, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 960, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 965, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 970, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 975, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 980, loss: 0.128, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 985, loss: 0.127, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 990, loss: 0.127, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n",
            "In epoch 995, loss: 0.127, train acc: 0.941 (train 0.941), test acc: 0.667 (best 0.762)\n"
          ]
        }
      ],
      "source": [
        "los=[]\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "epoch=[]\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "def train(sg_train,sg_test, model):\n",
        "    model.train()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_train_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features_train = sg_train.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "\n",
        "    for e in range(1000):\n",
        "        # Forward\n",
        "        logits = model(sg_train,features_train)\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        labels = g.ndata[\"label\"].long()\n",
        "        loss = F.cross_entropy(logits, labels[train_mask])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            logits_test = model(sg_test,sg_test.ndata[\"feat\"])\n",
        "\n",
        "\n",
        "        pred_test = logits_test.argmax(1)\n",
        "\n",
        "        train_acc = (pred == labels[train_mask]).float().mean()\n",
        "        test_acc = (pred_test == labels[test_mask]).float().mean()\n",
        "\n",
        "        if best_train_acc < train_acc:\n",
        "            best_train_acc = train_acc\n",
        "        if best_test_acc < test_acc:\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            epoch.append(e)\n",
        "            los.append(round(loss.item(),3))\n",
        "            train_accuracy.append(round(train_acc.item(),3))\n",
        "            test_accuracy.append(round(test_acc.item(),3))\n",
        "            print(\n",
        "                f\"In epoch {e}, loss: {loss:.3f}, train acc: {train_acc:.3f} (train {best_train_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
        "            )\n",
        "\n",
        "\n",
        "model = GCN(g.ndata[\"feat\"].shape[1],20, 2)\n",
        "train(sg_train,sg_test,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25868d11",
      "metadata": {
        "id": "25868d11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import torch\n",
        "from dgl.data import DGLDataset\n",
        "\n",
        "\n",
        "class KarateClubDataset(DGLDataset):\n",
        "    def __init__(self,params):\n",
        "        self.params=params\n",
        "        #self.threshold=threshold\n",
        "        super().__init__(name=\"karate_club\")\n",
        "        self.process()\n",
        "    def process(self):\n",
        "        edge_remove=[]\n",
        "        C=edge_weights\n",
        "        for i in range(0,len(C)):\n",
        "            if C[i]<=self.params['percentile']:\n",
        "                edge_remove.append(i)\n",
        "        nodes_data = Nodes_Data\n",
        "        edges_data = Edge_Data\n",
        "        features_array = np.array(nodes_data[\"features\"].tolist(), dtype=float)\n",
        "        node_features = torch.from_numpy(features_array)\n",
        "        node_labels = torch.from_numpy(\n",
        "                      nodes_data[\"label\"].astype(\"category\").cat.codes.to_numpy()\n",
        "                       ).clone().detach()\n",
        "        edge_features = torch.from_numpy(edges_data[\"edge weights\"].to_numpy())\n",
        "        edges_src = torch.from_numpy(edges_data[\"Src Ids\"].to_numpy())\n",
        "        edges_dst = torch.from_numpy(edges_data[\"Dst Ids\"].to_numpy())\n",
        "        self.graph = dgl.graph(\n",
        "            (edges_src, edges_dst), num_nodes=nodes_data.shape[0]\n",
        "        )\n",
        "        self.graph.ndata[\"feat\"] = node_features\n",
        "        self.graph.ndata[\"label\"] = node_labels\n",
        "        self.graph.edata[\"weight\"] = edge_features\n",
        "\n",
        "        self.graph=dgl.remove_edges(self.graph, torch.tensor(edge_remove))\n",
        "        n_nodes = nodes_data.shape[0]\n",
        "        n_train = int(n_nodes * 0.6)\n",
        "        n_val = int(n_nodes * 0.2)\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[:n_train] = True\n",
        "        val_mask[n_train : n_train + n_val] = True\n",
        "        test_mask[n_train + n_val :] = True\n",
        "        self.graph.ndata[\"train_mask\"] = train_mask\n",
        "        self.graph.ndata[\"val_mask\"] = val_mask\n",
        "        self.graph.ndata[\"test_mask\"] = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b3db11",
      "metadata": {
        "id": "98b3db11"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self,in_feats,params,num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, params['output_features'])\n",
        "        self.conv2 = GraphConv(params['output_features'], num_classes)\n",
        "\n",
        "    def forward(self, g,in_feat,params):\n",
        "        in_feat = in_feat.float()\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = getattr(F, params['activation'])(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe9aac8",
      "metadata": {
        "id": "efe9aac8"
      },
      "outputs": [],
      "source": [
        "los=[]\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "TT=[]\n",
        "CT=[]\n",
        "epoch=[]\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "def train(g,sg_train,sg_test, model,params):\n",
        "    model.train()\n",
        "    optimizer = getattr(optim, params['optimizer'])(model.parameters(), lr= params['learning_rate'])\n",
        "    best_train_acc = 0\n",
        "    best_test_acc = 0\n",
        "    corresponding_test=0\n",
        "\n",
        "    features_train = sg_train.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(sg_train,features_train,params)\n",
        "\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "\n",
        "        labels = g.ndata[\"label\"].long()\n",
        "        if params['loss'] == 'binary_cross_entropy':\n",
        "            loss = getattr(F, params['loss'])(torch.sigmoid(logits), labels[train_mask])\n",
        "        else:\n",
        "            loss = getattr(F, params['loss'])(logits, labels[train_mask])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            logits_test = model(sg_test,sg_test.ndata[\"feat\"],params)\n",
        "\n",
        "\n",
        "        pred_test = logits_test.argmax(1)\n",
        "\n",
        "        train_acc = (pred == labels[train_mask]).float().mean()\n",
        "        test_acc = (pred_test == labels[test_mask]).float().mean()\n",
        "\n",
        "        if best_train_acc < train_acc:\n",
        "            best_train_acc = train_acc\n",
        "            corresponding_test=test_acc\n",
        "        if best_test_acc < test_acc:\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            epoch.append(e)\n",
        "            los.append(round(loss.item(),3))\n",
        "            train_accuracy.append(round(train_acc.item(),3))\n",
        "\n",
        "    TT.append({'train_accuracy':best_train_acc})\n",
        "    CT.append({'test_accuracy': corresponding_test})\n",
        "\n",
        "    print(f'Train Accuracy: {best_train_acc}, Test Accuracy: {corresponding_test}')\n",
        "    return best_train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23fca1dd",
      "metadata": {
        "id": "23fca1dd",
        "outputId": "d686728b-ff14-40f2-c283-13fef0949235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in ./anaconda3/lib/python3.11/site-packages (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in ./anaconda3/lib/python3.11/site-packages (from optuna) (1.8.1)\n",
            "Requirement already satisfied: colorlog in ./anaconda3/lib/python3.11/site-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in ./anaconda3/lib/python3.11/site-packages (from optuna) (2.0.25)\n",
            "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.11/site-packages (from optuna) (4.65.0)\n",
            "Requirement already satisfied: PyYAML in ./anaconda3/lib/python3.11/site-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in ./anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in ./anaconda3/lib/python3.11/site-packages (from sqlalchemy>=1.3.0->optuna) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in ./anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf23785",
      "metadata": {
        "id": "daf23785"
      },
      "outputs": [],
      "source": [
        "percentiles=[round(0.000000,4),round(0.016449,4),round(0.052869,4),round(0.16715442625713778,4),round(0.043810,4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80df91ce",
      "metadata": {
        "id": "80df91ce"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    percentile_values=[percentiles[0],percentiles[1],percentiles[2],percentiles[3],percentiles[4]]\n",
        "    learning_rate=[0.01,0.1,1,10,100,200]\n",
        "    output_features=[10,12,14,16,18,20,22]\n",
        "    params={'output_features':trial.suggest_categorical('output_features',output_features),\n",
        "           'optimizer':trial.suggest_categorical('optimizer',[\"Adam\", \"RMSprop\", \"SGD\"]),\n",
        "           'percentile':trial.suggest_categorical('percentile',percentile_values),\n",
        "           'learning_rate':trial.suggest_categorical('learning_rate',learning_rate),\n",
        "           'loss':trial.suggest_categorical('loss',['cross_entropy']),\n",
        "           'activation':trial.suggest_categorical('activation',['relu','selu','elu','leaky_relu','tanh'])}\n",
        "    dataset = KarateClubDataset(params)\n",
        "    g = dataset[0]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    for i in range(106):\n",
        "        train_mask[i] = True\n",
        "\n",
        "    indices_to_change = [4, 105, 84, 27, 98, 88, 18, 65, 9, 2, 5, 49, 99, 69, 86, 67, 7, 28, 78, 70, 18, 74]\n",
        "    train_mask[indices_to_change] = False\n",
        "    g.ndata[\"train_mask\"]=train_mask\n",
        "    test_mask = ~train_mask\n",
        "    g.ndata[\"test_mask\"]=test_mask\n",
        "    sg_train=dgl.node_subgraph(g, train_mask)\n",
        "    sg_test = dgl.node_subgraph(g, test_mask)\n",
        "    model=GCN(g.ndata[\"feat\"].shape[1],params, 2)\n",
        "    accuracy=train(g,sg_train,sg_test,model,params)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c178e8ba",
      "metadata": {
        "id": "c178e8ba"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=3150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc976b9",
      "metadata": {
        "id": "0bc976b9",
        "outputId": "a6d15a54-00d9-40ff-86a2-6d3d209c239d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index: 883, Test Accuracy: 0.8571428656578064\n",
            "Index: 1453, Test Accuracy: 0.8571428656578064\n",
            "Index: 257, Test Accuracy: 0.8095238208770752\n",
            "Index: 414, Test Accuracy: 0.8095238208770752\n",
            "Index: 492, Test Accuracy: 0.8095238208770752\n",
            "Index: 529, Test Accuracy: 0.8095238208770752\n",
            "Index: 544, Test Accuracy: 0.8095238208770752\n",
            "Index: 570, Test Accuracy: 0.8095238208770752\n",
            "Index: 648, Test Accuracy: 0.8095238208770752\n",
            "Index: 674, Test Accuracy: 0.8095238208770752\n",
            "Index: 778, Test Accuracy: 0.8095238208770752\n",
            "Index: 961, Test Accuracy: 0.8095238208770752\n",
            "Index: 1078, Test Accuracy: 0.8095238208770752\n",
            "Index: 1142, Test Accuracy: 0.8095238208770752\n",
            "Index: 1168, Test Accuracy: 0.8095238208770752\n",
            "Index: 1248, Test Accuracy: 0.8095238208770752\n",
            "Index: 1273, Test Accuracy: 0.8095238208770752\n",
            "Index: 1323, Test Accuracy: 0.8095238208770752\n",
            "Index: 1349, Test Accuracy: 0.8095238208770752\n",
            "Index: 1375, Test Accuracy: 0.8095238208770752\n",
            "Index: 1405, Test Accuracy: 0.8095238208770752\n",
            "Index: 1505, Test Accuracy: 0.8095238208770752\n",
            "Index: 1660, Test Accuracy: 0.8095238208770752\n",
            "Index: 1713, Test Accuracy: 0.8095238208770752\n",
            "Index: 1790, Test Accuracy: 0.8095238208770752\n",
            "Index: 2049, Test Accuracy: 0.8095238208770752\n",
            "Index: 2106, Test Accuracy: 0.8095238208770752\n",
            "Index: 2256, Test Accuracy: 0.8095238208770752\n",
            "Index: 2619, Test Accuracy: 0.8095238208770752\n",
            "Index: 2698, Test Accuracy: 0.8095238208770752\n",
            "Index: 2800, Test Accuracy: 0.8095238208770752\n",
            "Index: 2905, Test Accuracy: 0.8095238208770752\n",
            "Index: 3114, Test Accuracy: 0.8095238208770752\n",
            "Index: 63, Test Accuracy: 0.761904776096344\n",
            "Index: 67, Test Accuracy: 0.761904776096344\n",
            "Index: 102, Test Accuracy: 0.761904776096344\n",
            "Index: 107, Test Accuracy: 0.761904776096344\n",
            "Index: 158, Test Accuracy: 0.761904776096344\n",
            "Index: 196, Test Accuracy: 0.761904776096344\n",
            "Index: 286, Test Accuracy: 0.761904776096344\n",
            "Index: 457, Test Accuracy: 0.761904776096344\n",
            "Index: 463, Test Accuracy: 0.761904776096344\n",
            "Index: 466, Test Accuracy: 0.761904776096344\n",
            "Index: 510, Test Accuracy: 0.761904776096344\n",
            "Index: 536, Test Accuracy: 0.761904776096344\n",
            "Index: 705, Test Accuracy: 0.761904776096344\n",
            "Index: 806, Test Accuracy: 0.761904776096344\n",
            "Index: 837, Test Accuracy: 0.761904776096344\n",
            "Index: 857, Test Accuracy: 0.761904776096344\n",
            "Index: 968, Test Accuracy: 0.761904776096344\n",
            "Index: 1058, Test Accuracy: 0.761904776096344\n",
            "Index: 1095, Test Accuracy: 0.761904776096344\n",
            "Index: 1479, Test Accuracy: 0.761904776096344\n",
            "Index: 1653, Test Accuracy: 0.761904776096344\n",
            "Index: 1690, Test Accuracy: 0.761904776096344\n",
            "Index: 1756, Test Accuracy: 0.761904776096344\n",
            "Index: 1778, Test Accuracy: 0.761904776096344\n",
            "Index: 1786, Test Accuracy: 0.761904776096344\n",
            "Index: 1800, Test Accuracy: 0.761904776096344\n",
            "Index: 1817, Test Accuracy: 0.761904776096344\n",
            "Index: 1997, Test Accuracy: 0.761904776096344\n",
            "Index: 2039, Test Accuracy: 0.761904776096344\n",
            "Index: 2211, Test Accuracy: 0.761904776096344\n",
            "Index: 2230, Test Accuracy: 0.761904776096344\n",
            "Index: 2235, Test Accuracy: 0.761904776096344\n",
            "Index: 2446, Test Accuracy: 0.761904776096344\n",
            "Index: 2490, Test Accuracy: 0.761904776096344\n",
            "Index: 2519, Test Accuracy: 0.761904776096344\n",
            "Index: 2592, Test Accuracy: 0.761904776096344\n",
            "Index: 2609, Test Accuracy: 0.761904776096344\n",
            "Index: 2612, Test Accuracy: 0.761904776096344\n",
            "Index: 2779, Test Accuracy: 0.761904776096344\n",
            "Index: 2878, Test Accuracy: 0.761904776096344\n",
            "Index: 2930, Test Accuracy: 0.761904776096344\n",
            "Index: 3020, Test Accuracy: 0.761904776096344\n",
            "Index: 1, Test Accuracy: 0.7142857313156128\n",
            "Index: 19, Test Accuracy: 0.7142857313156128\n",
            "Index: 28, Test Accuracy: 0.7142857313156128\n",
            "Index: 31, Test Accuracy: 0.7142857313156128\n",
            "Index: 53, Test Accuracy: 0.7142857313156128\n",
            "Index: 56, Test Accuracy: 0.7142857313156128\n",
            "Index: 79, Test Accuracy: 0.7142857313156128\n",
            "Index: 110, Test Accuracy: 0.7142857313156128\n",
            "Index: 128, Test Accuracy: 0.7142857313156128\n",
            "Index: 136, Test Accuracy: 0.7142857313156128\n",
            "Index: 169, Test Accuracy: 0.7142857313156128\n",
            "Index: 172, Test Accuracy: 0.7142857313156128\n",
            "Index: 185, Test Accuracy: 0.7142857313156128\n",
            "Index: 188, Test Accuracy: 0.7142857313156128\n",
            "Index: 190, Test Accuracy: 0.7142857313156128\n",
            "Index: 194, Test Accuracy: 0.7142857313156128\n",
            "Index: 197, Test Accuracy: 0.7142857313156128\n",
            "Index: 209, Test Accuracy: 0.7142857313156128\n",
            "Index: 216, Test Accuracy: 0.7142857313156128\n",
            "Index: 272, Test Accuracy: 0.7142857313156128\n",
            "Index: 283, Test Accuracy: 0.7142857313156128\n",
            "Index: 289, Test Accuracy: 0.7142857313156128\n",
            "Index: 311, Test Accuracy: 0.7142857313156128\n",
            "Index: 338, Test Accuracy: 0.7142857313156128\n",
            "Index: 361, Test Accuracy: 0.7142857313156128\n"
          ]
        }
      ],
      "source": [
        "import heapq\n",
        "\n",
        "# Assuming CT is a list of dictionaries and each dictionary has a 'test_accuracy' key\n",
        "top_ten_max_results = heapq.nlargest(100, enumerate(CT), key=lambda x: x[1]['test_accuracy'])\n",
        "\n",
        "# Print the top ten results along with their indices\n",
        "for index, result in top_ten_max_results:\n",
        "    print(f'Index: {index}, Test Accuracy: {result[\"test_accuracy\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "775cea5d-4518-4830-8d48-559ebd7214a7",
      "metadata": {
        "id": "775cea5d-4518-4830-8d48-559ebd7214a7",
        "outputId": "3f1a748f-1501-4db2-eb03-9394ca1584ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index: 180, Train Accuracy: 0.9647058844566345\n",
            "Index: 181, Train Accuracy: 0.9647058844566345\n",
            "Index: 184, Train Accuracy: 0.9647058844566345\n",
            "Index: 186, Train Accuracy: 0.9647058844566345\n",
            "Index: 187, Train Accuracy: 0.9647058844566345\n",
            "Index: 192, Train Accuracy: 0.9647058844566345\n",
            "Index: 193, Train Accuracy: 0.9647058844566345\n",
            "Index: 195, Train Accuracy: 0.9647058844566345\n",
            "Index: 201, Train Accuracy: 0.9647058844566345\n",
            "Index: 202, Train Accuracy: 0.9647058844566345\n",
            "Index: 204, Train Accuracy: 0.9647058844566345\n",
            "Index: 206, Train Accuracy: 0.9647058844566345\n",
            "Index: 207, Train Accuracy: 0.9647058844566345\n",
            "Index: 208, Train Accuracy: 0.9647058844566345\n",
            "Index: 210, Train Accuracy: 0.9647058844566345\n",
            "Index: 213, Train Accuracy: 0.9647058844566345\n",
            "Index: 217, Train Accuracy: 0.9647058844566345\n",
            "Index: 218, Train Accuracy: 0.9647058844566345\n",
            "Index: 223, Train Accuracy: 0.9647058844566345\n",
            "Index: 224, Train Accuracy: 0.9647058844566345\n"
          ]
        }
      ],
      "source": [
        "import heapq\n",
        "\n",
        "# Assuming CT is a list of dictionaries and each dictionary has a 'test_accuracy' key\n",
        "top_ten_max_results = heapq.nlargest(20, enumerate(TT), key=lambda x: x[1]['train_accuracy'])\n",
        "\n",
        "# Print the top ten results along with their indices\n",
        "for index, result in top_ten_max_results:\n",
        "    print(f'Index: {index}, Train Accuracy: {result[\"train_accuracy\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5cfd08e",
      "metadata": {
        "id": "e5cfd08e"
      },
      "outputs": [],
      "source": [
        "train=[]\n",
        "test=[]\n",
        "for i in range(0,2520):\n",
        "    train.append(round(TT[i]['train_accuracy'].item(),4))\n",
        "    test.append(round(CT[i]['test_accuracy'].item(),4))\n",
        "\n",
        "Final_results=pd.DataFrame()\n",
        "\n",
        "Final_results['train']=train\n",
        "Final_results['test']=test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c82dac5",
      "metadata": {
        "id": "5c82dac5"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "Final_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3e8afb",
      "metadata": {
        "id": "2b3e8afb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e81c7c",
      "metadata": {
        "id": "53e81c7c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a56bd97",
      "metadata": {
        "id": "0a56bd97"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "993f746b",
      "metadata": {
        "id": "993f746b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc72f14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "2cc72f14",
        "outputId": "b4d32eb1-763f-4b77-bb9b-4b4fce2bc561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0           1          2          3          4          5   \\\n",
              "0   -74.549828   -0.885949   2.377620  -0.174074 -21.635666 -55.543640   \n",
              "1   -50.827946   92.439621 -29.660473   2.829360  92.576904 -14.962410   \n",
              "2   -66.210930  -32.647007  17.131178  -6.459964 -11.460158  12.913366   \n",
              "3   -20.881756   33.974930  -6.223113 -20.398382  37.186951  49.017967   \n",
              "4   -22.930107   75.833672  -2.919736 -11.222651   8.041885  26.873707   \n",
              "..         ...         ...        ...        ...        ...        ...   \n",
              "101  21.325041  109.261292 -15.629189  30.476246 -11.372319  37.102547   \n",
              "102 -13.500424   35.440758   6.588461 -14.094884 -39.339134 -12.782825   \n",
              "103  36.391197   26.344395  20.810404  13.678070 -16.420580  37.180328   \n",
              "104 -38.982883   21.992250  23.472237  28.372465 -14.337254  -3.996281   \n",
              "105 -50.489323   38.830189   9.220806  34.558723   5.408667  -0.838692   \n",
              "\n",
              "            6          7          8          9   ...        90        91  \\\n",
              "0    32.047112  -9.153219  -6.192144  -2.553874  ...  1.914272  2.129846   \n",
              "1    25.743187   7.053574 -12.353153   6.574588  ...  1.289670  0.050204   \n",
              "2    23.404343 -15.207271 -13.879778  -1.190819  ... -1.770236  3.653347   \n",
              "3    21.145563  30.828457  -5.229436  31.507576  ...  0.362654 -0.039269   \n",
              "4    31.156895 -25.411415 -26.349335  15.379017  ...  1.134001 -1.416697   \n",
              "..         ...        ...        ...        ...  ...       ...       ...   \n",
              "101   1.016586  37.574272  26.509417   0.113276  ... -0.249081  0.941360   \n",
              "102   8.411622   2.241854   5.234433  10.103491  ...  1.591406 -2.254897   \n",
              "103  13.758723 -18.363499  35.117527  -4.331349  ... -1.314038 -1.366400   \n",
              "104  -1.164121  34.475231  -4.119354   8.761707  ... -2.317678  0.505124   \n",
              "105   8.073947  -0.572704 -21.729042  -0.621681  ...  3.189492  0.985362   \n",
              "\n",
              "           92        93        94        95        96        97        98  \\\n",
              "0   -0.488502  1.892621 -0.778922  0.127267 -2.917187  3.261943  1.405776   \n",
              "1   -0.076915 -2.068770 -2.699282 -1.105674 -0.565170  1.432251 -1.489546   \n",
              "2   -0.543027 -2.059259  2.025901  0.388134  2.266689 -1.447044 -2.458990   \n",
              "3    0.713222  0.125282  0.681904  0.007120  0.053995  0.043748 -0.141844   \n",
              "4   -0.116935 -1.100619  0.655013  0.505443 -0.340696  0.278907 -0.238498   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "101 -1.520365 -1.124377  0.814533  0.026191 -0.111244 -0.549475  0.002424   \n",
              "102 -1.669707  0.644036 -0.538053 -1.133710  0.865531 -1.756225 -0.214103   \n",
              "103 -0.608457  0.844126  1.064216  1.629322  0.454691 -0.445961  0.515248   \n",
              "104 -0.364364 -0.803355  0.641281 -0.905808  0.939006 -0.907997 -1.775463   \n",
              "105  1.439913 -1.464102 -3.078833  1.397886 -0.123905  1.258495  0.904951   \n",
              "\n",
              "           99  \n",
              "0   -0.530233  \n",
              "1    1.199826  \n",
              "2    0.769567  \n",
              "3    0.285705  \n",
              "4   -0.189361  \n",
              "..        ...  \n",
              "101  0.821408  \n",
              "102 -1.111649  \n",
              "103  0.115312  \n",
              "104  0.664279  \n",
              "105  1.039388  \n",
              "\n",
              "[106 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a7e2933-fa43-4020-ae79-4f962f4f21fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-74.549828</td>\n",
              "      <td>-0.885949</td>\n",
              "      <td>2.377620</td>\n",
              "      <td>-0.174074</td>\n",
              "      <td>-21.635666</td>\n",
              "      <td>-55.543640</td>\n",
              "      <td>32.047112</td>\n",
              "      <td>-9.153219</td>\n",
              "      <td>-6.192144</td>\n",
              "      <td>-2.553874</td>\n",
              "      <td>...</td>\n",
              "      <td>1.914272</td>\n",
              "      <td>2.129846</td>\n",
              "      <td>-0.488502</td>\n",
              "      <td>1.892621</td>\n",
              "      <td>-0.778922</td>\n",
              "      <td>0.127267</td>\n",
              "      <td>-2.917187</td>\n",
              "      <td>3.261943</td>\n",
              "      <td>1.405776</td>\n",
              "      <td>-0.530233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-50.827946</td>\n",
              "      <td>92.439621</td>\n",
              "      <td>-29.660473</td>\n",
              "      <td>2.829360</td>\n",
              "      <td>92.576904</td>\n",
              "      <td>-14.962410</td>\n",
              "      <td>25.743187</td>\n",
              "      <td>7.053574</td>\n",
              "      <td>-12.353153</td>\n",
              "      <td>6.574588</td>\n",
              "      <td>...</td>\n",
              "      <td>1.289670</td>\n",
              "      <td>0.050204</td>\n",
              "      <td>-0.076915</td>\n",
              "      <td>-2.068770</td>\n",
              "      <td>-2.699282</td>\n",
              "      <td>-1.105674</td>\n",
              "      <td>-0.565170</td>\n",
              "      <td>1.432251</td>\n",
              "      <td>-1.489546</td>\n",
              "      <td>1.199826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-66.210930</td>\n",
              "      <td>-32.647007</td>\n",
              "      <td>17.131178</td>\n",
              "      <td>-6.459964</td>\n",
              "      <td>-11.460158</td>\n",
              "      <td>12.913366</td>\n",
              "      <td>23.404343</td>\n",
              "      <td>-15.207271</td>\n",
              "      <td>-13.879778</td>\n",
              "      <td>-1.190819</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.770236</td>\n",
              "      <td>3.653347</td>\n",
              "      <td>-0.543027</td>\n",
              "      <td>-2.059259</td>\n",
              "      <td>2.025901</td>\n",
              "      <td>0.388134</td>\n",
              "      <td>2.266689</td>\n",
              "      <td>-1.447044</td>\n",
              "      <td>-2.458990</td>\n",
              "      <td>0.769567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-20.881756</td>\n",
              "      <td>33.974930</td>\n",
              "      <td>-6.223113</td>\n",
              "      <td>-20.398382</td>\n",
              "      <td>37.186951</td>\n",
              "      <td>49.017967</td>\n",
              "      <td>21.145563</td>\n",
              "      <td>30.828457</td>\n",
              "      <td>-5.229436</td>\n",
              "      <td>31.507576</td>\n",
              "      <td>...</td>\n",
              "      <td>0.362654</td>\n",
              "      <td>-0.039269</td>\n",
              "      <td>0.713222</td>\n",
              "      <td>0.125282</td>\n",
              "      <td>0.681904</td>\n",
              "      <td>0.007120</td>\n",
              "      <td>0.053995</td>\n",
              "      <td>0.043748</td>\n",
              "      <td>-0.141844</td>\n",
              "      <td>0.285705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-22.930107</td>\n",
              "      <td>75.833672</td>\n",
              "      <td>-2.919736</td>\n",
              "      <td>-11.222651</td>\n",
              "      <td>8.041885</td>\n",
              "      <td>26.873707</td>\n",
              "      <td>31.156895</td>\n",
              "      <td>-25.411415</td>\n",
              "      <td>-26.349335</td>\n",
              "      <td>15.379017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.134001</td>\n",
              "      <td>-1.416697</td>\n",
              "      <td>-0.116935</td>\n",
              "      <td>-1.100619</td>\n",
              "      <td>0.655013</td>\n",
              "      <td>0.505443</td>\n",
              "      <td>-0.340696</td>\n",
              "      <td>0.278907</td>\n",
              "      <td>-0.238498</td>\n",
              "      <td>-0.189361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>21.325041</td>\n",
              "      <td>109.261292</td>\n",
              "      <td>-15.629189</td>\n",
              "      <td>30.476246</td>\n",
              "      <td>-11.372319</td>\n",
              "      <td>37.102547</td>\n",
              "      <td>1.016586</td>\n",
              "      <td>37.574272</td>\n",
              "      <td>26.509417</td>\n",
              "      <td>0.113276</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.249081</td>\n",
              "      <td>0.941360</td>\n",
              "      <td>-1.520365</td>\n",
              "      <td>-1.124377</td>\n",
              "      <td>0.814533</td>\n",
              "      <td>0.026191</td>\n",
              "      <td>-0.111244</td>\n",
              "      <td>-0.549475</td>\n",
              "      <td>0.002424</td>\n",
              "      <td>0.821408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>-13.500424</td>\n",
              "      <td>35.440758</td>\n",
              "      <td>6.588461</td>\n",
              "      <td>-14.094884</td>\n",
              "      <td>-39.339134</td>\n",
              "      <td>-12.782825</td>\n",
              "      <td>8.411622</td>\n",
              "      <td>2.241854</td>\n",
              "      <td>5.234433</td>\n",
              "      <td>10.103491</td>\n",
              "      <td>...</td>\n",
              "      <td>1.591406</td>\n",
              "      <td>-2.254897</td>\n",
              "      <td>-1.669707</td>\n",
              "      <td>0.644036</td>\n",
              "      <td>-0.538053</td>\n",
              "      <td>-1.133710</td>\n",
              "      <td>0.865531</td>\n",
              "      <td>-1.756225</td>\n",
              "      <td>-0.214103</td>\n",
              "      <td>-1.111649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>36.391197</td>\n",
              "      <td>26.344395</td>\n",
              "      <td>20.810404</td>\n",
              "      <td>13.678070</td>\n",
              "      <td>-16.420580</td>\n",
              "      <td>37.180328</td>\n",
              "      <td>13.758723</td>\n",
              "      <td>-18.363499</td>\n",
              "      <td>35.117527</td>\n",
              "      <td>-4.331349</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.314038</td>\n",
              "      <td>-1.366400</td>\n",
              "      <td>-0.608457</td>\n",
              "      <td>0.844126</td>\n",
              "      <td>1.064216</td>\n",
              "      <td>1.629322</td>\n",
              "      <td>0.454691</td>\n",
              "      <td>-0.445961</td>\n",
              "      <td>0.515248</td>\n",
              "      <td>0.115312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>-38.982883</td>\n",
              "      <td>21.992250</td>\n",
              "      <td>23.472237</td>\n",
              "      <td>28.372465</td>\n",
              "      <td>-14.337254</td>\n",
              "      <td>-3.996281</td>\n",
              "      <td>-1.164121</td>\n",
              "      <td>34.475231</td>\n",
              "      <td>-4.119354</td>\n",
              "      <td>8.761707</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.317678</td>\n",
              "      <td>0.505124</td>\n",
              "      <td>-0.364364</td>\n",
              "      <td>-0.803355</td>\n",
              "      <td>0.641281</td>\n",
              "      <td>-0.905808</td>\n",
              "      <td>0.939006</td>\n",
              "      <td>-0.907997</td>\n",
              "      <td>-1.775463</td>\n",
              "      <td>0.664279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>-50.489323</td>\n",
              "      <td>38.830189</td>\n",
              "      <td>9.220806</td>\n",
              "      <td>34.558723</td>\n",
              "      <td>5.408667</td>\n",
              "      <td>-0.838692</td>\n",
              "      <td>8.073947</td>\n",
              "      <td>-0.572704</td>\n",
              "      <td>-21.729042</td>\n",
              "      <td>-0.621681</td>\n",
              "      <td>...</td>\n",
              "      <td>3.189492</td>\n",
              "      <td>0.985362</td>\n",
              "      <td>1.439913</td>\n",
              "      <td>-1.464102</td>\n",
              "      <td>-3.078833</td>\n",
              "      <td>1.397886</td>\n",
              "      <td>-0.123905</td>\n",
              "      <td>1.258495</td>\n",
              "      <td>0.904951</td>\n",
              "      <td>1.039388</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a7e2933-fa43-4020-ae79-4f962f4f21fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a7e2933-fa43-4020-ae79-4f962f4f21fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a7e2933-fa43-4020-ae79-4f962f4f21fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2b982e69-1a3c-44bc-86a3-382950de3957\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b982e69-1a3c-44bc-86a3-382950de3957')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2b982e69-1a3c-44bc-86a3-382950de3957 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4843dee2-9d78-477c-99cc-2aea962d1ae7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train_df_copy')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4843dee2-9d78-477c-99cc-2aea962d1ae7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train_df_copy');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_df_copy"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train_df_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "443b582d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "443b582d",
        "outputId": "09b0bc29-d4a4-4da8-c8ac-05317b688a49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.series.Series</b><br/>def __init__(data=None, index=None, dtype: Dtype | None=None, name=None, copy: bool | None=None, fastpath: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/series.py</a>One-dimensional ndarray with axis labels (including time series).\n",
              "\n",
              "Labels need not be unique but must be a hashable type. The object\n",
              "supports both integer- and label-based indexing and provides a host of\n",
              "methods for performing operations involving the index. Statistical\n",
              "methods from ndarray have been overridden to automatically exclude\n",
              "missing data (currently represented as NaN).\n",
              "\n",
              "Operations between Series (+, -, /, \\*, \\*\\*) align values based on their\n",
              "associated index values-- they need not be the same length. The result\n",
              "index will be the sorted union of the two indexes.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : array-like, Iterable, dict, or scalar value\n",
              "    Contains data stored in Series. If data is a dict, argument order is\n",
              "    maintained.\n",
              "index : array-like or Index (1d)\n",
              "    Values must be hashable and have the same length as `data`.\n",
              "    Non-unique index values are allowed. Will default to\n",
              "    RangeIndex (0, 1, 2, ..., n) if not provided. If data is dict-like\n",
              "    and index is None, then the keys in the data are used as the index. If the\n",
              "    index is not None, the resulting Series is reindexed with the index values.\n",
              "dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
              "    Data type for the output Series. If not specified, this will be\n",
              "    inferred from `data`.\n",
              "    See the :ref:`user guide &lt;basics.dtypes&gt;` for more usages.\n",
              "name : Hashable, default None\n",
              "    The name to give to the Series.\n",
              "copy : bool, default False\n",
              "    Copy input data. Only affects Series or 1d ndarray input. See examples.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.series&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing Series from a dictionary with an Index specified\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "a   1\n",
              "b   2\n",
              "c   3\n",
              "dtype: int64\n",
              "\n",
              "The keys of the dictionary match with the Index values, hence the Index\n",
              "values have no effect.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;a&#x27;: 1, &#x27;b&#x27;: 2, &#x27;c&#x27;: 3}\n",
              "&gt;&gt;&gt; ser = pd.Series(data=d, index=[&#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;])\n",
              "&gt;&gt;&gt; ser\n",
              "x   NaN\n",
              "y   NaN\n",
              "z   NaN\n",
              "dtype: float64\n",
              "\n",
              "Note that the Index is first build with the keys from the dictionary.\n",
              "After this the Series is reindexed with the given Index values, hence we\n",
              "get all NaN as a result.\n",
              "\n",
              "Constructing Series from a list with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = [1, 2]\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "[1, 2]\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `copy` of\n",
              "the original data even though `copy=False`, so\n",
              "the data is unchanged.\n",
              "\n",
              "Constructing Series from a 1d ndarray with `copy=False`.\n",
              "\n",
              "&gt;&gt;&gt; r = np.array([1, 2])\n",
              "&gt;&gt;&gt; ser = pd.Series(r, copy=False)\n",
              "&gt;&gt;&gt; ser.iloc[0] = 999\n",
              "&gt;&gt;&gt; r\n",
              "array([999,   2])\n",
              "&gt;&gt;&gt; ser\n",
              "0    999\n",
              "1      2\n",
              "dtype: int64\n",
              "\n",
              "Due to input data type the Series has a `view` on\n",
              "the original data, so\n",
              "the data is changed as well.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 244);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "labels = pd.read_csv(\"TreeLabels.csv\")\n",
        "labels['majority_vote'] = labels.mode(axis=1, numeric_only=True).astype(int)\n",
        "type(labels['majority_vote'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d5eb9c2",
      "metadata": {
        "id": "2d5eb9c2"
      },
      "outputs": [],
      "source": [
        "X_train_df_copy['label']=labels['majority_vote']\n",
        "y=X_train_df_copy['label']\n",
        "X=X_train_df_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686eb97f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "686eb97f",
        "outputId": "ccdc554c-6d80-4338-bf2f-7682f8fab765"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0           1          2          3          4          5   \\\n",
              "0   -74.549828   -0.885949   2.377620  -0.174074 -21.635666 -55.543640   \n",
              "1   -50.827946   92.439621 -29.660473   2.829360  92.576904 -14.962410   \n",
              "2   -66.210930  -32.647007  17.131178  -6.459964 -11.460158  12.913366   \n",
              "3   -20.881756   33.974930  -6.223113 -20.398382  37.186951  49.017967   \n",
              "4   -22.930107   75.833672  -2.919736 -11.222651   8.041885  26.873707   \n",
              "..         ...         ...        ...        ...        ...        ...   \n",
              "101  21.325041  109.261292 -15.629189  30.476246 -11.372319  37.102547   \n",
              "102 -13.500424   35.440758   6.588461 -14.094884 -39.339134 -12.782825   \n",
              "103  36.391197   26.344395  20.810404  13.678070 -16.420580  37.180328   \n",
              "104 -38.982883   21.992250  23.472237  28.372465 -14.337254  -3.996281   \n",
              "105 -50.489323   38.830189   9.220806  34.558723   5.408667  -0.838692   \n",
              "\n",
              "            6          7          8          9   ...        90        91  \\\n",
              "0    32.047112  -9.153219  -6.192144  -2.553874  ...  1.914272  2.129846   \n",
              "1    25.743187   7.053574 -12.353153   6.574588  ...  1.289670  0.050204   \n",
              "2    23.404343 -15.207271 -13.879778  -1.190819  ... -1.770236  3.653347   \n",
              "3    21.145563  30.828457  -5.229436  31.507576  ...  0.362654 -0.039269   \n",
              "4    31.156895 -25.411415 -26.349335  15.379017  ...  1.134001 -1.416697   \n",
              "..         ...        ...        ...        ...  ...       ...       ...   \n",
              "101   1.016586  37.574272  26.509417   0.113276  ... -0.249081  0.941360   \n",
              "102   8.411622   2.241854   5.234433  10.103491  ...  1.591406 -2.254897   \n",
              "103  13.758723 -18.363499  35.117527  -4.331349  ... -1.314038 -1.366400   \n",
              "104  -1.164121  34.475231  -4.119354   8.761707  ... -2.317678  0.505124   \n",
              "105   8.073947  -0.572704 -21.729042  -0.621681  ...  3.189492  0.985362   \n",
              "\n",
              "           92        93        94        95        96        97        98  \\\n",
              "0   -0.488502  1.892621 -0.778922  0.127267 -2.917187  3.261943  1.405776   \n",
              "1   -0.076915 -2.068770 -2.699282 -1.105674 -0.565170  1.432251 -1.489546   \n",
              "2   -0.543027 -2.059259  2.025901  0.388134  2.266689 -1.447044 -2.458990   \n",
              "3    0.713222  0.125282  0.681904  0.007120  0.053995  0.043748 -0.141844   \n",
              "4   -0.116935 -1.100619  0.655013  0.505443 -0.340696  0.278907 -0.238498   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "101 -1.520365 -1.124377  0.814533  0.026191 -0.111244 -0.549475  0.002424   \n",
              "102 -1.669707  0.644036 -0.538053 -1.133710  0.865531 -1.756225 -0.214103   \n",
              "103 -0.608457  0.844126  1.064216  1.629322  0.454691 -0.445961  0.515248   \n",
              "104 -0.364364 -0.803355  0.641281 -0.905808  0.939006 -0.907997 -1.775463   \n",
              "105  1.439913 -1.464102 -3.078833  1.397886 -0.123905  1.258495  0.904951   \n",
              "\n",
              "           99  \n",
              "0   -0.530233  \n",
              "1    1.199826  \n",
              "2    0.769567  \n",
              "3    0.285705  \n",
              "4   -0.189361  \n",
              "..        ...  \n",
              "101  0.821408  \n",
              "102 -1.111649  \n",
              "103  0.115312  \n",
              "104  0.664279  \n",
              "105  1.039388  \n",
              "\n",
              "[106 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cab8947-a030-4abf-b812-bf66cd66deb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-74.549828</td>\n",
              "      <td>-0.885949</td>\n",
              "      <td>2.377620</td>\n",
              "      <td>-0.174074</td>\n",
              "      <td>-21.635666</td>\n",
              "      <td>-55.543640</td>\n",
              "      <td>32.047112</td>\n",
              "      <td>-9.153219</td>\n",
              "      <td>-6.192144</td>\n",
              "      <td>-2.553874</td>\n",
              "      <td>...</td>\n",
              "      <td>1.914272</td>\n",
              "      <td>2.129846</td>\n",
              "      <td>-0.488502</td>\n",
              "      <td>1.892621</td>\n",
              "      <td>-0.778922</td>\n",
              "      <td>0.127267</td>\n",
              "      <td>-2.917187</td>\n",
              "      <td>3.261943</td>\n",
              "      <td>1.405776</td>\n",
              "      <td>-0.530233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-50.827946</td>\n",
              "      <td>92.439621</td>\n",
              "      <td>-29.660473</td>\n",
              "      <td>2.829360</td>\n",
              "      <td>92.576904</td>\n",
              "      <td>-14.962410</td>\n",
              "      <td>25.743187</td>\n",
              "      <td>7.053574</td>\n",
              "      <td>-12.353153</td>\n",
              "      <td>6.574588</td>\n",
              "      <td>...</td>\n",
              "      <td>1.289670</td>\n",
              "      <td>0.050204</td>\n",
              "      <td>-0.076915</td>\n",
              "      <td>-2.068770</td>\n",
              "      <td>-2.699282</td>\n",
              "      <td>-1.105674</td>\n",
              "      <td>-0.565170</td>\n",
              "      <td>1.432251</td>\n",
              "      <td>-1.489546</td>\n",
              "      <td>1.199826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-66.210930</td>\n",
              "      <td>-32.647007</td>\n",
              "      <td>17.131178</td>\n",
              "      <td>-6.459964</td>\n",
              "      <td>-11.460158</td>\n",
              "      <td>12.913366</td>\n",
              "      <td>23.404343</td>\n",
              "      <td>-15.207271</td>\n",
              "      <td>-13.879778</td>\n",
              "      <td>-1.190819</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.770236</td>\n",
              "      <td>3.653347</td>\n",
              "      <td>-0.543027</td>\n",
              "      <td>-2.059259</td>\n",
              "      <td>2.025901</td>\n",
              "      <td>0.388134</td>\n",
              "      <td>2.266689</td>\n",
              "      <td>-1.447044</td>\n",
              "      <td>-2.458990</td>\n",
              "      <td>0.769567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-20.881756</td>\n",
              "      <td>33.974930</td>\n",
              "      <td>-6.223113</td>\n",
              "      <td>-20.398382</td>\n",
              "      <td>37.186951</td>\n",
              "      <td>49.017967</td>\n",
              "      <td>21.145563</td>\n",
              "      <td>30.828457</td>\n",
              "      <td>-5.229436</td>\n",
              "      <td>31.507576</td>\n",
              "      <td>...</td>\n",
              "      <td>0.362654</td>\n",
              "      <td>-0.039269</td>\n",
              "      <td>0.713222</td>\n",
              "      <td>0.125282</td>\n",
              "      <td>0.681904</td>\n",
              "      <td>0.007120</td>\n",
              "      <td>0.053995</td>\n",
              "      <td>0.043748</td>\n",
              "      <td>-0.141844</td>\n",
              "      <td>0.285705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-22.930107</td>\n",
              "      <td>75.833672</td>\n",
              "      <td>-2.919736</td>\n",
              "      <td>-11.222651</td>\n",
              "      <td>8.041885</td>\n",
              "      <td>26.873707</td>\n",
              "      <td>31.156895</td>\n",
              "      <td>-25.411415</td>\n",
              "      <td>-26.349335</td>\n",
              "      <td>15.379017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.134001</td>\n",
              "      <td>-1.416697</td>\n",
              "      <td>-0.116935</td>\n",
              "      <td>-1.100619</td>\n",
              "      <td>0.655013</td>\n",
              "      <td>0.505443</td>\n",
              "      <td>-0.340696</td>\n",
              "      <td>0.278907</td>\n",
              "      <td>-0.238498</td>\n",
              "      <td>-0.189361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>21.325041</td>\n",
              "      <td>109.261292</td>\n",
              "      <td>-15.629189</td>\n",
              "      <td>30.476246</td>\n",
              "      <td>-11.372319</td>\n",
              "      <td>37.102547</td>\n",
              "      <td>1.016586</td>\n",
              "      <td>37.574272</td>\n",
              "      <td>26.509417</td>\n",
              "      <td>0.113276</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.249081</td>\n",
              "      <td>0.941360</td>\n",
              "      <td>-1.520365</td>\n",
              "      <td>-1.124377</td>\n",
              "      <td>0.814533</td>\n",
              "      <td>0.026191</td>\n",
              "      <td>-0.111244</td>\n",
              "      <td>-0.549475</td>\n",
              "      <td>0.002424</td>\n",
              "      <td>0.821408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>-13.500424</td>\n",
              "      <td>35.440758</td>\n",
              "      <td>6.588461</td>\n",
              "      <td>-14.094884</td>\n",
              "      <td>-39.339134</td>\n",
              "      <td>-12.782825</td>\n",
              "      <td>8.411622</td>\n",
              "      <td>2.241854</td>\n",
              "      <td>5.234433</td>\n",
              "      <td>10.103491</td>\n",
              "      <td>...</td>\n",
              "      <td>1.591406</td>\n",
              "      <td>-2.254897</td>\n",
              "      <td>-1.669707</td>\n",
              "      <td>0.644036</td>\n",
              "      <td>-0.538053</td>\n",
              "      <td>-1.133710</td>\n",
              "      <td>0.865531</td>\n",
              "      <td>-1.756225</td>\n",
              "      <td>-0.214103</td>\n",
              "      <td>-1.111649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>36.391197</td>\n",
              "      <td>26.344395</td>\n",
              "      <td>20.810404</td>\n",
              "      <td>13.678070</td>\n",
              "      <td>-16.420580</td>\n",
              "      <td>37.180328</td>\n",
              "      <td>13.758723</td>\n",
              "      <td>-18.363499</td>\n",
              "      <td>35.117527</td>\n",
              "      <td>-4.331349</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.314038</td>\n",
              "      <td>-1.366400</td>\n",
              "      <td>-0.608457</td>\n",
              "      <td>0.844126</td>\n",
              "      <td>1.064216</td>\n",
              "      <td>1.629322</td>\n",
              "      <td>0.454691</td>\n",
              "      <td>-0.445961</td>\n",
              "      <td>0.515248</td>\n",
              "      <td>0.115312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>-38.982883</td>\n",
              "      <td>21.992250</td>\n",
              "      <td>23.472237</td>\n",
              "      <td>28.372465</td>\n",
              "      <td>-14.337254</td>\n",
              "      <td>-3.996281</td>\n",
              "      <td>-1.164121</td>\n",
              "      <td>34.475231</td>\n",
              "      <td>-4.119354</td>\n",
              "      <td>8.761707</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.317678</td>\n",
              "      <td>0.505124</td>\n",
              "      <td>-0.364364</td>\n",
              "      <td>-0.803355</td>\n",
              "      <td>0.641281</td>\n",
              "      <td>-0.905808</td>\n",
              "      <td>0.939006</td>\n",
              "      <td>-0.907997</td>\n",
              "      <td>-1.775463</td>\n",
              "      <td>0.664279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>-50.489323</td>\n",
              "      <td>38.830189</td>\n",
              "      <td>9.220806</td>\n",
              "      <td>34.558723</td>\n",
              "      <td>5.408667</td>\n",
              "      <td>-0.838692</td>\n",
              "      <td>8.073947</td>\n",
              "      <td>-0.572704</td>\n",
              "      <td>-21.729042</td>\n",
              "      <td>-0.621681</td>\n",
              "      <td>...</td>\n",
              "      <td>3.189492</td>\n",
              "      <td>0.985362</td>\n",
              "      <td>1.439913</td>\n",
              "      <td>-1.464102</td>\n",
              "      <td>-3.078833</td>\n",
              "      <td>1.397886</td>\n",
              "      <td>-0.123905</td>\n",
              "      <td>1.258495</td>\n",
              "      <td>0.904951</td>\n",
              "      <td>1.039388</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 100 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cab8947-a030-4abf-b812-bf66cd66deb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cab8947-a030-4abf-b812-bf66cd66deb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cab8947-a030-4abf-b812-bf66cd66deb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1f888da-9b3d-4cfd-ba05-5fdec74f350a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1f888da-9b3d-4cfd-ba05-5fdec74f350a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1f888da-9b3d-4cfd-ba05-5fdec74f350a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_83527738-e31f-40e1-aa3b-6501f45eca74\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train_df_copy')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_83527738-e31f-40e1-aa3b-6501f45eca74 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train_df_copy');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train_df_copy"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "X.drop(columns=['label'],axis=1,inplace=True)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f14fe96d-da32-46e4-af9a-adb84db689a7",
      "metadata": {
        "id": "f14fe96d-da32-46e4-af9a-adb84db689a7"
      },
      "outputs": [],
      "source": [
        "indices_to_change = [4, 105, 84, 27, 98, 88, 18, 65, 9, 2, 5, 49, 99, 69, 86, 67, 7, 28, 78, 70, 18, 74]\n",
        "\n",
        "# Create a boolean mask to identify indices for the test set\n",
        "test_mask = np.zeros(len(X), dtype=bool)\n",
        "test_mask[indices_to_change] = True\n",
        "\n",
        "# Split the dataset based on the boolean mask\n",
        "X_train = X[~test_mask]\n",
        "X_test = X[test_mask]\n",
        "y_train = y[~test_mask]\n",
        "y_test = y[test_mask]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232245f6",
      "metadata": {
        "id": "232245f6"
      },
      "outputs": [],
      "source": [
        "param_grid = {'penalty':['l1','l2',None],'C': [0.1,2,2.5,3],\n",
        "                   'solver':['liblinear','saga'],'max_iter':[500]}\n",
        "LR=LogisticRegression(random_state=0)\n",
        "grid_search_LR = GridSearchCV(estimator=LR,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=3)\n",
        "\n",
        "grid_search_LR.fit(X_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search_LR.best_params_)\n",
        "print(\"Best Score: {}\".format(grid_search_LR.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc09049",
      "metadata": {
        "id": "3cc09049"
      },
      "outputs": [],
      "source": [
        "param_grid = {'penalty':['elasticnet',None],'C': [0.1,2,2.5,3],\n",
        "                   'solver':['saga'],'max_iter':[500],'l1_ratio':[0.5,0.2,0.7]}\n",
        "LR=LogisticRegression(random_state=0)\n",
        "grid_search_LR = GridSearchCV(estimator=LR,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=2)\n",
        "grid_search_LR.fit(X_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search_LR.best_params_)\n",
        "print(\"Best Score: {}\".format(grid_search_LR.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4dfadd",
      "metadata": {
        "id": "7d4dfadd"
      },
      "outputs": [],
      "source": [
        "param_grid = {'penalty':['l2',None],'C': [0.1,2,2.5,3],\n",
        "                   'solver':['lbfgs','newton-cg','sag'],'max_iter':[500]}\n",
        "LR=LogisticRegression(random_state=0)\n",
        "grid_search_LR = GridSearchCV(estimator=LR,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=3\n",
        "                          )\n",
        "\n",
        "grid_search_LR.fit(X_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search_LR.best_params_)\n",
        "print(\"Best Score: {}\".format(grid_search_LR.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36fa37d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "36fa37d7",
        "outputId": "dd32d7f8-8716-4839-cc84-3907f1b3bdb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=2, max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=2, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=2, max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "LR=LogisticRegression(C=2,penalty='l2',solver='lbfgs',max_iter=1000)\n",
        "LR.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17158811",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17158811",
        "outputId": "d9a5e90b-40eb-4778-a766-df8fc96da6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_accuracy 1.0\n",
            "test_accuracy 0.7142857142857143\n"
          ]
        }
      ],
      "source": [
        "LR_pred = LR.predict(X_train)\n",
        "acc_train=accuracy_score(y_train,LR_pred)\n",
        "print('train_accuracy',acc_train)\n",
        "LR_pred = LR.predict(X_test)\n",
        "acc=accuracy_score(y_test,LR_pred)\n",
        "print('test_accuracy',acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b8a2f2-3db9-4cd9-9af5-06720d76eccf",
      "metadata": {
        "id": "b7b8a2f2-3db9-4cd9-9af5-06720d76eccf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba961e4-336d-41c3-8509-7e816bf5f69e",
      "metadata": {
        "id": "9ba961e4-336d-41c3-8509-7e816bf5f69e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2df025-4cd8-4584-b163-3e1722f1ef04",
      "metadata": {
        "id": "4e2df025-4cd8-4584-b163-3e1722f1ef04"
      },
      "outputs": [],
      "source": [
        "X_train_values = X_train.values\n",
        "X_test_values = X_test.values\n",
        "#X_valid_values = X_valid.values\n",
        "\n",
        "# Reshape input data to 3D [samples, timesteps, features] so it'll fit the LSTM layer\n",
        "# Use a timestep of 1.\n",
        "X_train_reshaped = np.reshape(X_train_values, (X_train_values.shape[0], 1, X_train_values.shape[1]))\n",
        "X_test_reshaped = np.reshape(X_test_values, (X_test_values.shape[0], 1, X_test_values.shape[1]))\n",
        "#X_valid_reshaped = np.reshape(X_valid_values, (X_valid_values.shape[0], 1, X_valid_values.shape[1]))\n",
        "\n",
        "# LSTM model\n",
        "lstm = Sequential()\n",
        "lstm.add(LSTM(100,return_sequences=True,activation='selu',input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "lstm.add(Dropout(0.7))\n",
        "\n",
        "lstm.add(LSTM(50,activation='selu',return_sequences=False,kernel_regularizer=l2(0.01)))\n",
        "lstm.add(Dropout(0.7))\n",
        "lstm.add(Dense(1,activation='sigmoid'))  # Prediction of the next closing value\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "lstm.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "lstm.fit(X_train_reshaped, y_train, epochs=1000, batch_size=32, verbose=1)\n",
        "\n",
        "# Predicting and inverse transforming the predictions\n",
        "y_pred_train_lstm = lstm.predict(X_train_reshaped)\n",
        "y_pred_test_lstm = lstm.predict(X_test_reshaped)\n",
        "\n",
        "#y_pred = scaler.inverse_transform(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f7966e-0c00-4050-9c4b-c955c14561b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37f7966e-0c00-4050-9c4b-c955c14561b6",
        "outputId": "f08b6afb-ab89-426f-9e3c-9a71d052d323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy 1.0\n",
            "test accuracy 0.5238095238095238\n"
          ]
        }
      ],
      "source": [
        "y_pred_train_lstm = np.squeeze(y_pred_train_lstm)\n",
        "y_pred_test_lstm = np.squeeze(y_pred_test_lstm)\n",
        "y_pred_train_lstm = (y_pred_train_lstm > 0.5).astype(int)\n",
        "acc_train=accuracy_score(y_train,y_pred_train_lstm)\n",
        "print('train accuracy',acc_train)\n",
        "y_pred_test_lstm = (y_pred_test_lstm > 0.5).astype(int)\n",
        "acc_test=accuracy_score(y_test,y_pred_test_lstm)\n",
        "print('test accuracy',acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59673cad-837a-484c-9ccf-a7fda0957464",
      "metadata": {
        "id": "59673cad-837a-484c-9ccf-a7fda0957464"
      },
      "outputs": [],
      "source": [
        "bilstm = Sequential()\n",
        "bilstm.add(Bidirectional(LSTM(100, return_sequences=True,kernel_regularizer=l2(0.01)), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "#bilstm.add(Dropout(0.7))\n",
        "bilstm.add(Bidirectional(LSTM(50, return_sequences=False,kernel_regularizer=l2(0.01))))\n",
        "#bilstm.add(Dropout(0.7))\n",
        "bilstm.add(Dense(1, activation='sigmoid',kernel_regularizer=l2(0.01)))  # Binary classification output\n",
        "\n",
        "# Compile the model\n",
        "bilstm.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the model\n",
        "bilstm.fit(X_train_reshaped, y_train, epochs=500, batch_size=32, verbose=1)\n",
        "\n",
        "# Predicting\n",
        "y_pred_train_bilstm = bilstm.predict(X_train_reshaped)\n",
        "y_pred_test_bilstm = bilstm.predict(X_test_reshaped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76247ddc",
      "metadata": {
        "id": "76247ddc"
      },
      "outputs": [],
      "source": [
        "y_pred_train_bilstm = np.squeeze(y_pred_train_bilstm)\n",
        "y_pred_test_bilstm = np.squeeze(y_pred_test_bilstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd68f6a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd68f6a0",
        "outputId": "4d3acbe6-faaf-4422-f1fa-9457c7aebc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy 1.0\n",
            "test accuracy 0.6666666666666666\n"
          ]
        }
      ],
      "source": [
        "y_pred_train_bilstm = (y_pred_train_bilstm > 0.5).astype(int)\n",
        "acc_train=accuracy_score(y_train,y_pred_train_bilstm)\n",
        "print('train accuracy',acc_train)\n",
        "y_pred_test_bilstm = (y_pred_test_bilstm > 0.5).astype(int)\n",
        "acc_test=accuracy_score(y_test,y_pred_test_bilstm)\n",
        "print('test accuracy',acc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e26bd467-e763-40f3-a335-b5a7602e379e",
      "metadata": {
        "id": "e26bd467-e763-40f3-a335-b5a7602e379e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}